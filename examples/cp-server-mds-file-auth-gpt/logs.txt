➜  cp-server-mds-file-auth-gpt git:(cp-server-native) ✗ docker logs -f kafka
===> User
uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
===> Configuring ...
SASL is enabled.
===> Running preflight checks ...
===> Check if /var/lib/kafka/data is writable ...
===> Using provided cluster id 4L6g3nShT-eMCtK--X86sw ...
===> Launching ...
===> Launching kafka ...
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/share/java/kafka/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/share/java/confluent-metadata-service/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/share/java/ce-kafka-rest-servlet/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/share/java/ce-kafka-rest-extensions/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/share/java/confluent-security/kafka-rest/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
[2025-07-23 11:50:56,730] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-07-23 11:50:56,730] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-07-23 11:50:57,289] INFO KafkaConfig values:
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = SASL_PLAINTEXT://kafka:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
	broker.rack = null
	broker.session.timeout.ms = 9000
	broker.session.uuid = 2yBYTgb0Tf6Hp4Sp67hPyg
	client.quota.callback.class = null
	client.quota.max.throttle.time.in.response.ms = 60000
	client.quota.max.throttle.time.ms = 5000
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	confluent.accp.enabled = false
	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
	confluent.alter.broker.health.max.demoted.brokers = 2147483647
	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
	confluent.ansible.managed = false
	confluent.api.visibility = DEFAULT
	confluent.append.record.interceptor.classes = []
	confluent.apply.create.topic.policy.to.create.partitions = false
	confluent.authorizer.authority.name =
	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
	confluent.backpressure.disk.enable = false
	confluent.backpressure.disk.free.threshold.bytes = 21474836480
	confluent.backpressure.disk.produce.bytes.per.second = 131072
	confluent.backpressure.disk.threshold.recovery.factor = 1.5
	confluent.backpressure.request.min.broker.limit = 200
	confluent.backpressure.request.queue.size.percentile = p95
	confluent.backpressure.types = null
	confluent.balancer.api.state.topic = _confluent_balancer_api_state
	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
	confluent.balancer.capacity.threshold.upper.limit = 0.95
	confluent.balancer.cell.load.upper.bound = 0.7
	confluent.balancer.cell.overload.detection.interval.ms = 3600000
	confluent.balancer.cell.overload.duration.ms = 86400000
	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.cpu.balance.threshold = 1.1
	confluent.balancer.cpu.goal.act.as.capacity.goal = false
	confluent.balancer.cpu.low.utilization.threshold = 0.2
	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
	confluent.balancer.disk.max.load = 0.85
	confluent.balancer.disk.min.free.space.gb = 0
	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
	confluent.balancer.disk.utilization.detector.duration.ms = 600000
	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
	confluent.balancer.enable = true
	confluent.balancer.enable.network.capacity.metric.ingestion = false
	confluent.balancer.exclude.topic.names = []
	confluent.balancer.exclude.topic.prefixes = []
	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	confluent.balancer.incremental.balancing.enabled = false
	confluent.balancer.incremental.balancing.goals = []
	confluent.balancer.incremental.balancing.lower.bound = 0.02
	confluent.balancer.incremental.balancing.min.valid.windows = 5
	confluent.balancer.incremental.balancing.step.ratio = 0.2
	confluent.balancer.inter.cell.balancing.enabled = false
	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
	confluent.balancer.max.replicas = 2147483647
	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.rebalancing.goals = []
	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.resource.utilization.detector.interval.ms = 60000
	confluent.balancer.sbc.metrics.parser.enabled = false
	confluent.balancer.self.healing.maximum.rounds = 1
	confluent.balancer.task.history.retention.days = 30
	confluent.balancer.tenant.maximum.movements = 0
	confluent.balancer.tenant.suspension.ms = 86400000
	confluent.balancer.throttle.bytes.per.second = 10485760
	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
	confluent.balancer.topic.partition.maximum.movements = 3
	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
	confluent.balancer.topic.partition.movements.history.limit = 900
	confluent.balancer.topic.partition.suspension.ms = 3600000
	confluent.balancer.topic.replication.factor = 1
	confluent.balancer.triggering.goals = []
	confluent.balancer.v2.addition.enabled = false
	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
	confluent.balancer.v2.executor.enabled = false
	confluent.basic.auth.credentials.source = null
	confluent.basic.auth.user.info = null
	confluent.bearer.assertion.claim.aud = null
	confluent.bearer.assertion.claim.exp.minutes = null
	confluent.bearer.assertion.claim.iss = null
	confluent.bearer.assertion.claim.jti.include = null
	confluent.bearer.assertion.claim.nbf.include = null
	confluent.bearer.assertion.claim.sub = null
	confluent.bearer.assertion.file = null
	confluent.bearer.assertion.private.key.file = null
	confluent.bearer.assertion.private.key.passphrase = null
	confluent.bearer.assertion.template.file = null
	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
	confluent.bearer.auth.client.id = null
	confluent.bearer.auth.client.secret = null
	confluent.bearer.auth.credentials.source = null
	confluent.bearer.auth.identity.pool.id = null
	confluent.bearer.auth.issuer.endpoint.url = null
	confluent.bearer.auth.logical.cluster = null
	confluent.bearer.auth.scope = null
	confluent.bearer.auth.scope.claim.name = scope
	confluent.bearer.auth.sub.claim.name = sub
	confluent.bearer.auth.token = null
	confluent.broker.health.manager.enabled = true
	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
	confluent.broker.health.manager.hard.kill.duration.ms = 60000
	confluent.broker.health.manager.mitigation.enabled = false
	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
	confluent.broker.health.manager.sample.duration.ms = 1000
	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
	confluent.broker.load.advertised.limit.load = 0.8
	confluent.broker.load.average.service.request.time.ms = 0.1
	confluent.broker.load.delay.metric.start.ms = 180000
	confluent.broker.load.enabled = false
	confluent.broker.load.num.samples = 60
	confluent.broker.load.tenant.metric.enable = false
	confluent.broker.load.update.metric.tags.interval.ms = 60000
	confluent.broker.load.window.size.ms = 60000
	confluent.broker.load.workload.coefficient = 20.0
	confluent.broker.registration.delay.ms = 0
	confluent.calling.resource.identity.type.map =
	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
	confluent.catalog.collector.enable = false
	confluent.catalog.collector.full.configs.enable = false
	confluent.catalog.collector.max.bytes.per.snapshot = 850000
	confluent.catalog.collector.max.topics.process = 500
	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
	confluent.catalog.collector.multitenant.topics.enable = true
	confluent.catalog.collector.snapshot.init.delay.sec = 60
	confluent.catalog.collector.snapshot.interval.sec = 300
	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
	confluent.cdc.api.keys.topic =
	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
	confluent.cdc.client.quotas.enable = false
	confluent.cdc.client.quotas.topic.name =
	confluent.cdc.lkc.metadata.topic =
	confluent.cdc.user.metadata.enable = false
	confluent.cdc.user.metadata.topic = _confluent-user_metadata
	confluent.cell.metrics.refresh.period.ms = 60000
	confluent.cells.default.size = 15
	confluent.cells.enable = false
	confluent.cells.implicit.creation.enable = false
	confluent.cells.k2.base.broker.index = -1
	confluent.cells.load.refresher.enable = true
	confluent.cells.max.size = 15
	confluent.cells.min.size = 6
	confluent.checksum.enabled.files = [none]
	confluent.client.topic.max.metrics.count = 1000
	confluent.client.topic.metrics.expiry.sec = 3600
	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
	confluent.clm.enabled = false
	confluent.clm.frequency.in.hours = 6
	confluent.clm.list.object.thread_pool.size = 1
	confluent.clm.max.backup.days = 3
	confluent.clm.min.delay.in.minutes = 30
	confluent.clm.thread.pool.size = 2
	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
	confluent.close.connections.on.credential.delete = false
	confluent.cluster.link.admin.max.in.flight.requests = 1000
	confluent.cluster.link.admin.request.batch.size = 1
	confluent.cluster.link.allow.config.providers = true
	confluent.cluster.link.allow.legacy.message.format = false
	confluent.cluster.link.allow.truncation.below.hwm = false
	confluent.cluster.link.availability.check.mode = ALL
	confluent.cluster.link.background.thread.affinity = LINK
	confluent.cluster.link.bootstrap.translation.feature.enable = true
	confluent.cluster.link.clients.max.idle.ms = 3153600000000
	confluent.cluster.link.enable = true
	confluent.cluster.link.enable.local.admin = false
	confluent.cluster.link.enable.metrics.reduction = false
	confluent.cluster.link.enable.metrics.reduction.advanced = false
	confluent.cluster.link.fetch.response.min.bytes = 1
	confluent.cluster.link.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.fetcher.auto.tune.enable = false
	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
	confluent.cluster.link.insync.fetch.response.min.bytes = 1
	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
	confluent.cluster.link.intranet.connectivity.enable = false
	confluent.cluster.link.intranet.connectivity.migration.enable = false
	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
	confluent.cluster.link.local.admin.multitenant.enable = false
	confluent.cluster.link.local.reverse.connection.listener.map = null
	confluent.cluster.link.max.client.connections = 2147483647
	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
	confluent.cluster.link.metadata.topic.enable = false
	confluent.cluster.link.metadata.topic.min.isr = 2
	confluent.cluster.link.metadata.topic.partitions = 50
	confluent.cluster.link.metadata.topic.replication.factor = 3
	confluent.cluster.link.mirror.transition.batch.size = 10
	confluent.cluster.link.num.background.threads = 1
	confluent.cluster.link.periodic.task.batch.size = 2147483647
	confluent.cluster.link.periodic.task.min.interval.ms = 1000
	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
	confluent.cluster.link.replica.fetch.connections.mode = combined
	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
	confluent.cluster.link.replication.quota.mode.per.tenant.overrides =
	confluent.cluster.link.replication.quota.window.num = 11
	confluent.cluster.link.replication.quota.window.size.seconds = 2
	confluent.cluster.link.request.quota.capacity = 400
	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
	confluent.cluster.link.switchover.disabled.principals = []
	confluent.cluster.link.switchover.enable = false
	confluent.cluster.link.switchover.listeners = []
	confluent.cluster.link.switchover.server.states = []
	confluent.cluster.link.tenant.replication.quota.enable = false
	confluent.cluster.link.tenant.request.quota.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
	confluent.cluster.metadata.snapshot.tier.upload.enable = false
	confluent.compacted.topic.prefer.tier.fetch.ms = -1
	confluent.connection.invalid.request.delay.enable = false
	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
	confluent.consumer.fetch.partition.pruning.enable = true
	confluent.consumer.lag.emitter.enabled = false
	confluent.consumer.lag.emitter.interval.ms = 60000
	confluent.dataflow.policy.watch.monitor.ms = 300000
	confluent.default.data.policy.enforcement = true
	confluent.defer.isr.shrink.enable = false
	confluent.describe.topic.partitions.enabled = true
	confluent.disk.io.manager.enable = false
	confluent.disk.throughput.headroom = 10485760
	confluent.disk.throughput.limit = 10485760000
	confluent.disk.throughput.quota.tier.archive = 1048576000
	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
	confluent.durability.audit.batch.flush.frequency.ms = 900000
	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
	confluent.durability.audit.enable = false
	confluent.durability.audit.idempotent.producer = false
	confluent.durability.audit.initial.job.delay.ms = 900000
	confluent.durability.audit.io.bytes.per.sec = 10485760
	confluent.durability.audit.log.ignored.event.types =
	confluent.durability.audit.reporting.batch.ms = 1800000
	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
	confluent.durability.topic.partition.count = 50
	confluent.durability.topic.replication.factor = 3
	confluent.e2e_checksum.protection.enabled = false
	confluent.e2e_checksum.protection.files = [none]
	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
	confluent.elastic.cku.enabled = false
	confluent.elastic.cku.scaletozero.enabled = false
	confluent.eligible.controllers = []
	confluent.enable.broker.reporting.min.usage.mode = true
	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.fail.unsatisfied.placement.constraints = false
	confluent.fetch.from.follower.require.leader.epoch.enable = false
	confluent.fetch.partition.pruning.enable = true
	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
	confluent.flexible.fanout.enabled = false
	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
	confluent.flexible.fanout.mode = TENANT_QUOTA
	confluent.floor.connection.rate.per.ip = -1.0
	confluent.floor.connection.rate.per.tenant = -1.0
	confluent.group.coordinator.dynamic.append.linger.enable = false
	confluent.group.coordinator.offsets.batching.enable = false
	confluent.group.coordinator.offsets.writer.threads = 2
	confluent.group.coordinator.txn.offset.validation.enable = false
	confluent.group.highest.offset.commit.rates.log.count = 10
	confluent.group.highest.offset.commit.rates.log.enable = false
	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
	confluent.group.metadata.load.threads = 32
	confluent.group.subscription.pattern.log.interval.ms = -1
	confluent.heap.tenured.notify.bytes = 0
	confluent.heap.tenured.notify.enabled = false
	confluent.hot.partition.ratio = 0.8
	confluent.http.server.start.timeout.ms = 60000
	confluent.http.server.stop.timeout.ms = 30000
	confluent.internal.metrics.enable = false
	confluent.internal.rest.server.bind.port = null
	confluent.internal.rest.server.ssl.enable = false
	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
	confluent.leader.epoch.checkpoint.checksum.enabled = false
	confluent.listener.protocol = TCP
	confluent.log.cleaner.timestamp.validation.enable = true
	confluent.log.placement.constraints =
	confluent.max.broker.load = 1.0
	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
	confluent.max.connection.rate.per.ip = -1.0
	confluent.max.connection.rate.per.tenant = -1.0
	confluent.max.connection.throttle.ms = null
	confluent.max.segment.ms = 9223372036854775807
	confluent.metadata.active.encryptor = null
	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
	confluent.metadata.encryptor.classes = null
	confluent.metadata.encryptor.required = false
	confluent.metadata.encryptor.secret.file = null
	confluent.metadata.encryptor.secrets = null
	confluent.metadata.jvm.warmup.ms = 60000
	confluent.metadata.leader.balance.slice.delay.ms = 100
	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
	confluent.metadata.max.leader.balance.changes.per.slice = 1000
	confluent.metadata.reject.when.throttled.enable = false
	confluent.metadata.server.cluster.registry.clusters = []
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.min.acks = 0
	confluent.min.connection.throttle.ms = 0
	confluent.min.segment.ms = 1
	confluent.missing.id.cache.ttl.sec = 60
	confluent.missing.id.query.range = 20000
	confluent.missing.schema.cache.ttl.sec = 60
	confluent.mtls.build.client.cert.chain.enable = false
	confluent.mtls.enable = false
	confluent.mtls.listener.name = EXTERNAL
	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
	confluent.mtls.truststore.manager.class.name = null
	confluent.multitenant.authorizer.enable.acl.state = false
	confluent.multitenant.interceptor.balancer.apis.enabled = false
	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
	confluent.multitenant.listener.names = null
	confluent.multitenant.parse.lkc.id.enable = false
	confluent.multitenant.parse.sni.host.name.enable = false
	confluent.network.health.manager.enabled = false
	confluent.network.health.manager.external.listener.name = EXTERNAL
	confluent.network.health.manager.externalconnectivitystartup.enabled = false
	confluent.network.health.manager.min.healthy.network.samples = 3
	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
	confluent.network.health.manager.mitigation.enabled = false
	confluent.network.health.manager.network.sample.window.size = 120
	confluent.network.health.manager.sample.duration.ms = 1000
	confluent.oauth.flat.networking.verification.enable = false
	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
	confluent.offsets.topic.placement.constraints =
	confluent.omit.network.processor.metric.tag = false
	confluent.operator.managed = false
	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings =
	confluent.ppv2.endpoint.scheme.enable = false
	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
	confluent.ppv2.endpoint.scheme.template.variable.cloud =
	confluent.ppv2.endpoint.scheme.template.variable.domain =
	confluent.ppv2.endpoint.scheme.template.variable.region =
	confluent.ppv2.endpoint.scheme.template.variables =
	confluent.ppv2.endpoint.scheme.templates =
	confluent.prefer.tier.fetch.ms = -1
	confluent.produce.throttle.pre.check.enable = false
	confluent.produce.throttle.pre.check.for.new.connection.enable = false
	confluent.producer.id.cache.broker.hard.limit = -1
	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
	confluent.producer.id.cache.extra.eviction.percentage = 0
	confluent.producer.id.cache.limit = 2147483647
	confluent.producer.id.cache.partition.hard.limit = -1
	confluent.producer.id.cache.tenant.hard.limit = -1
	confluent.producer.id.quota.manager.enable = false
	confluent.producer.id.quota.window.num = 11
	confluent.producer.id.quota.window.size.seconds = 1
	confluent.producer.id.throttle.enable = false
	confluent.producer.id.throttle.enable.threshold.percentage = 100
	confluent.proxy.mode.local.default = false
	confluent.proxy.protocol.fallback.enabled = false
	confluent.proxy.protocol.version = NONE
	confluent.quota.computing.usage.adjustment = 0.5
	confluent.quota.dynamic.adjustment.min.usage = 102400
	confluent.quota.dynamic.enable = false
	confluent.quota.dynamic.publishing.interval.ms = 60000
	confluent.quota.dynamic.reporting.interval.ms = 30000
	confluent.quota.tenant.broker.max.consumer.rate = 13107200
	confluent.quota.tenant.broker.max.producer.rate = 13107200
	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
	confluent.quota.tenant.fetch.multiplier = 1.0
	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
	confluent.quota.tenant.internal.throttling.enable = false
	confluent.quota.tenant.produce.multiplier = 1.0
	confluent.quota.tenant.user.quotas.enable = false
	confluent.rack.id.mapping = null
	confluent.regional.metadata.client.class = null
	confluent.regional.resource.manager.client.scheduler.threads = 2
	confluent.regional.resource.manager.endpoint = null
	confluent.regional.resource.manager.watch.endpoint = null
	confluent.replica.fetch.backoff.max.ms = 1000
	confluent.replica.fetch.connections.mode = combined
	confluent.replication.mode = PULL
	confluent.replication.push.feature.enable = false
	confluent.reporters.telemetry.auto.enable = true
	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
	confluent.request.pipelining.enable = true
	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
	confluent.require.calling.resource.identity = false
	confluent.require.compatible.keystore.updates = true
	confluent.require.confluent.issuer = false
	confluent.roll.check.interval.ms = 300000
	confluent.schema.registry.max.cache.size = 10000
	confluent.schema.registry.max.retries = 1
	confluent.schema.registry.retries.wait.ms = 0
	confluent.schema.registry.url = null
	confluent.schema.validation.context.name.enable = false
	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
	confluent.schema.validator.multitenant.enable = false
	confluent.schema.validator.samples.per.min = 0
	confluent.security.bc.approved.mode.enable = false
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.config =
	confluent.security.revoked.certificate.ids =
	confluent.segment.eager.roll.enable = false
	confluent.segment.speculative.prefetch.enable = false
	confluent.share.metadata.load.threads = 32
	confluent.spiffe.id.principal.extraction.rules =
	confluent.ssl.key.password = null
	confluent.ssl.keystore.location = null
	confluent.ssl.keystore.password = null
	confluent.ssl.keystore.type = null
	confluent.ssl.protocol = null
	confluent.ssl.truststore.location = null
	confluent.ssl.truststore.password = null
	confluent.ssl.truststore.type = null
	confluent.step.connection.rate.per.ip = -1.0
	confluent.step.connection.rate.per.tenant = -1.0
	confluent.storage.probe.period.ms = -1
	confluent.storage.probe.slow.write.threshold.ms = 5000
	confluent.stray.log.delete.delay.ms = 604800000
	confluent.stray.log.max.deletions.per.run = 72
	confluent.subdomain.prefix = null
	confluent.subdomain.separator.map = null
	confluent.subdomain.separator.variable = %sep
	confluent.system.time.roll.enable = false
	confluent.telemetry.enabled = false
	confluent.telemetry.external.client.metrics.delta.temporality = true
	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
	confluent.telemetry.external.client.metrics.push.enabled = false
	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
	confluent.telemetry.external.client.metrics.subscription.match.list = null
	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
	confluent.tenant.latency.metric.enabled = false
	confluent.tenantaware.encryption.key.manager.enable = false
	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
	confluent.tier.archiver.num.threads = 2
	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
	confluent.tier.azure.block.blob.container = null
	confluent.tier.azure.block.blob.cred.file.path = null
	confluent.tier.azure.block.blob.endpoint = null
	confluent.tier.azure.block.blob.prefix =
	confluent.tier.backend =
	confluent.tier.bucket.probe.period.ms = -1
	confluent.tier.cleaner.compact.min.efficiency = 0.5
	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
	confluent.tier.cleaner.dedupe.buffer.size = 134217728
	confluent.tier.cleaner.dual.compaction = false
	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
	confluent.tier.cleaner.dual.compaction.validation.percent = 0
	confluent.tier.cleaner.enable = false
	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
	confluent.tier.cleaner.feature.enable = false
	confluent.tier.cleaner.io.buffer.load.factor = 0.9
	confluent.tier.cleaner.io.buffer.size = 10485760
	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	confluent.tier.cleaner.min.cleanable.ratio = 0.75
	confluent.tier.cleaner.num.threads = 2
	confluent.tier.enable = false
	confluent.tier.feature = false
	confluent.tier.fenced.segment.delete.delay.ms = 600000
	confluent.tier.fetcher.async.enable = false
	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
	confluent.tier.fetcher.memorypool.bytes = 0
	confluent.tier.fetcher.num.threads = 4
	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
	confluent.tier.fetcher.offset.cache.period.ms = 60000
	confluent.tier.fetcher.offset.cache.size = 200000
	confluent.tier.gcs.bucket = null
	confluent.tier.gcs.cred.file.path = null
	confluent.tier.gcs.prefix =
	confluent.tier.gcs.region = null
	confluent.tier.gcs.sse.customer.encryption.key = null
	confluent.tier.gcs.write.chunk.size = 0
	confluent.tier.local.hotset.bytes = -1
	confluent.tier.local.hotset.ms = 86400000
	confluent.tier.max.partition.fetch.bytes.override = 0
	confluent.tier.metadata.bootstrap.servers = null
	confluent.tier.metadata.max.poll.ms = 100
	confluent.tier.metadata.namespace = null
	confluent.tier.metadata.num.partitions = 50
	confluent.tier.metadata.replication.factor = 3
	confluent.tier.metadata.request.timeout.ms = 30000
	confluent.tier.metadata.snapshots.enable = false
	confluent.tier.metadata.snapshots.interval.ms = 86400000
	confluent.tier.metadata.snapshots.retention.days = 7
	confluent.tier.metadata.snapshots.threads = 2
	confluent.tier.object.fetcher.num.threads = 1
	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
	confluent.tier.partition.state.cleanup.enable = false
	confluent.tier.partition.state.cleanup.interval.ms = 86400000
	confluent.tier.partition.state.commit.interval.ms = 15000
	confluent.tier.prefetch.cache.enable = false
	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
	confluent.tier.prefetch.cache.range.bytes = 5242880
	confluent.tier.prefetch.cache.total.size.bytes = 209715200
	confluent.tier.s3.assumerole.arn = null
	confluent.tier.s3.auto.abort.threshold.bytes = 500000
	confluent.tier.s3.aws.endpoint.override = null
	confluent.tier.s3.aws.signer.override = null
	confluent.tier.s3.bucket = null
	confluent.tier.s3.cred.file.path = null
	confluent.tier.s3.force.path.style.access = false
	confluent.tier.s3.ipv6.enabled = true
	confluent.tier.s3.prefix =
	confluent.tier.s3.region = null
	confluent.tier.s3.security.providers = null
	confluent.tier.s3.sse.algorithm = AES256
	confluent.tier.s3.sse.customer.encryption.key = null
	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.tier.s3.ssl.key.password = null
	confluent.tier.s3.ssl.keystore.location = null
	confluent.tier.s3.ssl.keystore.password = null
	confluent.tier.s3.ssl.keystore.type = null
	confluent.tier.s3.ssl.protocol = TLSv1.3
	confluent.tier.s3.ssl.provider = null
	confluent.tier.s3.ssl.truststore.location = null
	confluent.tier.s3.ssl.truststore.password = null
	confluent.tier.s3.ssl.truststore.type = null
	confluent.tier.s3.storage.class.override =
	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
	confluent.tier.s3.v2.enabled = false
	confluent.tier.segment.hotset.roll.min.bytes = 104857600
	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
	confluent.tier.topic.data.loss.validation.fencing.enable = false
	confluent.tier.topic.delete.backoff.ms = 21600000
	confluent.tier.topic.delete.check.interval.ms = 300000
	confluent.tier.topic.delete.max.inprogress.partitions = 100
	confluent.tier.topic.head.data.loss.validation.enable = true
	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
	confluent.tier.topic.materialization.from.snapshot.enable = false
	confluent.tier.topic.producer.enable.idempotence = true
	confluent.tier.topic.snapshots.enable = false
	confluent.tier.topic.snapshots.interval.ms = 300000
	confluent.tier.topic.snapshots.max.records = 100000
	confluent.tier.topic.snapshots.retention.hours = 168
	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
	confluent.topic.partition.default.placement = 2
	confluent.topic.policy.use.computed.assignments = false
	confluent.topic.replica.assignor.builder.class =
	confluent.track.api.key.per.ip = false
	confluent.track.per.ip.max.size = 100000
	confluent.track.tenant.id.per.ip = false
	confluent.traffic.cdc.network.id.routes.enable = false
	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
	confluent.traffic.network.id =
	confluent.traffic.network.type =
	confluent.transaction.2pc.timeout.ms = -1
	confluent.transaction.logging.verbosity = 0
	confluent.transaction.state.log.placement.constraints =
	confluent.unique.deprecated.request.metrics.per.tenant = 1000
	confluent.valid.broker.rack.set = null
	confluent.valid.sni.hostnames =
	confluent.valid.sni.hostnames.exclude.suffix =
	confluent.verify.group.subscription.prefix = false
	confluent.virtual.topic.creation.enabled = false
	confluent.zone.tagged.request.metrics.enable = false
	connection.failed.authentication.delay.ms = 100
	connection.min.expire.interval.ms = 250
	connections.max.age.ms = 3153600000000
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@kafka:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.cluster.link.policy.class.name = null
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	enable.fips = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	floor.max.connection.creation.rate = null
	follower.replication.throttled.rate = 9223372036854775807
	follower.replication.throttled.replicas = none
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = SASL_PLAINTEXT
	k2.stack.builder.class.name = null
	k2.startup.timeout.ms = 60000
	k2.topic.metadata.refresh.ms = 10000
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.replication.throttled.rate = 9223372036854775807
	leader.replication.throttled.replicas = none
	listener.security.protocol.map = SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:PLAINTEXT
	listeners = SASL_PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.hash.algorithm = MD5
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.cleanup.policy.empty.validation = none
	log.deletion.max.segments.per.run = 2147483647
	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 1.7976931348623157E308
	max.connection.creation.rate.per.ip.enable.threshold = 0.0
	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.connections.per.tenant = 0
	max.connections.protected.listeners = []
	max.connections.reap.amount = 0
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	multitenant.authorizer.support.resource.ids = false
	multitenant.metadata.class = null
	multitenant.metadata.dir = null
	multitenant.metadata.reload.delay.ms = 120000
	multitenant.metadata.ssl.certs.path = null
	multitenant.tenant.delete.batch.size = 10
	multitenant.tenant.delete.check.ms = 120000
	multitenant.tenant.delete.delay = 604800000
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	otel.exporter.otlp.custom.endpoint = default
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	quotas.consumption.expiration.time.ms = 600000
	quotas.expiration.interval.ms = 3600000
	quotas.expiration.time.ms = 604800000
	quotas.lazy.evaluation.threshold = 0.5
	quotas.topic.append.timeout.ms = 5000
	quotas.topic.compression.codec = 3
	quotas.topic.load.buffer.size = 5242880
	quotas.topic.num.partitions = 50
	quotas.topic.placement.constraints =
	quotas.topic.replication.factor = 3
	quotas.topic.segment.bytes = 104857600
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [PLAIN]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.authn.async.enable = false
	sasl.server.authn.async.max.threads = 1
	sasl.server.authn.async.timeout.ms = 30000
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	throughput.quota.window.num = 11
	token.impersonation.validation = true
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.metadata.load.threads = 32
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,315] INFO KafkaConfig values:
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = SASL_PLAINTEXT://kafka:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
	broker.rack = null
	broker.session.timeout.ms = 9000
	broker.session.uuid = 2yBYTgb0Tf6Hp4Sp67hPyg
	client.quota.callback.class = null
	client.quota.max.throttle.time.in.response.ms = 60000
	client.quota.max.throttle.time.ms = 5000
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	confluent.accp.enabled = false
	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
	confluent.alter.broker.health.max.demoted.brokers = 2147483647
	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
	confluent.ansible.managed = false
	confluent.api.visibility = DEFAULT
	confluent.append.record.interceptor.classes = []
	confluent.apply.create.topic.policy.to.create.partitions = false
	confluent.authorizer.authority.name =
	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
	confluent.backpressure.disk.enable = false
	confluent.backpressure.disk.free.threshold.bytes = 21474836480
	confluent.backpressure.disk.produce.bytes.per.second = 131072
	confluent.backpressure.disk.threshold.recovery.factor = 1.5
	confluent.backpressure.request.min.broker.limit = 200
	confluent.backpressure.request.queue.size.percentile = p95
	confluent.backpressure.types = null
	confluent.balancer.api.state.topic = _confluent_balancer_api_state
	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
	confluent.balancer.capacity.threshold.upper.limit = 0.95
	confluent.balancer.cell.load.upper.bound = 0.7
	confluent.balancer.cell.overload.detection.interval.ms = 3600000
	confluent.balancer.cell.overload.duration.ms = 86400000
	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.cpu.balance.threshold = 1.1
	confluent.balancer.cpu.goal.act.as.capacity.goal = false
	confluent.balancer.cpu.low.utilization.threshold = 0.2
	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
	confluent.balancer.disk.max.load = 0.85
	confluent.balancer.disk.min.free.space.gb = 0
	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
	confluent.balancer.disk.utilization.detector.duration.ms = 600000
	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
	confluent.balancer.enable = true
	confluent.balancer.enable.network.capacity.metric.ingestion = false
	confluent.balancer.exclude.topic.names = []
	confluent.balancer.exclude.topic.prefixes = []
	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	confluent.balancer.incremental.balancing.enabled = false
	confluent.balancer.incremental.balancing.goals = []
	confluent.balancer.incremental.balancing.lower.bound = 0.02
	confluent.balancer.incremental.balancing.min.valid.windows = 5
	confluent.balancer.incremental.balancing.step.ratio = 0.2
	confluent.balancer.inter.cell.balancing.enabled = false
	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
	confluent.balancer.max.replicas = 2147483647
	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.rebalancing.goals = []
	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.resource.utilization.detector.interval.ms = 60000
	confluent.balancer.sbc.metrics.parser.enabled = false
	confluent.balancer.self.healing.maximum.rounds = 1
	confluent.balancer.task.history.retention.days = 30
	confluent.balancer.tenant.maximum.movements = 0
	confluent.balancer.tenant.suspension.ms = 86400000
	confluent.balancer.throttle.bytes.per.second = 10485760
	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
	confluent.balancer.topic.partition.maximum.movements = 3
	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
	confluent.balancer.topic.partition.movements.history.limit = 900
	confluent.balancer.topic.partition.suspension.ms = 3600000
	confluent.balancer.topic.replication.factor = 1
	confluent.balancer.triggering.goals = []
	confluent.balancer.v2.addition.enabled = false
	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
	confluent.balancer.v2.executor.enabled = false
	confluent.basic.auth.credentials.source = null
	confluent.basic.auth.user.info = null
	confluent.bearer.assertion.claim.aud = null
	confluent.bearer.assertion.claim.exp.minutes = null
	confluent.bearer.assertion.claim.iss = null
	confluent.bearer.assertion.claim.jti.include = null
	confluent.bearer.assertion.claim.nbf.include = null
	confluent.bearer.assertion.claim.sub = null
	confluent.bearer.assertion.file = null
	confluent.bearer.assertion.private.key.file = null
	confluent.bearer.assertion.private.key.passphrase = null
	confluent.bearer.assertion.template.file = null
	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
	confluent.bearer.auth.client.id = null
	confluent.bearer.auth.client.secret = null
	confluent.bearer.auth.credentials.source = null
	confluent.bearer.auth.identity.pool.id = null
	confluent.bearer.auth.issuer.endpoint.url = null
	confluent.bearer.auth.logical.cluster = null
	confluent.bearer.auth.scope = null
	confluent.bearer.auth.scope.claim.name = scope
	confluent.bearer.auth.sub.claim.name = sub
	confluent.bearer.auth.token = null
	confluent.broker.health.manager.enabled = true
	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
	confluent.broker.health.manager.hard.kill.duration.ms = 60000
	confluent.broker.health.manager.mitigation.enabled = false
	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
	confluent.broker.health.manager.sample.duration.ms = 1000
	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
	confluent.broker.load.advertised.limit.load = 0.8
	confluent.broker.load.average.service.request.time.ms = 0.1
	confluent.broker.load.delay.metric.start.ms = 180000
	confluent.broker.load.enabled = false
	confluent.broker.load.num.samples = 60
	confluent.broker.load.tenant.metric.enable = false
	confluent.broker.load.update.metric.tags.interval.ms = 60000
	confluent.broker.load.window.size.ms = 60000
	confluent.broker.load.workload.coefficient = 20.0
	confluent.broker.registration.delay.ms = 0
	confluent.calling.resource.identity.type.map =
	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
	confluent.catalog.collector.enable = false
	confluent.catalog.collector.full.configs.enable = false
	confluent.catalog.collector.max.bytes.per.snapshot = 850000
	confluent.catalog.collector.max.topics.process = 500
	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
	confluent.catalog.collector.multitenant.topics.enable = true
	confluent.catalog.collector.snapshot.init.delay.sec = 60
	confluent.catalog.collector.snapshot.interval.sec = 300
	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
	confluent.cdc.api.keys.topic =
	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
	confluent.cdc.client.quotas.enable = false
	confluent.cdc.client.quotas.topic.name =
	confluent.cdc.lkc.metadata.topic =
	confluent.cdc.user.metadata.enable = false
	confluent.cdc.user.metadata.topic = _confluent-user_metadata
	confluent.cell.metrics.refresh.period.ms = 60000
	confluent.cells.default.size = 15
	confluent.cells.enable = false
	confluent.cells.implicit.creation.enable = false
	confluent.cells.k2.base.broker.index = -1
	confluent.cells.load.refresher.enable = true
	confluent.cells.max.size = 15
	confluent.cells.min.size = 6
	confluent.checksum.enabled.files = [none]
	confluent.client.topic.max.metrics.count = 1000
	confluent.client.topic.metrics.expiry.sec = 3600
	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
	confluent.clm.enabled = false
	confluent.clm.frequency.in.hours = 6
	confluent.clm.list.object.thread_pool.size = 1
	confluent.clm.max.backup.days = 3
	confluent.clm.min.delay.in.minutes = 30
	confluent.clm.thread.pool.size = 2
	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
	confluent.close.connections.on.credential.delete = false
	confluent.cluster.link.admin.max.in.flight.requests = 1000
	confluent.cluster.link.admin.request.batch.size = 1
	confluent.cluster.link.allow.config.providers = true
	confluent.cluster.link.allow.legacy.message.format = false
	confluent.cluster.link.allow.truncation.below.hwm = false
	confluent.cluster.link.availability.check.mode = ALL
	confluent.cluster.link.background.thread.affinity = LINK
	confluent.cluster.link.bootstrap.translation.feature.enable = true
	confluent.cluster.link.clients.max.idle.ms = 3153600000000
	confluent.cluster.link.enable = true
	confluent.cluster.link.enable.local.admin = false
	confluent.cluster.link.enable.metrics.reduction = false
	confluent.cluster.link.enable.metrics.reduction.advanced = false
	confluent.cluster.link.fetch.response.min.bytes = 1
	confluent.cluster.link.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.fetcher.auto.tune.enable = false
	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
	confluent.cluster.link.insync.fetch.response.min.bytes = 1
	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
	confluent.cluster.link.intranet.connectivity.enable = false
	confluent.cluster.link.intranet.connectivity.migration.enable = false
	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
	confluent.cluster.link.local.admin.multitenant.enable = false
	confluent.cluster.link.local.reverse.connection.listener.map = null
	confluent.cluster.link.max.client.connections = 2147483647
	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
	confluent.cluster.link.metadata.topic.enable = false
	confluent.cluster.link.metadata.topic.min.isr = 2
	confluent.cluster.link.metadata.topic.partitions = 50
	confluent.cluster.link.metadata.topic.replication.factor = 3
	confluent.cluster.link.mirror.transition.batch.size = 10
	confluent.cluster.link.num.background.threads = 1
	confluent.cluster.link.periodic.task.batch.size = 2147483647
	confluent.cluster.link.periodic.task.min.interval.ms = 1000
	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
	confluent.cluster.link.replica.fetch.connections.mode = combined
	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
	confluent.cluster.link.replication.quota.mode.per.tenant.overrides =
	confluent.cluster.link.replication.quota.window.num = 11
	confluent.cluster.link.replication.quota.window.size.seconds = 2
	confluent.cluster.link.request.quota.capacity = 400
	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
	confluent.cluster.link.switchover.disabled.principals = []
	confluent.cluster.link.switchover.enable = false
	confluent.cluster.link.switchover.listeners = []
	confluent.cluster.link.switchover.server.states = []
	confluent.cluster.link.tenant.replication.quota.enable = false
	confluent.cluster.link.tenant.request.quota.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
	confluent.cluster.metadata.snapshot.tier.upload.enable = false
	confluent.compacted.topic.prefer.tier.fetch.ms = -1
	confluent.connection.invalid.request.delay.enable = false
	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
	confluent.consumer.fetch.partition.pruning.enable = true
	confluent.consumer.lag.emitter.enabled = false
	confluent.consumer.lag.emitter.interval.ms = 60000
	confluent.dataflow.policy.watch.monitor.ms = 300000
	confluent.default.data.policy.enforcement = true
	confluent.defer.isr.shrink.enable = false
	confluent.describe.topic.partitions.enabled = true
	confluent.disk.io.manager.enable = false
	confluent.disk.throughput.headroom = 10485760
	confluent.disk.throughput.limit = 10485760000
	confluent.disk.throughput.quota.tier.archive = 1048576000
	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
	confluent.durability.audit.batch.flush.frequency.ms = 900000
	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
	confluent.durability.audit.enable = false
	confluent.durability.audit.idempotent.producer = false
	confluent.durability.audit.initial.job.delay.ms = 900000
	confluent.durability.audit.io.bytes.per.sec = 10485760
	confluent.durability.audit.log.ignored.event.types =
	confluent.durability.audit.reporting.batch.ms = 1800000
	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
	confluent.durability.topic.partition.count = 50
	confluent.durability.topic.replication.factor = 3
	confluent.e2e_checksum.protection.enabled = false
	confluent.e2e_checksum.protection.files = [none]
	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
	confluent.elastic.cku.enabled = false
	confluent.elastic.cku.scaletozero.enabled = false
	confluent.eligible.controllers = []
	confluent.enable.broker.reporting.min.usage.mode = true
	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.fail.unsatisfied.placement.constraints = false
	confluent.fetch.from.follower.require.leader.epoch.enable = false
	confluent.fetch.partition.pruning.enable = true
	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
	confluent.flexible.fanout.enabled = false
	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
	confluent.flexible.fanout.mode = TENANT_QUOTA
	confluent.floor.connection.rate.per.ip = -1.0
	confluent.floor.connection.rate.per.tenant = -1.0
	confluent.group.coordinator.dynamic.append.linger.enable = false
	confluent.group.coordinator.offsets.batching.enable = false
	confluent.group.coordinator.offsets.writer.threads = 2
	confluent.group.coordinator.txn.offset.validation.enable = false
	confluent.group.highest.offset.commit.rates.log.count = 10
	confluent.group.highest.offset.commit.rates.log.enable = false
	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
	confluent.group.metadata.load.threads = 32
	confluent.group.subscription.pattern.log.interval.ms = -1
	confluent.heap.tenured.notify.bytes = 0
	confluent.heap.tenured.notify.enabled = false
	confluent.hot.partition.ratio = 0.8
	confluent.http.server.start.timeout.ms = 60000
	confluent.http.server.stop.timeout.ms = 30000
	confluent.internal.metrics.enable = false
	confluent.internal.rest.server.bind.port = null
	confluent.internal.rest.server.ssl.enable = false
	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
	confluent.leader.epoch.checkpoint.checksum.enabled = false
	confluent.listener.protocol = TCP
	confluent.log.cleaner.timestamp.validation.enable = true
	confluent.log.placement.constraints =
	confluent.max.broker.load = 1.0
	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
	confluent.max.connection.rate.per.ip = -1.0
	confluent.max.connection.rate.per.tenant = -1.0
	confluent.max.connection.throttle.ms = null
	confluent.max.segment.ms = 9223372036854775807
	confluent.metadata.active.encryptor = null
	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
	confluent.metadata.encryptor.classes = null
	confluent.metadata.encryptor.required = false
	confluent.metadata.encryptor.secret.file = null
	confluent.metadata.encryptor.secrets = null
	confluent.metadata.jvm.warmup.ms = 60000
	confluent.metadata.leader.balance.slice.delay.ms = 100
	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
	confluent.metadata.max.leader.balance.changes.per.slice = 1000
	confluent.metadata.reject.when.throttled.enable = false
	confluent.metadata.server.cluster.registry.clusters = []
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.min.acks = 0
	confluent.min.connection.throttle.ms = 0
	confluent.min.segment.ms = 1
	confluent.missing.id.cache.ttl.sec = 60
	confluent.missing.id.query.range = 20000
	confluent.missing.schema.cache.ttl.sec = 60
	confluent.mtls.build.client.cert.chain.enable = false
	confluent.mtls.enable = false
	confluent.mtls.listener.name = EXTERNAL
	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
	confluent.mtls.truststore.manager.class.name = null
	confluent.multitenant.authorizer.enable.acl.state = false
	confluent.multitenant.interceptor.balancer.apis.enabled = false
	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
	confluent.multitenant.listener.names = null
	confluent.multitenant.parse.lkc.id.enable = false
	confluent.multitenant.parse.sni.host.name.enable = false
	confluent.network.health.manager.enabled = false
	confluent.network.health.manager.external.listener.name = EXTERNAL
	confluent.network.health.manager.externalconnectivitystartup.enabled = false
	confluent.network.health.manager.min.healthy.network.samples = 3
	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
	confluent.network.health.manager.mitigation.enabled = false
	confluent.network.health.manager.network.sample.window.size = 120
	confluent.network.health.manager.sample.duration.ms = 1000
	confluent.oauth.flat.networking.verification.enable = false
	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
	confluent.offsets.topic.placement.constraints =
	confluent.omit.network.processor.metric.tag = false
	confluent.operator.managed = false
	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings =
	confluent.ppv2.endpoint.scheme.enable = false
	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
	confluent.ppv2.endpoint.scheme.template.variable.cloud =
	confluent.ppv2.endpoint.scheme.template.variable.domain =
	confluent.ppv2.endpoint.scheme.template.variable.region =
	confluent.ppv2.endpoint.scheme.template.variables =
	confluent.ppv2.endpoint.scheme.templates =
	confluent.prefer.tier.fetch.ms = -1
	confluent.produce.throttle.pre.check.enable = false
	confluent.produce.throttle.pre.check.for.new.connection.enable = false
	confluent.producer.id.cache.broker.hard.limit = -1
	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
	confluent.producer.id.cache.extra.eviction.percentage = 0
	confluent.producer.id.cache.limit = 2147483647
	confluent.producer.id.cache.partition.hard.limit = -1
	confluent.producer.id.cache.tenant.hard.limit = -1
	confluent.producer.id.quota.manager.enable = false
	confluent.producer.id.quota.window.num = 11
	confluent.producer.id.quota.window.size.seconds = 1
	confluent.producer.id.throttle.enable = false
	confluent.producer.id.throttle.enable.threshold.percentage = 100
	confluent.proxy.mode.local.default = false
	confluent.proxy.protocol.fallback.enabled = false
	confluent.proxy.protocol.version = NONE
	confluent.quota.computing.usage.adjustment = 0.5
	confluent.quota.dynamic.adjustment.min.usage = 102400
	confluent.quota.dynamic.enable = false
	confluent.quota.dynamic.publishing.interval.ms = 60000
	confluent.quota.dynamic.reporting.interval.ms = 30000
	confluent.quota.tenant.broker.max.consumer.rate = 13107200
	confluent.quota.tenant.broker.max.producer.rate = 13107200
	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
	confluent.quota.tenant.fetch.multiplier = 1.0
	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
	confluent.quota.tenant.internal.throttling.enable = false
	confluent.quota.tenant.produce.multiplier = 1.0
	confluent.quota.tenant.user.quotas.enable = false
	confluent.rack.id.mapping = null
	confluent.regional.metadata.client.class = null
	confluent.regional.resource.manager.client.scheduler.threads = 2
	confluent.regional.resource.manager.endpoint = null
	confluent.regional.resource.manager.watch.endpoint = null
	confluent.replica.fetch.backoff.max.ms = 1000
	confluent.replica.fetch.connections.mode = combined
	confluent.replication.mode = PULL
	confluent.replication.push.feature.enable = false
	confluent.reporters.telemetry.auto.enable = true
	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
	confluent.request.pipelining.enable = true
	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
	confluent.require.calling.resource.identity = false
	confluent.require.compatible.keystore.updates = true
	confluent.require.confluent.issuer = false
	confluent.roll.check.interval.ms = 300000
	confluent.schema.registry.max.cache.size = 10000
	confluent.schema.registry.max.retries = 1
	confluent.schema.registry.retries.wait.ms = 0
	confluent.schema.registry.url = null
	confluent.schema.validation.context.name.enable = false
	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
	confluent.schema.validator.multitenant.enable = false
	confluent.schema.validator.samples.per.min = 0
	confluent.security.bc.approved.mode.enable = false
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.config =
	confluent.security.revoked.certificate.ids =
	confluent.segment.eager.roll.enable = false
	confluent.segment.speculative.prefetch.enable = false
	confluent.share.metadata.load.threads = 32
	confluent.spiffe.id.principal.extraction.rules =
	confluent.ssl.key.password = null
	confluent.ssl.keystore.location = null
	confluent.ssl.keystore.password = null
	confluent.ssl.keystore.type = null
	confluent.ssl.protocol = null
	confluent.ssl.truststore.location = null
	confluent.ssl.truststore.password = null
	confluent.ssl.truststore.type = null
	confluent.step.connection.rate.per.ip = -1.0
	confluent.step.connection.rate.per.tenant = -1.0
	confluent.storage.probe.period.ms = -1
	confluent.storage.probe.slow.write.threshold.ms = 5000
	confluent.stray.log.delete.delay.ms = 604800000
	confluent.stray.log.max.deletions.per.run = 72
	confluent.subdomain.prefix = null
	confluent.subdomain.separator.map = null
	confluent.subdomain.separator.variable = %sep
	confluent.system.time.roll.enable = false
	confluent.telemetry.enabled = false
	confluent.telemetry.external.client.metrics.delta.temporality = true
	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
	confluent.telemetry.external.client.metrics.push.enabled = false
	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
	confluent.telemetry.external.client.metrics.subscription.match.list = null
	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
	confluent.tenant.latency.metric.enabled = false
	confluent.tenantaware.encryption.key.manager.enable = false
	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
	confluent.tier.archiver.num.threads = 2
	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
	confluent.tier.azure.block.blob.container = null
	confluent.tier.azure.block.blob.cred.file.path = null
	confluent.tier.azure.block.blob.endpoint = null
	confluent.tier.azure.block.blob.prefix =
	confluent.tier.backend =
	confluent.tier.bucket.probe.period.ms = -1
	confluent.tier.cleaner.compact.min.efficiency = 0.5
	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
	confluent.tier.cleaner.dedupe.buffer.size = 134217728
	confluent.tier.cleaner.dual.compaction = false
	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
	confluent.tier.cleaner.dual.compaction.validation.percent = 0
	confluent.tier.cleaner.enable = false
	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
	confluent.tier.cleaner.feature.enable = false
	confluent.tier.cleaner.io.buffer.load.factor = 0.9
	confluent.tier.cleaner.io.buffer.size = 10485760
	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	confluent.tier.cleaner.min.cleanable.ratio = 0.75
	confluent.tier.cleaner.num.threads = 2
	confluent.tier.enable = false
	confluent.tier.feature = false
	confluent.tier.fenced.segment.delete.delay.ms = 600000
	confluent.tier.fetcher.async.enable = false
	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
	confluent.tier.fetcher.memorypool.bytes = 0
	confluent.tier.fetcher.num.threads = 4
	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
	confluent.tier.fetcher.offset.cache.period.ms = 60000
	confluent.tier.fetcher.offset.cache.size = 200000
	confluent.tier.gcs.bucket = null
	confluent.tier.gcs.cred.file.path = null
	confluent.tier.gcs.prefix =
	confluent.tier.gcs.region = null
	confluent.tier.gcs.sse.customer.encryption.key = null
	confluent.tier.gcs.write.chunk.size = 0
	confluent.tier.local.hotset.bytes = -1
	confluent.tier.local.hotset.ms = 86400000
	confluent.tier.max.partition.fetch.bytes.override = 0
	confluent.tier.metadata.bootstrap.servers = null
	confluent.tier.metadata.max.poll.ms = 100
	confluent.tier.metadata.namespace = null
	confluent.tier.metadata.num.partitions = 50
	confluent.tier.metadata.replication.factor = 3
	confluent.tier.metadata.request.timeout.ms = 30000
	confluent.tier.metadata.snapshots.enable = false
	confluent.tier.metadata.snapshots.interval.ms = 86400000
	confluent.tier.metadata.snapshots.retention.days = 7
	confluent.tier.metadata.snapshots.threads = 2
	confluent.tier.object.fetcher.num.threads = 1
	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
	confluent.tier.partition.state.cleanup.enable = false
	confluent.tier.partition.state.cleanup.interval.ms = 86400000
	confluent.tier.partition.state.commit.interval.ms = 15000
	confluent.tier.prefetch.cache.enable = false
	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
	confluent.tier.prefetch.cache.range.bytes = 5242880
	confluent.tier.prefetch.cache.total.size.bytes = 209715200
	confluent.tier.s3.assumerole.arn = null
	confluent.tier.s3.auto.abort.threshold.bytes = 500000
	confluent.tier.s3.aws.endpoint.override = null
	confluent.tier.s3.aws.signer.override = null
	confluent.tier.s3.bucket = null
	confluent.tier.s3.cred.file.path = null
	confluent.tier.s3.force.path.style.access = false
	confluent.tier.s3.ipv6.enabled = true
	confluent.tier.s3.prefix =
	confluent.tier.s3.region = null
	confluent.tier.s3.security.providers = null
	confluent.tier.s3.sse.algorithm = AES256
	confluent.tier.s3.sse.customer.encryption.key = null
	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.tier.s3.ssl.key.password = null
	confluent.tier.s3.ssl.keystore.location = null
	confluent.tier.s3.ssl.keystore.password = null
	confluent.tier.s3.ssl.keystore.type = null
	confluent.tier.s3.ssl.protocol = TLSv1.3
	confluent.tier.s3.ssl.provider = null
	confluent.tier.s3.ssl.truststore.location = null
	confluent.tier.s3.ssl.truststore.password = null
	confluent.tier.s3.ssl.truststore.type = null
	confluent.tier.s3.storage.class.override =
	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
	confluent.tier.s3.v2.enabled = false
	confluent.tier.segment.hotset.roll.min.bytes = 104857600
	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
	confluent.tier.topic.data.loss.validation.fencing.enable = false
	confluent.tier.topic.delete.backoff.ms = 21600000
	confluent.tier.topic.delete.check.interval.ms = 300000
	confluent.tier.topic.delete.max.inprogress.partitions = 100
	confluent.tier.topic.head.data.loss.validation.enable = true
	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
	confluent.tier.topic.materialization.from.snapshot.enable = false
	confluent.tier.topic.producer.enable.idempotence = true
	confluent.tier.topic.snapshots.enable = false
	confluent.tier.topic.snapshots.interval.ms = 300000
	confluent.tier.topic.snapshots.max.records = 100000
	confluent.tier.topic.snapshots.retention.hours = 168
	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
	confluent.topic.partition.default.placement = 2
	confluent.topic.policy.use.computed.assignments = false
	confluent.topic.replica.assignor.builder.class =
	confluent.track.api.key.per.ip = false
	confluent.track.per.ip.max.size = 100000
	confluent.track.tenant.id.per.ip = false
	confluent.traffic.cdc.network.id.routes.enable = false
	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
	confluent.traffic.network.id =
	confluent.traffic.network.type =
	confluent.transaction.2pc.timeout.ms = -1
	confluent.transaction.logging.verbosity = 0
	confluent.transaction.state.log.placement.constraints =
	confluent.unique.deprecated.request.metrics.per.tenant = 1000
	confluent.valid.broker.rack.set = null
	confluent.valid.sni.hostnames =
	confluent.valid.sni.hostnames.exclude.suffix =
	confluent.verify.group.subscription.prefix = false
	confluent.virtual.topic.creation.enabled = false
	confluent.zone.tagged.request.metrics.enable = false
	connection.failed.authentication.delay.ms = 100
	connection.min.expire.interval.ms = 250
	connections.max.age.ms = 3153600000000
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@kafka:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.cluster.link.policy.class.name = null
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	enable.fips = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	floor.max.connection.creation.rate = null
	follower.replication.throttled.rate = 9223372036854775807
	follower.replication.throttled.replicas = none
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = SASL_PLAINTEXT
	k2.stack.builder.class.name = null
	k2.startup.timeout.ms = 60000
	k2.topic.metadata.refresh.ms = 10000
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.replication.throttled.rate = 9223372036854775807
	leader.replication.throttled.replicas = none
	listener.security.protocol.map = SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:PLAINTEXT
	listeners = SASL_PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.hash.algorithm = MD5
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.cleanup.policy.empty.validation = none
	log.deletion.max.segments.per.run = 2147483647
	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 1.7976931348623157E308
	max.connection.creation.rate.per.ip.enable.threshold = 0.0
	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.connections.per.tenant = 0
	max.connections.protected.listeners = []
	max.connections.reap.amount = 0
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	multitenant.authorizer.support.resource.ids = false
	multitenant.metadata.class = null
	multitenant.metadata.dir = null
	multitenant.metadata.reload.delay.ms = 120000
	multitenant.metadata.ssl.certs.path = null
	multitenant.tenant.delete.batch.size = 10
	multitenant.tenant.delete.check.ms = 120000
	multitenant.tenant.delete.delay = 604800000
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	otel.exporter.otlp.custom.endpoint = default
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	quotas.consumption.expiration.time.ms = 600000
	quotas.expiration.interval.ms = 3600000
	quotas.expiration.time.ms = 604800000
	quotas.lazy.evaluation.threshold = 0.5
	quotas.topic.append.timeout.ms = 5000
	quotas.topic.compression.codec = 3
	quotas.topic.load.buffer.size = 5242880
	quotas.topic.num.partitions = 50
	quotas.topic.placement.constraints =
	quotas.topic.replication.factor = 3
	quotas.topic.segment.bytes = 104857600
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [PLAIN]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.authn.async.enable = false
	sasl.server.authn.async.max.threads = 1
	sasl.server.authn.async.timeout.ms = 30000
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	throughput.quota.window.num = 11
	token.impersonation.validation = true
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.metadata.load.threads = 32
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,334] INFO Registering metric ActiveBalancerCount (io.confluent.databalancer.KafkaDataBalanceManager)
[2025-07-23 11:50:57,358] INFO Instantiating ClusterBalanceManager with an instance of io.confluent.databalancer.SbcDataBalanceManager (ClusterBalanceManager)
[2025-07-23 11:50:57,360] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-07-23 11:50:57,362] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
[2025-07-23 11:50:57,362] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
[2025-07-23 11:50:57,365] INFO [ControllerServer id=1] FIPS mode enabled: false (kafka.server.ControllerServer)
[2025-07-23 11:50:57,365] INFO [ControllerServer id=1] FIPS mode enabled: false (kafka.server.ControllerServer)
[2025-07-23 11:50:57,371] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,372] INFO CrnAuthorityConfig values:
	confluent.authorizer.authority.cache.entries = 10000
	confluent.authorizer.authority.name =
	confluent.metadata.server.api.flavor = CP
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,373] INFO NamedConfigEnabled: false (io.confluent.security.audit.provider.ConfluentAuditLogProvider)
[2025-07-23 11:50:57,373] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,384] INFO CrnAuthorityConfig values:
	confluent.authorizer.authority.cache.entries = 10000
	confluent.authorizer.authority.name =
	confluent.metadata.server.api.flavor = CP
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,384] INFO MultiTenantAuditLogConfig values:
	confluent.security.event.logger.client.ip.enable = false
	confluent.security.event.logger.multitenant.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,385] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,385] INFO Audit Log rate limiter reconfigured: Authn: -1, Authz: -1, Kafka request: -1 (io.confluent.security.audit.provider.AuditLogRateLimiter)
[2025-07-23 11:50:57,483] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Creating data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-07-23 11:50:57,483] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Creating data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-07-23 11:50:57,492] INFO Quota CONTROLLER-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
[2025-07-23 11:50:57,492] INFO Quota CONTROLLER-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
[2025-07-23 11:50:57,493] INFO Quota CONTROLLER-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
[2025-07-23 11:50:57,493] INFO Quota CONTROLLER-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
[2025-07-23 11:50:57,493] INFO Quota CONTROLLER-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
[2025-07-23 11:50:57,493] INFO Quota CONTROLLER-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
[2025-07-23 11:50:57,495] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
[2025-07-23 11:50:57,495] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
[2025-07-23 11:50:57,511] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,523] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,525] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,527] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) used TCP protocol (kafka.network.SocketServer)
[2025-07-23 11:50:57,527] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) used TCP protocol (kafka.network.SocketServer)
[2025-07-23 11:50:57,529] INFO CONTROLLER: resolved wildcard host to kafka (org.apache.kafka.metadata.ListenerInfo)
[2025-07-23 11:50:57,536] INFO [SharedServer id=1] Using kafka:9092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
[2025-07-23 11:50:57,536] INFO [SharedServer id=1] Using kafka:9092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
[2025-07-23 11:50:57,545] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
[2025-07-23 11:50:57,545] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
[2025-07-23 11:50:57,623] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:50:57,623] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:50:57,623] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset $lastOffset (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:50:57,631] INFO Initialized snapshots with IDs SortedSet() from /var/lib/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-07-23 11:50:57,631] INFO Initialized snapshots with IDs SortedSet() from /var/lib/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-07-23 11:50:57,648] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-07-23 11:50:57,648] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-07-23 11:50:57,660] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
[2025-07-23 11:50:57,662] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=kafka/192.168.128.3:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
[2025-07-23 11:50:57,662] INFO [RaftManager id=1] Starting request manager with static voters: [kafka:9093 (id: 1 rack: null isFenced: false)] (org.apache.kafka.raft.KafkaRaftClient)
[2025-07-23 11:50:57,665] INFO [RaftManager id=1] Attempting durable transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1649, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2025-07-23 11:50:57,677] INFO [RaftManager id=1] Completed transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1649, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2025-07-23 11:50:57,681] INFO [RaftManager id=1] Completed transition to ProspectiveState(epoch=0, leaderId=OptionalInt.empty, retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1263, highWatermark=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1649, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-07-23 11:50:57,682] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=8faM4DwJIg-uLt0nW5zqpw, epoch=1, retries=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1794) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1263, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-07-23 11:50:57,683] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=8faM4DwJIg-uLt0nW5zqpw, epoch=1, retries=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1794) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1263, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-07-23 11:50:57,686] INFO [RaftManager id=1] Attempting durable transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=8faM4DwJIg-uLt0nW5zqpw), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=kafka/<unresolved>:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=8faM4DwJIg-uLt0nW5zqpw, epoch=1, retries=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1794) (org.apache.kafka.raft.QuorumState)
[2025-07-23 11:50:57,687] INFO [RaftManager id=1] Completed transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=8faM4DwJIg-uLt0nW5zqpw), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=kafka/<unresolved>:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=8faM4DwJIg-uLt0nW5zqpw, epoch=1, retries=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1794) (org.apache.kafka.raft.QuorumState)
[2025-07-23 11:50:57,700] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2025-07-23 11:50:57,700] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
[2025-07-23 11:50:57,713] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,715] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-07-23 11:50:57,715] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-07-23 11:50:57,715] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-07-23 11:50:57,715] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-07-23 11:50:57,718] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
[2025-07-23 11:50:57,728] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@9183361 (org.apache.kafka.raft.KafkaRaftClient)
[2025-07-23 11:50:57,728] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@9183361 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2025-07-23 11:50:57,730] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,750] INFO [ControllerServer id=1] Registering periodic task writeNoOpRecord to run every 500 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 11:50:57,750] INFO [ControllerServer id=1] Registering periodic task maybeFenceStaleBroker to run every 1125 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 11:50:57,750] INFO [ControllerServer id=1] Registering periodic task electUnclean to run every 300000 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 11:50:57,751] INFO [ControllerServer id=1] Registering periodic task expireDelegationTokens to run every 3600000 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 11:50:57,751] INFO [ControllerServer id=1] Registering periodic task generatePeriodicPerformanceMessage to run every 60000 ms (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 11:50:57,752] INFO [ControllerServer id=1] Creating new QuorumController with clusterId 4L6g3nShT-eMCtK--X86sw (org.apache.kafka.controller.QuorumController)
[2025-07-23 11:50:57,752] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@1352274956 (org.apache.kafka.raft.KafkaRaftClient)
[2025-07-23 11:50:57,752] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@1352274956 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2025-07-23 11:50:57,753] INFO [ControllerServer id=1] Becoming the active controller at epoch 1, next write offset 1. (org.apache.kafka.controller.QuorumController)
[2025-07-23 11:50:57,757] WARN [ControllerServer id=1] Performing controller activation. The metadata log appears to be empty. Appending 3 bootstrap record(s) in metadata transaction at metadata.version 4.0-IV3A from bootstrap source 'the binary bootstrap metadata file: /var/lib/kafka/data/bootstrap.checkpoint'. (org.apache.kafka.controller.QuorumController)
[2025-07-23 11:50:57,759] INFO [ControllerServer id=1] Replayed BeginTransactionRecord(name='Bootstrap records') at offset 1. (org.apache.kafka.controller.OffsetControlManager)
[2025-07-23 11:50:57,759] INFO [ControllerServer id=1] Replayed a Confluent FeatureLevelRecord setting metadata version to 4.0-IV3A (org.apache.kafka.controller.FeatureControlManager)
[2025-07-23 11:50:57,759] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-07-23 11:50:57,760] INFO [ControllerServer id=1] Replayed a FeatureLevelRecord setting feature group.version to 1 (org.apache.kafka.controller.FeatureControlManager)
[2025-07-23 11:50:57,760] INFO [ControllerServer id=1] Replayed a FeatureLevelRecord setting feature transaction.version to 2 (org.apache.kafka.controller.FeatureControlManager)
[2025-07-23 11:50:57,760] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-07-23 11:50:57,760] INFO [ControllerServer id=1] Replayed EndTransactionRecord() at offset 5. (org.apache.kafka.controller.OffsetControlManager)
[2025-07-23 11:50:57,761] INFO [ControllerServer id=1] Activated periodic tasks: electUnclean, expireDelegationTokens, generatePeriodicPerformanceMessage, maybeFenceStaleBroker, writeNoOpRecord (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 11:50:57,765] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,765] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,765] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-07-23 11:50:57,766] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,766] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,767] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-07-23 11:50:57,768] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,768] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,770] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
[2025-07-23 11:50:57,770] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
[2025-07-23 11:50:57,774] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-07-23 11:50:57,774] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
[2025-07-23 11:50:57,774] INFO [controller-1-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,774] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
[2025-07-23 11:50:57,774] INFO [controller-1-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,778] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,778] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,788] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 6 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,792] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-07-23 11:50:57,793] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,795] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,796] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,797] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,797] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,797] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,798] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,798] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,798] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,808] INFO [ControllerServer id=1] Self-Balancing Kafka is enabled and will be installed as a metadata publisher. (kafka.server.ControllerServer)
[2025-07-23 11:50:57,808] INFO [ControllerServer id=1] Self-Balancing Kafka is enabled and will be installed as a metadata publisher. (kafka.server.ControllerServer)
[2025-07-23 11:50:57,809] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,809] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,809] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,809] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,809] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,809] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,810] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-07-23 11:50:57,810] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-07-23 11:50:57,811] INFO [ControllerServer id=1] Loaded new metadata Features(metadataVersion=4.0-IV3A, finalizedFeatures={group.version=1, transaction.version=2, confluent.metadata.version=127}, finalizedFeaturesEpoch=5). (org.apache.kafka.metadata.publisher.FeaturesPublisher)
[2025-07-23 11:50:57,811] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,811] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,811] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,812] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,812] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
[2025-07-23 11:50:57,812] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
[2025-07-23 11:50:57,812] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,813] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,814] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,814] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ConfluentControllerMetricsPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,815] INFO [ConfluentControllerMetricsChanges id=1] Finished reloading all Confluent controller metrics in 0 ms. (org.apache.kafka.controller.metrics.ConfluentControllerMetricsChanges)
[2025-07-23 11:50:57,815] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing CellControllerMetadataMetricsPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,815] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SbcDataBalanceManager with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,817] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:57,818] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,818] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,818] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,818] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,818] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,818] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,818] INFO [ControllerRegistrationManager id=1 incarnation=DGsXw8eeRIS4-rh7jlHqGg] initialized channel manager. (kafka.server.ControllerRegistrationManager)
[2025-07-23 11:50:57,818] INFO [ControllerServer id=1] Waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
[2025-07-23 11:50:57,818] INFO [ControllerRegistrationManager id=1 incarnation=DGsXw8eeRIS4-rh7jlHqGg] initialized channel manager. (kafka.server.ControllerRegistrationManager)
[2025-07-23 11:50:57,818] INFO [ControllerServer id=1] Waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
[2025-07-23 11:50:57,818] INFO [ControllerServer id=1] Finished waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
[2025-07-23 11:50:57,818] INFO [ControllerServer id=1] Finished waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
[2025-07-23 11:50:57,819] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,819] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,819] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-07-23 11:50:57,819] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-07-23 11:50:57,819] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-07-23 11:50:57,819] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-07-23 11:50:57,819] INFO [ControllerServer id=1] Waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,819] INFO [ControllerServer id=1] Waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,819] INFO [ControllerServer id=1] Finished waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,819] INFO [ControllerServer id=1] Finished waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
[2025-07-23 11:50:57,820] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-07-23 11:50:57,820] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-07-23 11:50:57,820] INFO Balancer received a new Replica Exclusions Image (image: , delta: BrokerReplicaExclusionsDelta{newExclusions=[], removedExclusions=[]}) (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:57,821] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
[2025-07-23 11:50:57,821] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
[2025-07-23 11:50:57,821] INFO Handling event SbcAlteredExclusionsEvent-4 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:57,821] INFO SBC Event SbcMetadataUpdateEvent-1 generated 1 more events to enqueue in the following order - [SbcConfigUpdateEvent-3]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:57,822] INFO Handling event SbcLeaderUpdateEvent-2 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:57,822] INFO This balancer node is now the metadata quorum leader. Activating kafkadatabalance manager without alive broker snapshot. (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:57,822] INFO Handling event SbcConfigUpdateEvent-3 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:57,822] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC config processing delayed. (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:57,822] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:57,822] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC startup delayed. (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:57,823] INFO [ControllerRegistrationManager id=1 incarnation=DGsXw8eeRIS4-rh7jlHqGg] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=DGsXw8eeRIS4-rh7jlHqGg, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='kafka', port=9093, securityProtocol=0)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='confluent.metadata.version', minSupportedVersion=7, maxSupportedVersion=127), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=25)], metadataEncryptors=[]) (kafka.server.ControllerRegistrationManager)
[2025-07-23 11:50:57,823] INFO [ControllerRegistrationManager id=1 incarnation=DGsXw8eeRIS4-rh7jlHqGg] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=DGsXw8eeRIS4-rh7jlHqGg, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='kafka', port=9093, securityProtocol=0)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='confluent.metadata.version', minSupportedVersion=7, maxSupportedVersion=127), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=25)], metadataEncryptors=[]) (kafka.server.ControllerRegistrationManager)
[2025-07-23 11:50:57,830] INFO [BrokerServer id=1] FIPS mode enabled: false (kafka.server.BrokerServer)
[2025-07-23 11:50:57,830] INFO [BrokerServer id=1] FIPS mode enabled: false (kafka.server.BrokerServer)
[2025-07-23 11:50:57,833] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-07-23 11:50:57,833] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-07-23 11:50:57,833] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,833] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,834] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-07-23 11:50:57,835] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
[2025-07-23 11:50:57,835] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
[2025-07-23 11:50:57,835] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,835] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,835] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,835] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,835] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-07-23 11:50:57,836] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
[2025-07-23 11:50:57,836] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
[2025-07-23 11:50:57,836] INFO [broker-1-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,836] INFO [broker-1-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,838] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,838] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-07-23 11:50:57,840] INFO FlexFanout is not enabled or there is no ClientQuotaCallback so does not start FlexFanoutQuotaManager. (kafka.server.FlexFanoutQuotaManager)
[2025-07-23 11:50:57,840] INFO FlexFanout is not enabled or there is no ClientQuotaCallback so does not start FlexFanoutQuotaManager. (kafka.server.FlexFanoutQuotaManager)
[2025-07-23 11:50:57,854] INFO Skip DiskIOManager init: confluent.disk.io.manager.enable = false (kafka.server.resource.DiskIOManager)
[2025-07-23 11:50:57,854] INFO Skip DiskIOManager init: confluent.disk.io.manager.enable = false (kafka.server.resource.DiskIOManager)
[2025-07-23 11:50:57,855] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,855] INFO CrnAuthorityConfig values:
	confluent.authorizer.authority.cache.entries = 10000
	confluent.authorizer.authority.name =
	confluent.metadata.server.api.flavor = CP
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,855] INFO NamedConfigEnabled: false (io.confluent.security.audit.provider.ConfluentAuditLogProvider)
[2025-07-23 11:50:57,856] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,856] INFO CrnAuthorityConfig values:
	confluent.authorizer.authority.cache.entries = 10000
	confluent.authorizer.authority.name =
	confluent.metadata.server.api.flavor = CP
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,856] INFO MultiTenantAuditLogConfig values:
	confluent.security.event.logger.client.ip.enable = false
	confluent.security.event.logger.multitenant.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,856] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,856] INFO Audit Log rate limiter reconfigured: Authn: -1, Authz: -1, Kafka request: -1 (io.confluent.security.audit.provider.AuditLogRateLimiter)
[2025-07-23 11:50:57,859] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-07-23 11:50:57,859] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-07-23 11:50:57,859] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-07-23 11:50:57,859] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-07-23 11:50:57,860] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,860] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,860] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,860] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,866] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2025-07-23 11:50:57,891] INFO [ControllerServer id=1] Node 1 identified 0 potential metadata log encryptor rotation candidates: [] (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:57,892] INFO [ControllerServer id=1] Potential metadata log encryptor rotation candidates that are existing in all controllers: [] (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:57,892] INFO [ControllerServer id=1] Potential metadata log encryptor rotation candidates that are existing in all brokers: [] (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:57,894] INFO [ControllerServer id=1] Replayed RegisterControllerRecord containing ControllerRegistration(id=1, incarnationId=DGsXw8eeRIS4-rh7jlHqGg, zkMigrationReady=false, listeners=[Endpoint(listenerName='CONTROLLER', securityProtocol=PLAINTEXT, host='kafka', port=9093)], supportedFeatures={confluent.metadata.version: 7-127, eligible.leader.replicas.version: 0-1, group.version: 0-1, kraft.version: 0-1, metadata.version: 7-25, transaction.version: 0-2}, metadataEncryptors=[]). (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:57,915] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-07-23 11:50:57,919] INFO [ControllerRegistrationManager id=1 incarnation=DGsXw8eeRIS4-rh7jlHqGg] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
[2025-07-23 11:50:57,919] INFO [ControllerRegistrationManager id=1 incarnation=DGsXw8eeRIS4-rh7jlHqGg] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
[2025-07-23 11:50:57,921] INFO [ControllerRegistrationManager id=1 incarnation=DGsXw8eeRIS4-rh7jlHqGg] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
[2025-07-23 11:50:57,921] INFO [ControllerRegistrationManager id=1 incarnation=DGsXw8eeRIS4-rh7jlHqGg] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
[2025-07-23 11:50:57,936] INFO [SocketServer listenerType=BROKER, nodeId=1] Creating data-plane acceptor and processors for endpoint : ListenerName(SASL_PLAINTEXT) (kafka.network.SocketServer)
[2025-07-23 11:50:57,936] INFO [SocketServer listenerType=BROKER, nodeId=1] Creating data-plane acceptor and processors for endpoint : ListenerName(SASL_PLAINTEXT) (kafka.network.SocketServer)
[2025-07-23 11:50:57,937] INFO Quota SASL_PLAINTEXT-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
[2025-07-23 11:50:57,937] INFO Quota SASL_PLAINTEXT-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
[2025-07-23 11:50:57,937] INFO Quota SASL_PLAINTEXT-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
[2025-07-23 11:50:57,937] INFO Quota SASL_PLAINTEXT-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
[2025-07-23 11:50:57,937] INFO Quota SASL_PLAINTEXT-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
[2025-07-23 11:50:57,937] INFO Quota SASL_PLAINTEXT-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
[2025-07-23 11:50:57,938] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
[2025-07-23 11:50:57,938] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
[2025-07-23 11:50:57,939] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,972] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[2025-07-23 11:50:57,976] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,978] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:57,980] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(SASL_PLAINTEXT) used TCP protocol (kafka.network.SocketServer)
[2025-07-23 11:50:57,980] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(SASL_PLAINTEXT) used TCP protocol (kafka.network.SocketServer)
[2025-07-23 11:50:57,988] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,988] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,988] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,988] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,996] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,996] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,996] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:57,996] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:58,000] INFO [BrokerHealthManager]: Starting (kafka.availability.BrokerHealthManager)
[2025-07-23 11:50:58,000] INFO [BrokerHealthManager]: Starting (kafka.availability.BrokerHealthManager)
[2025-07-23 11:50:58,015] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-07-23 11:50:58,016] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-07-23 11:50:58,016] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-07-23 11:50:58,017] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-07-23 11:50:58,017] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-07-23 11:50:58,026] INFO ReplicationConfig values:
	confluent.replication.linger.ms = 0
	confluent.replication.max.in.flight.requests = 1
	confluent.replication.max.memory.buffer.bytes = 209715200
	confluent.replication.max.replica.pushers = 4
	confluent.replication.max.wait.ms = 500
	confluent.replication.mode = PULL
	confluent.replication.num.pushers.per.broker = 1
	confluent.replication.push.internal.topics.enable = false
	confluent.replication.request.max.bytes = 52428800
	confluent.replication.request.max.partition.bytes = 52428800
	confluent.replication.request.timeout.ms = 5000
	confluent.replication.retry.timeout.ms = 10000
	confluent.replication.socket.send.buffer.bytes = 1048576
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,034] INFO [BrokerServer id=1] Using no op persister (kafka.server.BrokerServer)
[2025-07-23 11:50:58,034] INFO [BrokerServer id=1] Using no op persister (kafka.server.BrokerServer)
[2025-07-23 11:50:58,036] INFO [group-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2025-07-23 11:50:58,052] INFO [group-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-07-23 11:50:58,052] INFO [group-coordinator-event-processor-1]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-07-23 11:50:58,052] INFO [group-coordinator-event-processor-2]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-07-23 11:50:58,052] INFO [group-coordinator-event-processor-3]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-07-23 11:50:58,070] INFO Unable to read the broker epoch in /var/lib/kafka/data. (kafka.log.LogManager)
[2025-07-23 11:50:58,070] INFO Unable to read the broker epoch in /var/lib/kafka/data. (kafka.log.LogManager)
[2025-07-23 11:50:58,070] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:58,070] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:58,071] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:58,071] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafka:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-07-23 11:50:58,071] INFO [SharedServer id=1] Using kafka:9092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
[2025-07-23 11:50:58,071] INFO [SharedServer id=1] Using kafka:9092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
[2025-07-23 11:50:58,071] INFO [SharedServer id=1] Using kafka:9092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
[2025-07-23 11:50:58,071] INFO [SharedServer id=1] Using kafka:9092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
[2025-07-23 11:50:58,072] INFO [BrokerLifecycleManager id=1] Incarnation Z5u4d9xzQHuo0OGI_jEhsA of broker 1 in cluster 4L6g3nShT-eMCtK--X86sw is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,072] INFO [BrokerLifecycleManager id=1] Incarnation Z5u4d9xzQHuo0OGI_jEhsA of broker 1 in cluster 4L6g3nShT-eMCtK--X86sw is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,080] INFO [ControllerServer id=1] No previous registration found for broker 1. New incarnation ID is Z5u4d9xzQHuo0OGI_jEhsA.  Generated 0 record(s) to clean up previous incarnations. New broker epoch is 7. (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:58,080] INFO [ControllerServer id=1] Node 1 identified 0 potential metadata log encryptor rotation candidates: [] (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:58,080] INFO [ControllerServer id=1] Potential metadata log encryptor rotation candidates that are existing in all controllers: [] (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:58,080] INFO [ControllerServer id=1] Potential metadata log encryptor rotation candidates that are existing in all brokers: [] (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:58,084] INFO [ControllerServer id=1] Replayed initial RegisterBrokerRecord for broker 1: RegisterBrokerRecord(brokerId=1, isMigratingZkBroker=false, incarnationId=Z5u4d9xzQHuo0OGI_jEhsA, brokerEpoch=7, endPoints=[BrokerEndpoint(name='SASL_PLAINTEXT', host='kafka', port=9092, securityProtocol=2)], features=[BrokerFeature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='confluent.metadata.version', minSupportedVersion=7, maxSupportedVersion=127), BrokerFeature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), BrokerFeature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), BrokerFeature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=25)], rack=null, fenced=true, inControlledShutdown=false, degradedComponents=[], metadataEncryptors=[], logDirs=[8faM4DwJIg-uLt0nW5zqpw]) (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:58,092] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-07-23 11:50:58,097] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,097] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,097] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,098] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,098] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,099] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,099] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,099] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,100] INFO [BrokerServer id=1] Waiting for broker metadata to catch up (kafka.server.BrokerServer)
[2025-07-23 11:50:58,100] INFO [BrokerServer id=1] Waiting for broker metadata to catch up (kafka.server.BrokerServer)
[2025-07-23 11:50:58,107] INFO Handling event SbcConfigUpdateEvent-3 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,107] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC config processing delayed. (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,107] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,107] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC startup delayed. (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,110] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 7 (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,110] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 7 (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,115] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,115] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,115] INFO [BrokerServer id=1] Finished waiting for broker metadata to catch up (kafka.server.BrokerServer)
[2025-07-23 11:50:58,115] INFO [BrokerServer id=1] Finished waiting for broker metadata to catch up (kafka.server.BrokerServer)
[2025-07-23 11:50:58,127] INFO [BrokerLifecycleManager id=1] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,127] INFO [BrokerLifecycleManager id=1] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,133] INFO Starting DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
[2025-07-23 11:50:58,133] INFO Starting DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
[2025-07-23 11:50:58,134] INFO Attempting to initiate DynamicMetricsReporters. Attempt: 1 (kafka.server.DynamicMetricsReportersScheduler)
[2025-07-23 11:50:58,134] INFO Attempting to initiate DynamicMetricsReporters. Attempt: 1 (kafka.server.DynamicMetricsReportersScheduler)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-07-23 11:50:58,146] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:58,146] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:58,147] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=7, epoch=1) with metadata.version Optional[4.0-IV3A]. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-07-23 11:50:58,147] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=7, epoch=1) with metadata.version Optional[4.0-IV3A]. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-07-23 11:50:58,147] INFO Loading logs from log dirs ArrayBuffer(/var/lib/kafka/data) (kafka.log.LogManager)
[2025-07-23 11:50:58,147] INFO Loading logs from log dirs ArrayBuffer(/var/lib/kafka/data) (kafka.log.LogManager)
[2025-07-23 11:50:58,148] INFO EventEmitterConfig values:
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,149] INFO No logs found to be loaded in /var/lib/kafka/data (kafka.log.LogManager)
[2025-07-23 11:50:58,149] INFO No logs found to be loaded in /var/lib/kafka/data (kafka.log.LogManager)
[2025-07-23 11:50:58,158] INFO Loaded 0 logs in 5ms (kafka.log.LogManager)
[2025-07-23 11:50:58,158] INFO Loaded 0 logs in 5ms (kafka.log.LogManager)
[2025-07-23 11:50:58,158] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-07-23 11:50:58,158] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-07-23 11:50:58,159] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-07-23 11:50:58,159] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-07-23 11:50:58,159] INFO Starting log roller with a period of 300000 ms. (kafka.log.LogManager)
[2025-07-23 11:50:58,159] INFO Starting log roller with a period of 300000 ms. (kafka.log.LogManager)
[2025-07-23 11:50:58,165] INFO Linux CPU collector enabled: true (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-07-23 11:50:58,165] INFO Using cpu metric: io\.confluent\.kafka\.server/server/linux_system_cpu_utilization_1m (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-07-23 11:50:58,170] INFO Starting the log cleaner (kafka.log.LogCleaner)
[2025-07-23 11:50:58,170] INFO Starting the log cleaner (kafka.log.LogCleaner)
[2025-07-23 11:50:58,170] INFO Starting the log cleaner (kafka.log.LogCleaner)
[2025-07-23 11:50:58,178] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
[2025-07-23 11:50:58,179] WARN no telemetry exporters are enabled (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-07-23 11:50:58,278] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-07-23 11:50:58,278] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-07-23 11:50:58,280] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-07-23 11:50:58,280] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-07-23 11:50:58,281] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-07-23 11:50:58,281] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-07-23 11:50:58,291] INFO [ClusterLinkTaskManager brokerId=1] Creating local admin client for task manager 0 (kafka.server.link.ClusterLinkTaskManager)
[2025-07-23 11:50:58,291] INFO [ClusterLinkTaskManager brokerId=1] Creating local admin client for task manager 0 (kafka.server.link.ClusterLinkTaskManager)
[2025-07-23 11:50:58,294] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = cluster-link--local-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,301] WARN Ignoring redefinition of existing telemetry label kafka.version (io.confluent.telemetry.ResourceBuilderFacade)
[2025-07-23 11:50:58,315] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[2025-07-23 11:50:58,316] INFO ConfluentTelemetryConfig values:
	confluent.telemetry.api.key = null
	confluent.telemetry.api.secret = null
	confluent.telemetry.cluster.id = null
	confluent.telemetry.debug.enabled = false
	confluent.telemetry.enabled = false
	confluent.telemetry.events.collector.include = .*transaction.remove.expired.transaction.cleanup.interval.ms.*|.*transaction.state.log.load.buffer.size.*|.*transaction.state.log.min.isr.*|.*transaction.state.log.num.partitions.*|.*transaction.state.log.replication.factor.*|.*transaction.state.log.segment.bytes.*|.*transactional.id.expiration.ms.*|.*controlled.shutdown.enable.*|.*fetch.max.bytes.*|.*fetch.purgatory.purge.interval.requests.*|.*group.initial.rebalance.delay.ms.*|.*group.max.session.timeout.ms.*|.*group.max.size.*|.*group.min.session.timeout.ms.*|.*log.cleaner.backoff.ms.*|.*log.cleaner.dedupe.buffer.size.*|.*log.cleaner.delete.retention.ms.*|.*log.cleaner.enable.*|.*log.cleaner.io.buffer.load.factor.*|.*log.cleaner.io.buffer.size.*|.*log.cleaner.io.max.bytes.per.second.*|.*log.cleaner.max.compaction.lag.ms.*|.*log.cleaner.min.cleanable.ratio.*|.*log.cleaner.min.compaction.lag.ms.*|.*log.cleaner.threads.*|.*log.cleanup.policy.*|.*log.index.interval.bytes.*|.*log.index.size.max.bytes.*|.*log.message.downconversion.enable.*|.*log.message.format.version.*|.*log.message.timestamp.difference.max.ms.*|.*log.message.timestamp.type.*|.*max.connection.creation.rate.*|.*max.connections.*|.*max.connections.per.ip.*|.*max.incremental.fetch.session.cache.slots.*|.*replica.fetch.backoff.ms.*|.*replica.fetch.max.bytes.*|.*replica.fetch.min.bytes.*|.*replica.fetch.response.max.bytes.*|.*replica.fetch.wait.max.ms.*|.*replica.high.watermark.checkpoint.interval.ms.*|.*replica.lag.time.max.ms.*|.*replica.selector.class.*|.*replica.socket.receive.buffer.bytes.*|.*replica.socket.timeout.ms.*|.*alter.config.policy.class.name.*|.*alter.log.dirs.replication.quota.window.num.*|.*alter.log.dirs.replication.quota.window.size.seconds.*|.*metrics.num.samples.*|.*metrics.recording.level.*|.*metrics.sample.window.ms.*|.*quota.window.num.*|.*quota.window.size.seconds.*|.*replication.quota.window.num.*|.*replication.quota.window.size.seconds.*|.*confluent.balancer.enable.*|.*confluent.balancer.throttle.bytes.per.second.*|.*confluent.balancer.heal.uneven.load.trigger.*|.*confluent.balancer.heal.broker.failure.threshold.ms.*|.*confluent.balancer.disk.max.load.*|.*confluent.balancer.exclude.topic.prefixes.*|.*confluent.balancer.exclude.topic.names.*|.*confluent.tier.local.hotset.bytes.*|.*confluent.tier.local.hotset.ms.*|.*confluent.tier.archiver.num.threads.*|.*confluent.tier.backend.*|.*confluent.tier.enable.*|.*confluent.tier.feature.*|.*confluent.tier.fetcher.num.threads.*|.*confluent.tier.max.partition.fetch.bytes.override.*|.*confluent.tier.metadata.replication.factor.*|.*confluent.operator.managed.*|.*confluent.ansible.managed.*|.*confluent.license.*
	confluent.telemetry.events.enable = true
	confluent.telemetry.external.client.metrics.exclude.labels =
	confluent.telemetry.metrics.collector.include = .*io.confluent.telemetry/.*.*|.*io\.confluent\.system/(?:.*/)?(process_cpu_load|max_file_descriptor_count|open_file_descriptor_count|system_cpu_load|system_load_average|free_physical_memory_size|total_physical_memory_size|disk_total_bytes|disk_usable_bytes|jvm/mem|jvm/gc).*|.*io.confluent.kafka.server/.*(confluent_audit/audit_log_fallback_rate_per_minute|confluent_audit/audit_log_rate_per_minute|confluent_authorizer/authorization_request_rate_per_minute|confluent_authorizer/authorization_allowed_rate_per_minute|confluent_authorizer/authorization_denied_rate_per_minute|confluent_auth_store/rbac_role_bindings_count|confluent_auth_store/rbac_access_rules_count|confluent_auth_store/acl_access_rules_count).*|.*io.confluent.kafka.server/.*(acl_authorizer/zookeeper_disconnects/total/delta|acl_authorizer/zookeeper_expires/total/delta|broker_failure/zookeeper_disconnects/total/delta|broker_failure/zookeeper_expires/total/delta|broker_topic/bytes_in/total/delta|broker_topic/bytes_out/total/delta|broker_topic/failed_produce_requests/total/delta|broker_topic/failed_fetch_requests/total/delta|broker_topic/produce_message_conversions/total/delta|broker_topic/fetch_message_conversions/total/delta|client_broker_topic/client_bytes_in/delta|client_broker_topic/client_bytes_out/delta|client_broker_topic/client_records_in/delta|client_broker_topic/client_records_out/delta|cluster_link/active_link_count|cluster_link/consumer_offset_committed_rate|cluster_link/consumer_offset_committed_total|cluster_link/fetch_throttle_time_avg|cluster_link/fetch_throttle_time_max|cluster_link/link_count|cluster_link/linked_leader_epoch_change_rate|cluster_link/linked_leader_epoch_change_total|cluster_link/linked_topic_partition_addition_rate|cluster_link/linked_topic_partition_addition_total|cluster_link/mirror_partition_count|cluster_link/mirror_topic_byte_total|cluster_link/mirror_topic_count|cluster_link/mirror_topic_lag|cluster_link/topic_config_update_rate|cluster_link/topic_config_update_total|cluster_link_fetcher/connection_count|cluster_link_fetcher/failed_reauthentication_rate|cluster_link_fetcher/failed_reauthentication_total|cluster_link_fetcher/incoming_byte_rate|cluster_link_fetcher/incoming_byte_total|cluster_link_fetcher/outgoing_byte_rate|cluster_link_fetcher/outgoing_byte_total|cluster_link_fetcher/reauthentication_latency_avg|cluster_link_fetcher_manager/max_lag|controller/active_controller_count|controller/leader_election_rate_and_time_ms|controller/offline_partitions_count|controller/partition_availability|controller/preferred_replica_imbalance_count|controller/tenant_partition_availability|controller/global_under_min_isr_partition_count|controller/unclean_leader_elections/total|controller_channel/connection_close_rate|controller_channel/connection_close_total|controller_channel/connection_count|controller_channel/connection_creation_rate|controller_channel/connection_creation_total|controller_channel/request_size_avg|controller_channel/request_size_max|controller_channel_manager/queue_size|controller_channel_manager/total_queue_size|controller_event_manager/event_queue_size|delayed_operation_purgatory/purgatory_size|executor/zookeeper_disconnects/total/delta|executor/zookeeper_expires/total/delta|fetch/queue_size|fetcher/bytes_per_sec|fetcher_lag/consumer_lag|group_coordinator/partition_load_time_max|log/log_end_offset|log/log_start_offset|log/total_size|log_cleaner_manager/achieved_cleaning_ratio/time/delta|log_cleaner_manager/achieved_cleaning_ratio/total/delta|log_cleaner_manager/compacted_partition_bytes|log_cleaner_manager/max_dirty_percent|log_cleaner_manager/time_since_last_run_ms|log_cleaner_manager/uncleanable_bytes|log_cleaner_manager/uncleanable_partitions_count|replica_alter_log_dirs_manager/max_lag|replica_fetcher/request_size_avg|replica_fetcher/request_size_max|replica_fetcher_manager/max_lag|replica_manager/blocked_on_mirror_source_partition_count|replica_manager/isr_shrinks|replica_manager/leader_count|replica_manager/partition_count|replica_manager/under_min_isr_mirror_partition_count|replica_manager/under_min_isr_partition_count|replica_manager/under_replicated_mirror_partitions|replica_manager/under_replicated_partitions|request/errors/total/delta|request/local_time_ms/time/delta|request/local_time_ms/total/delta|request/queue_size|request/remote_time_ms/time/delta|request/remote_time_ms/total/delta|request/request_queue_time_ms/time/delta|request/request_queue_time_ms/total/delta|request/requests|request/response_queue_time_ms/time/delta|request/response_queue_time_ms/total/delta|request/response_send_time_ms/time/delta|request/response_send_time_ms/total/delta|request/total_time_ms/time/delta|request/total_time_ms/total/delta|request_channel/request_queue_size|request_channel/response_queue_size|request_handler_pool/request_handler_avg_idle_percent|session_expire_listener/zookeeper_disconnects/total/delta|session_expire_listener/zookeeper_expires/total/delta|socket_server/connections|socket_server/successful_authentication_total/delta|socket_server/failed_authentication_total/delta|socket_server/network_processor_avg_idle_percent|socket_server/request_size_avg|socket_server/request_size_max|tenant/consumer_lag_offsets).*|.*org\.apache\.kafka\.(producer\.connection\.creation\.rate|producer\.node\.request\.latency\.avg|producer\.node\.request\.latency\.max|producer\.produce\.throttle\.time\.avg|producer\.produce\.throttle\.time\.max|producer\.record\.queue\.time\.avg|producer\.record\.queue\.time\.max|producer\.connection\.creation\.total|consumer\.connection\.creation\.rate|consumer\.connection\.creation\.total|consumer\.node\.request\.latency\.avg|consumer\.node\.request\.latency\.max|consumer\.poll\.idle\.ratio\.avg|consumer\.coordinator\.commit\.latency\.avg|consumer\.coordinator\.commit\.latency\.max|consumer\.coordinator\.assigned\.partitions|consumer\.coordinator\.rebalance\.latency\.avg|consumer\.coordinator\.rebalance\.latency\.max|consumer\.coordinator\.rebalance\.latency\.total|consumer\.fetch\.manager\.fetch\.latency\.avg|consumer\.fetch\.manager\.fetch\.latency\.max).*
	confluent.telemetry.metrics.collector.interval.ms = 60000
	confluent.telemetry.metrics.collector.slo.enabled = false
	confluent.telemetry.proxy.password = null
	confluent.telemetry.proxy.url = null
	confluent.telemetry.proxy.username = null
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,317] INFO VolumeMetricsCollectorConfig values:
	confluent.telemetry.metrics.collector.volume.update.ms = 15000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,317] INFO HttpClientConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = httpTelemetryClient
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,317] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client = _confluentClient
	client.attempts.max = null
	client.base.url = null
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = false
	events.enabled = true
	metrics.enabled = true
	metrics.include = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	remote.configurable = true
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,317] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
[2025-07-23 11:50:58,318] INFO HttpExporterConfig values:
	api.key = unused
	api.secret = [hidden]
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = 2000
	buffer.inflight.submissions.max = 10
	buffer.pending.batches.max = 25
	client =
	client.attempts.max = null
	client.base.url = http://localhost:9090/api/v1/otlp
	client.compression = gzip
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = false
	events.enabled = true
	metrics.enabled = true
	metrics.include = (io.confluent.kafka.server.request.(?!.*delta).*|io.confluent.kafka.server.server.broker.state|io.confluent.kafka.server.replica.manager.leader.count|io.confluent.kafka.server.request.queue.size|io.confluent.kafka.server.broker.topic.failed.produce.requests.rate.1_min|io.confluent.kafka.server.tier.archiver.total.lag|io.confluent.kafka.server.request.total.time.ms.p99|io.confluent.kafka.server.broker.topic.failed.fetch.requests.rate.1_min|io.confluent.kafka.server.log.total.size|io.confluent.kafka.server.broker.topic.total.fetch.requests.rate.1_min|io.confluent.kafka.server.partition.caught.up.replicas.count|io.confluent.kafka.server.partition.observer.replicas.count|io.confluent.kafka.server.tier.tasks.num.partitions.in.error|io.confluent.kafka.server.broker.topic.bytes.out.rate.1_min|io.confluent.kafka.server.request.total.time.ms.p95|io.confluent.kafka.server.controller.active.controller.count|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.total|io.confluent.kafka.server.request.total.time.ms.p999|io.confluent.kafka.server.controller.active.broker.count|io.confluent.kafka.server.request.handler.pool.request.handler.avg.idle.percent.rate.1_min|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.rate.1_min|io.confluent.kafka.server.controller.unclean.leader.elections.rate.1_min|io.confluent.kafka.server.replica.manager.partition.count|io.confluent.kafka.server.controller.unclean.leader.elections.total|io.confluent.kafka.server.partition.replicas.count|io.confluent.kafka.server.broker.topic.total.produce.requests.rate.1_min|io.confluent.kafka.server.controller.offline.partitions.count|io.confluent.kafka.server.socket.server.network.processor.avg.idle.percent|io.confluent.kafka.server.partition.under.replicated|io.confluent.kafka.server.log.log.start.offset|io.confluent.kafka.server.log.tier.size|io.confluent.kafka.server.log.size|io.confluent.kafka.server.tier.fetcher.bytes.fetched.total|io.confluent.kafka.server.request.total.time.ms.p50|io.confluent.kafka.server.tenant.consumer.lag.offsets|io.confluent.kafka.server.session.expire.listener.zookeeper.expires.rate.1_min|io.confluent.kafka.server.log.log.end.offset|io.confluent.kafka.server.log.num.log.segments|io.confluent.kafka.server.broker.topic.bytes.in.rate.1_min|io.confluent.kafka.server.partition.under.min.isr|io.confluent.kafka.server.partition.in.sync.replicas.count|io.confluent.telemetry.http.exporter.batches.dropped|io.confluent.telemetry.http.exporter.items.total|io.confluent.telemetry.http.exporter.items.succeeded|io.confluent.telemetry.http.exporter.send.time.total.millis|io.confluent.kafka.server.controller.leader.election.rate.(?!.*delta).*|io.confluent.telemetry.http.exporter.batches.failed)
	proxy.password = null
	proxy.url = null
	proxy.username = null
	remote.configurable = true
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,319] INFO These configurations '[cluster.link.metadata.topic.replication, confluent.metadata.server.advertised.listeners, confluent.metrics.reporter.topic.replicas, confluent.metadata.server.user.store.file.path, confluent.metadata.server.listeners, confluent.metadata.server.authentication.method, confluent.license.topic.replication.factor, transaction.state.log.replication, confluent.metadata.server.user.store.file.hot.reload, confluent.balancer.topic.replication, confluent.durability.topic.replication, confluent.license.topic.replication, confluent.link.metadata.topic.replication, confluent.metadata.server.user.store, confluent.command.topic.replication, confluent.cluster.link.metadata.topic.replication, confluent.tier.metadata.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,319] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:58,320] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:58,320] INFO Kafka startTimeMs: 1753271458319 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:58,320] INFO KafkaExporterConfig values:
	client =
	enabled = true
	events.enabled = true
	metrics.enabled = true
	metrics.include = (io\.confluent\.kafka\.server/fetch/broker_quota|io\.confluent\.kafka\.server/produce/broker_quota|io\.confluent\.kafka\.server/broker_load/broker_load_percent|io\.confluent\.kafka\.server/broker_topic/bytes_in/rate/1_min|io\.confluent\.kafka\.server/broker_topic/bytes_out/rate/1_min|io\.confluent\.kafka\.server/broker_topic/fetch_from_follower_bytes_out/rate/1_min|io\.confluent\.kafka\.server/broker_topic/messages_in/rate/1_min|io\.confluent\.kafka\.server/broker_topic/replication_bytes_in/rate/1_min|io\.confluent\.kafka\.server/broker_topic/replication_bytes_out/rate/1_min|io\.confluent\.kafka\.server/broker_topic/total_fetch_requests/rate/1_min|io\.confluent\.kafka\.server/broker_topic/total_follower_fetch_requests/rate/1_min|io\.confluent\.kafka\.server/broker_topic/mirror_bytes_in/rate/1_min|io\.confluent\.kafka\.server/broker_topic/total_fetch_from_follower_requests/rate/1_min|io\.confluent\.kafka\.server/broker_topic/total_produce_requests/rate/1_min|io\.confluent\.kafka\.server/log/size|io\.confluent\.kafka\.server/request/requests/rate/1_min|io\.confluent\.kafka\.server/request_handler_pool/request_handler_avg_idle_percent/rate/1_min|io\.confluent\.kafka\.server/server/linux_system_cpu_utilization_1m|io\.confluent\.kafka\.server/replica_manager/partition_count|io\.confluent\.system/volume/disk_total_bytes)
	producer.bootstrap.servers = kafka:9092
	remote.configurable = false
	topic.create = true
	topic.max.message.bytes = 10485760
	topic.name = _confluent-telemetry-metrics
	topic.partitions = 12
	topic.replicas = 1
	topic.retention.bytes = -1
	topic.retention.ms = 259200000
	topic.roll.ms = 14400000
	type = kafka
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,320] INFO PollingRemoteConfigurationConfig values:
	enabled = true
	refresh.interval.ms = 60000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,320] INFO Initializing the event logger (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-07-23 11:50:58,321] INFO EventLoggerConfig values:
	event.logger.cloudevent.codec = structured
	event.logger.exporter.class = class io.confluent.telemetry.events.exporter.http.EventHttpExporter
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,322] INFO [ClusterLinkRegionalMetadata-broker-1] Set local network type to persisted value NOT_SET (kafka.server.link.ClusterLinkRegionalMetadata)
[2025-07-23 11:50:58,322] INFO [ClusterLinkRegionalMetadata-broker-1] Set local network type to persisted value NOT_SET (kafka.server.link.ClusterLinkRegionalMetadata)
[2025-07-23 11:50:58,322] INFO [ClusterLinkManager-broker-1] ClusterLinkManager has started up. (kafka.server.link.ClusterLinkManager)
[2025-07-23 11:50:58,322] INFO [ClusterLinkManager-broker-1] ClusterLinkManager has started up. (kafka.server.link.ClusterLinkManager)
[2025-07-23 11:50:58,322] INFO [GroupCoordinator id=1] Starting up. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
[2025-07-23 11:50:58,322] INFO [GroupCoordinator id=1] Startup complete. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
[2025-07-23 11:50:58,323] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-07-23 11:50:58,323] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-07-23 11:50:58,324] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-07-23 11:50:58,324] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-07-23 11:50:58,324] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-07-23 11:50:58,324] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-07-23 11:50:58,326] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = true
	events.enabled = true
	filtering.enabled = false
	filtering.routes.allowed = []
	metrics.enabled = true
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,331] INFO [AdminClient clientId=cluster-link--local-admin-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-07-23 11:50:58,331] WARN [AdminClient clientId=cluster-link--local-admin-1] Connection to node -1 (kafka/192.168.128.3:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-07-23 11:50:58,333] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:58,333] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-07-23 11:50:58,333] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-07-23 11:50:58,333] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ClusterLinkCoordinatorListener with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
[2025-07-23 11:50:58,334] INFO Handling event SbcConfigUpdateEvent-3 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,334] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC config processing delayed. (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,334] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,334] INFO Cluster metadata containing at least one unfenced broker not yet available, SBC startup delayed. (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,335] INFO KafkaConfig values:
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = SASL_PLAINTEXT://kafka:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
	broker.rack = null
	broker.session.timeout.ms = 9000
	broker.session.uuid = 2yBYTgb0Tf6Hp4Sp67hPyg
	client.quota.callback.class = null
	client.quota.max.throttle.time.in.response.ms = 60000
	client.quota.max.throttle.time.ms = 5000
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	confluent.accp.enabled = false
	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
	confluent.alter.broker.health.max.demoted.brokers = 2147483647
	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
	confluent.ansible.managed = false
	confluent.api.visibility = DEFAULT
	confluent.append.record.interceptor.classes = []
	confluent.apply.create.topic.policy.to.create.partitions = false
	confluent.authorizer.authority.name =
	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
	confluent.backpressure.disk.enable = false
	confluent.backpressure.disk.free.threshold.bytes = 21474836480
	confluent.backpressure.disk.produce.bytes.per.second = 131072
	confluent.backpressure.disk.threshold.recovery.factor = 1.5
	confluent.backpressure.request.min.broker.limit = 200
	confluent.backpressure.request.queue.size.percentile = p95
	confluent.backpressure.types = null
	confluent.balancer.api.state.topic = _confluent_balancer_api_state
	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
	confluent.balancer.capacity.threshold.upper.limit = 0.95
	confluent.balancer.cell.load.upper.bound = 0.7
	confluent.balancer.cell.overload.detection.interval.ms = 3600000
	confluent.balancer.cell.overload.duration.ms = 86400000
	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.cpu.balance.threshold = 1.1
	confluent.balancer.cpu.goal.act.as.capacity.goal = false
	confluent.balancer.cpu.low.utilization.threshold = 0.2
	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
	confluent.balancer.disk.max.load = 0.85
	confluent.balancer.disk.min.free.space.gb = 0
	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
	confluent.balancer.disk.utilization.detector.duration.ms = 600000
	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
	confluent.balancer.enable = true
	confluent.balancer.enable.network.capacity.metric.ingestion = false
	confluent.balancer.exclude.topic.names = []
	confluent.balancer.exclude.topic.prefixes = []
	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	confluent.balancer.incremental.balancing.enabled = false
	confluent.balancer.incremental.balancing.goals = []
	confluent.balancer.incremental.balancing.lower.bound = 0.02
	confluent.balancer.incremental.balancing.min.valid.windows = 5
	confluent.balancer.incremental.balancing.step.ratio = 0.2
	confluent.balancer.inter.cell.balancing.enabled = false
	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
	confluent.balancer.max.replicas = 2147483647
	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.rebalancing.goals = []
	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.resource.utilization.detector.interval.ms = 60000
	confluent.balancer.sbc.metrics.parser.enabled = false
	confluent.balancer.self.healing.maximum.rounds = 1
	confluent.balancer.task.history.retention.days = 30
	confluent.balancer.tenant.maximum.movements = 0
	confluent.balancer.tenant.suspension.ms = 86400000
	confluent.balancer.throttle.bytes.per.second = 10485760
	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
	confluent.balancer.topic.partition.maximum.movements = 3
	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
	confluent.balancer.topic.partition.movements.history.limit = 900
	confluent.balancer.topic.partition.suspension.ms = 3600000
	confluent.balancer.topic.replication.factor = 1
	confluent.balancer.triggering.goals = []
	confluent.balancer.v2.addition.enabled = false
	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
	confluent.balancer.v2.executor.enabled = false
	confluent.basic.auth.credentials.source = null
	confluent.basic.auth.user.info = null
	confluent.bearer.assertion.claim.aud = null
	confluent.bearer.assertion.claim.exp.minutes = null
	confluent.bearer.assertion.claim.iss = null
	confluent.bearer.assertion.claim.jti.include = null
	confluent.bearer.assertion.claim.nbf.include = null
	confluent.bearer.assertion.claim.sub = null
	confluent.bearer.assertion.file = null
	confluent.bearer.assertion.private.key.file = null
	confluent.bearer.assertion.private.key.passphrase = null
	confluent.bearer.assertion.template.file = null
	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
	confluent.bearer.auth.client.id = null
	confluent.bearer.auth.client.secret = null
	confluent.bearer.auth.credentials.source = null
	confluent.bearer.auth.identity.pool.id = null
	confluent.bearer.auth.issuer.endpoint.url = null
	confluent.bearer.auth.logical.cluster = null
	confluent.bearer.auth.scope = null
	confluent.bearer.auth.scope.claim.name = scope
	confluent.bearer.auth.sub.claim.name = sub
	confluent.bearer.auth.token = null
	confluent.broker.health.manager.enabled = true
	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
	confluent.broker.health.manager.hard.kill.duration.ms = 60000
	confluent.broker.health.manager.mitigation.enabled = false
	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
	confluent.broker.health.manager.sample.duration.ms = 1000
	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
	confluent.broker.load.advertised.limit.load = 0.8
	confluent.broker.load.average.service.request.time.ms = 0.1
	confluent.broker.load.delay.metric.start.ms = 180000
	confluent.broker.load.enabled = false
	confluent.broker.load.num.samples = 60
	confluent.broker.load.tenant.metric.enable = false
	confluent.broker.load.update.metric.tags.interval.ms = 60000
	confluent.broker.load.window.size.ms = 60000
	confluent.broker.load.workload.coefficient = 20.0
	confluent.broker.registration.delay.ms = 0
	confluent.calling.resource.identity.type.map =
	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
	confluent.catalog.collector.enable = false
	confluent.catalog.collector.full.configs.enable = false
	confluent.catalog.collector.max.bytes.per.snapshot = 850000
	confluent.catalog.collector.max.topics.process = 500
	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
	confluent.catalog.collector.multitenant.topics.enable = true
	confluent.catalog.collector.snapshot.init.delay.sec = 60
	confluent.catalog.collector.snapshot.interval.sec = 300
	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
	confluent.cdc.api.keys.topic =
	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
	confluent.cdc.client.quotas.enable = false
	confluent.cdc.client.quotas.topic.name =
	confluent.cdc.lkc.metadata.topic =
	confluent.cdc.user.metadata.enable = false
	confluent.cdc.user.metadata.topic = _confluent-user_metadata
	confluent.cell.metrics.refresh.period.ms = 60000
	confluent.cells.default.size = 15
	confluent.cells.enable = false
	confluent.cells.implicit.creation.enable = false
	confluent.cells.k2.base.broker.index = -1
	confluent.cells.load.refresher.enable = true
	confluent.cells.max.size = 15
	confluent.cells.min.size = 6
	confluent.checksum.enabled.files = [none]
	confluent.client.topic.max.metrics.count = 1000
	confluent.client.topic.metrics.expiry.sec = 3600
	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
	confluent.clm.enabled = false
	confluent.clm.frequency.in.hours = 6
	confluent.clm.list.object.thread_pool.size = 1
	confluent.clm.max.backup.days = 3
	confluent.clm.min.delay.in.minutes = 30
	confluent.clm.thread.pool.size = 2
	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
	confluent.close.connections.on.credential.delete = false
	confluent.cluster.link.admin.max.in.flight.requests = 1000
	confluent.cluster.link.admin.request.batch.size = 1
	confluent.cluster.link.allow.config.providers = true
	confluent.cluster.link.allow.legacy.message.format = false
	confluent.cluster.link.allow.truncation.below.hwm = false
	confluent.cluster.link.availability.check.mode = ALL
	confluent.cluster.link.background.thread.affinity = LINK
	confluent.cluster.link.bootstrap.translation.feature.enable = true
	confluent.cluster.link.clients.max.idle.ms = 3153600000000
	confluent.cluster.link.enable = true
	confluent.cluster.link.enable.local.admin = false
	confluent.cluster.link.enable.metrics.reduction = false
	confluent.cluster.link.enable.metrics.reduction.advanced = false
	confluent.cluster.link.fetch.response.min.bytes = 1
	confluent.cluster.link.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.fetcher.auto.tune.enable = false
	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
	confluent.cluster.link.insync.fetch.response.min.bytes = 1
	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
	confluent.cluster.link.intranet.connectivity.enable = false
	confluent.cluster.link.intranet.connectivity.migration.enable = false
	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
	confluent.cluster.link.local.admin.multitenant.enable = false
	confluent.cluster.link.local.reverse.connection.listener.map = null
	confluent.cluster.link.max.client.connections = 2147483647
	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
	confluent.cluster.link.metadata.topic.enable = false
	confluent.cluster.link.metadata.topic.min.isr = 2
	confluent.cluster.link.metadata.topic.partitions = 50
	confluent.cluster.link.metadata.topic.replication.factor = 3
	confluent.cluster.link.mirror.transition.batch.size = 10
	confluent.cluster.link.num.background.threads = 1
	confluent.cluster.link.periodic.task.batch.size = 2147483647
	confluent.cluster.link.periodic.task.min.interval.ms = 1000
	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
	confluent.cluster.link.replica.fetch.connections.mode = combined
	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
	confluent.cluster.link.replication.quota.mode.per.tenant.overrides =
	confluent.cluster.link.replication.quota.window.num = 11
	confluent.cluster.link.replication.quota.window.size.seconds = 2
	confluent.cluster.link.request.quota.capacity = 400
	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
	confluent.cluster.link.switchover.disabled.principals = []
	confluent.cluster.link.switchover.enable = false
	confluent.cluster.link.switchover.listeners = []
	confluent.cluster.link.switchover.server.states = []
	confluent.cluster.link.tenant.replication.quota.enable = false
	confluent.cluster.link.tenant.request.quota.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
	confluent.cluster.metadata.snapshot.tier.upload.enable = false
	confluent.compacted.topic.prefer.tier.fetch.ms = -1
	confluent.connection.invalid.request.delay.enable = false
	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
	confluent.consumer.fetch.partition.pruning.enable = true
	confluent.consumer.lag.emitter.enabled = false
	confluent.consumer.lag.emitter.interval.ms = 60000
	confluent.dataflow.policy.watch.monitor.ms = 300000
	confluent.default.data.policy.enforcement = true
	confluent.defer.isr.shrink.enable = false
	confluent.describe.topic.partitions.enabled = true
	confluent.disk.io.manager.enable = false
	confluent.disk.throughput.headroom = 10485760
	confluent.disk.throughput.limit = 10485760000
	confluent.disk.throughput.quota.tier.archive = 1048576000
	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
	confluent.durability.audit.batch.flush.frequency.ms = 900000
	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
	confluent.durability.audit.enable = false
	confluent.durability.audit.idempotent.producer = false
	confluent.durability.audit.initial.job.delay.ms = 900000
	confluent.durability.audit.io.bytes.per.sec = 10485760
	confluent.durability.audit.log.ignored.event.types =
	confluent.durability.audit.reporting.batch.ms = 1800000
	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
	confluent.durability.topic.partition.count = 50
	confluent.durability.topic.replication.factor = 3
	confluent.e2e_checksum.protection.enabled = false
	confluent.e2e_checksum.protection.files = [none]
	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
	confluent.elastic.cku.enabled = false
	confluent.elastic.cku.scaletozero.enabled = false
	confluent.eligible.controllers = []
	confluent.enable.broker.reporting.min.usage.mode = true
	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.fail.unsatisfied.placement.constraints = false
	confluent.fetch.from.follower.require.leader.epoch.enable = false
	confluent.fetch.partition.pruning.enable = true
	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
	confluent.flexible.fanout.enabled = false
	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
	confluent.flexible.fanout.mode = TENANT_QUOTA
	confluent.floor.connection.rate.per.ip = -1.0
	confluent.floor.connection.rate.per.tenant = -1.0
	confluent.group.coordinator.dynamic.append.linger.enable = false
	confluent.group.coordinator.offsets.batching.enable = false
	confluent.group.coordinator.offsets.writer.threads = 2
	confluent.group.coordinator.txn.offset.validation.enable = false
	confluent.group.highest.offset.commit.rates.log.count = 10
	confluent.group.highest.offset.commit.rates.log.enable = false
	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
	confluent.group.metadata.load.threads = 32
	confluent.group.subscription.pattern.log.interval.ms = -1
	confluent.heap.tenured.notify.bytes = 0
	confluent.heap.tenured.notify.enabled = false
	confluent.hot.partition.ratio = 0.8
	confluent.http.server.start.timeout.ms = 60000
	confluent.http.server.stop.timeout.ms = 30000
	confluent.internal.metrics.enable = false
	confluent.internal.rest.server.bind.port = null
	confluent.internal.rest.server.ssl.enable = false
	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
	confluent.leader.epoch.checkpoint.checksum.enabled = false
	confluent.listener.protocol = TCP
	confluent.log.cleaner.timestamp.validation.enable = true
	confluent.log.placement.constraints =
	confluent.max.broker.load = 1.0
	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
	confluent.max.connection.rate.per.ip = -1.0
	confluent.max.connection.rate.per.tenant = -1.0
	confluent.max.connection.throttle.ms = null
	confluent.max.segment.ms = 9223372036854775807
	confluent.metadata.active.encryptor = null
	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
	confluent.metadata.encryptor.classes = null
	confluent.metadata.encryptor.required = false
	confluent.metadata.encryptor.secret.file = null
	confluent.metadata.encryptor.secrets = null
	confluent.metadata.jvm.warmup.ms = 60000
	confluent.metadata.leader.balance.slice.delay.ms = 100
	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
	confluent.metadata.max.leader.balance.changes.per.slice = 1000
	confluent.metadata.reject.when.throttled.enable = false
	confluent.metadata.server.cluster.registry.clusters = []
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.min.acks = 0
	confluent.min.connection.throttle.ms = 0
	confluent.min.segment.ms = 1
	confluent.missing.id.cache.ttl.sec = 60
	confluent.missing.id.query.range = 20000
	confluent.missing.schema.cache.ttl.sec = 60
	confluent.mtls.build.client.cert.chain.enable = false
	confluent.mtls.enable = false
	confluent.mtls.listener.name = EXTERNAL
	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
	confluent.mtls.truststore.manager.class.name = null
	confluent.multitenant.authorizer.enable.acl.state = false
	confluent.multitenant.interceptor.balancer.apis.enabled = false
	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
	confluent.multitenant.listener.names = null
	confluent.multitenant.parse.lkc.id.enable = false
	confluent.multitenant.parse.sni.host.name.enable = false
	confluent.network.health.manager.enabled = false
	confluent.network.health.manager.external.listener.name = EXTERNAL
	confluent.network.health.manager.externalconnectivitystartup.enabled = false
	confluent.network.health.manager.min.healthy.network.samples = 3
	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
	confluent.network.health.manager.mitigation.enabled = false
	confluent.network.health.manager.network.sample.window.size = 120
	confluent.network.health.manager.sample.duration.ms = 1000
	confluent.oauth.flat.networking.verification.enable = false
	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
	confluent.offsets.topic.placement.constraints =
	confluent.omit.network.processor.metric.tag = false
	confluent.operator.managed = false
	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings =
	confluent.ppv2.endpoint.scheme.enable = false
	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
	confluent.ppv2.endpoint.scheme.template.variable.cloud =
	confluent.ppv2.endpoint.scheme.template.variable.domain =
	confluent.ppv2.endpoint.scheme.template.variable.region =
	confluent.ppv2.endpoint.scheme.template.variables =
	confluent.ppv2.endpoint.scheme.templates =
	confluent.prefer.tier.fetch.ms = -1
	confluent.produce.throttle.pre.check.enable = false
	confluent.produce.throttle.pre.check.for.new.connection.enable = false
	confluent.producer.id.cache.broker.hard.limit = -1
	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
	confluent.producer.id.cache.extra.eviction.percentage = 0
	confluent.producer.id.cache.limit = 2147483647
	confluent.producer.id.cache.partition.hard.limit = -1
	confluent.producer.id.cache.tenant.hard.limit = -1
	confluent.producer.id.quota.manager.enable = false
	confluent.producer.id.quota.window.num = 11
	confluent.producer.id.quota.window.size.seconds = 1
	confluent.producer.id.throttle.enable = false
	confluent.producer.id.throttle.enable.threshold.percentage = 100
	confluent.proxy.mode.local.default = false
	confluent.proxy.protocol.fallback.enabled = false
	confluent.proxy.protocol.version = NONE
	confluent.quota.computing.usage.adjustment = 0.5
	confluent.quota.dynamic.adjustment.min.usage = 102400
	confluent.quota.dynamic.enable = false
	confluent.quota.dynamic.publishing.interval.ms = 60000
	confluent.quota.dynamic.reporting.interval.ms = 30000
	confluent.quota.tenant.broker.max.consumer.rate = 13107200
	confluent.quota.tenant.broker.max.producer.rate = 13107200
	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
	confluent.quota.tenant.fetch.multiplier = 1.0
	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
	confluent.quota.tenant.internal.throttling.enable = false
	confluent.quota.tenant.produce.multiplier = 1.0
	confluent.quota.tenant.user.quotas.enable = false
	confluent.rack.id.mapping = null
	confluent.regional.metadata.client.class = null
	confluent.regional.resource.manager.client.scheduler.threads = 2
	confluent.regional.resource.manager.endpoint = null
	confluent.regional.resource.manager.watch.endpoint = null
	confluent.replica.fetch.backoff.max.ms = 1000
	confluent.replica.fetch.connections.mode = combined
	confluent.replication.mode = PULL
	confluent.replication.push.feature.enable = false
	confluent.reporters.telemetry.auto.enable = true
	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
	confluent.request.pipelining.enable = true
	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
	confluent.require.calling.resource.identity = false
	confluent.require.compatible.keystore.updates = true
	confluent.require.confluent.issuer = false
	confluent.roll.check.interval.ms = 300000
	confluent.schema.registry.max.cache.size = 10000
	confluent.schema.registry.max.retries = 1
	confluent.schema.registry.retries.wait.ms = 0
	confluent.schema.registry.url = null
	confluent.schema.validation.context.name.enable = false
	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
	confluent.schema.validator.multitenant.enable = false
	confluent.schema.validator.samples.per.min = 0
	confluent.security.bc.approved.mode.enable = false
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.config =
	confluent.security.revoked.certificate.ids =
	confluent.segment.eager.roll.enable = false
	confluent.segment.speculative.prefetch.enable = false
	confluent.share.metadata.load.threads = 32
	confluent.spiffe.id.principal.extraction.rules =
	confluent.ssl.key.password = null
	confluent.ssl.keystore.location = null
	confluent.ssl.keystore.password = null
	confluent.ssl.keystore.type = null
	confluent.ssl.protocol = null
	confluent.ssl.truststore.location = null
	confluent.ssl.truststore.password = null
	confluent.ssl.truststore.type = null
	confluent.step.connection.rate.per.ip = -1.0
	confluent.step.connection.rate.per.tenant = -1.0
	confluent.storage.probe.period.ms = -1
	confluent.storage.probe.slow.write.threshold.ms = 5000
	confluent.stray.log.delete.delay.ms = 604800000
	confluent.stray.log.max.deletions.per.run = 72
	confluent.subdomain.prefix = null
	confluent.subdomain.separator.map = null
	confluent.subdomain.separator.variable = %sep
	confluent.system.time.roll.enable = false
	confluent.telemetry.enabled = false
	confluent.telemetry.external.client.metrics.delta.temporality = true
	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
	confluent.telemetry.external.client.metrics.push.enabled = false
	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
	confluent.telemetry.external.client.metrics.subscription.match.list = null
	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
	confluent.tenant.latency.metric.enabled = false
	confluent.tenantaware.encryption.key.manager.enable = false
	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
	confluent.tier.archiver.num.threads = 2
	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
	confluent.tier.azure.block.blob.container = null
	confluent.tier.azure.block.blob.cred.file.path = null
	confluent.tier.azure.block.blob.endpoint = null
	confluent.tier.azure.block.blob.prefix =
	confluent.tier.backend =
	confluent.tier.bucket.probe.period.ms = -1
	confluent.tier.cleaner.compact.min.efficiency = 0.5
	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
	confluent.tier.cleaner.dedupe.buffer.size = 134217728
	confluent.tier.cleaner.dual.compaction = false
	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
	confluent.tier.cleaner.dual.compaction.validation.percent = 0
	confluent.tier.cleaner.enable = false
	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
	confluent.tier.cleaner.feature.enable = false
	confluent.tier.cleaner.io.buffer.load.factor = 0.9
	confluent.tier.cleaner.io.buffer.size = 10485760
	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	confluent.tier.cleaner.min.cleanable.ratio = 0.75
	confluent.tier.cleaner.num.threads = 2
	confluent.tier.enable = false
	confluent.tier.feature = false
	confluent.tier.fenced.segment.delete.delay.ms = 600000
	confluent.tier.fetcher.async.enable = false
	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
	confluent.tier.fetcher.memorypool.bytes = 0
	confluent.tier.fetcher.num.threads = 4
	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
	confluent.tier.fetcher.offset.cache.period.ms = 60000
	confluent.tier.fetcher.offset.cache.size = 200000
	confluent.tier.gcs.bucket = null
	confluent.tier.gcs.cred.file.path = null
	confluent.tier.gcs.prefix =
	confluent.tier.gcs.region = null
	confluent.tier.gcs.sse.customer.encryption.key = null
	confluent.tier.gcs.write.chunk.size = 0
	confluent.tier.local.hotset.bytes = -1
	confluent.tier.local.hotset.ms = 86400000
	confluent.tier.max.partition.fetch.bytes.override = 0
	confluent.tier.metadata.bootstrap.servers = null
	confluent.tier.metadata.max.poll.ms = 100
	confluent.tier.metadata.namespace = null
	confluent.tier.metadata.num.partitions = 50
	confluent.tier.metadata.replication.factor = 3
	confluent.tier.metadata.request.timeout.ms = 30000
	confluent.tier.metadata.snapshots.enable = false
	confluent.tier.metadata.snapshots.interval.ms = 86400000
	confluent.tier.metadata.snapshots.retention.days = 7
	confluent.tier.metadata.snapshots.threads = 2
	confluent.tier.object.fetcher.num.threads = 1
	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
	confluent.tier.partition.state.cleanup.enable = false
	confluent.tier.partition.state.cleanup.interval.ms = 86400000
	confluent.tier.partition.state.commit.interval.ms = 15000
	confluent.tier.prefetch.cache.enable = false
	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
	confluent.tier.prefetch.cache.range.bytes = 5242880
	confluent.tier.prefetch.cache.total.size.bytes = 209715200
	confluent.tier.s3.assumerole.arn = null
	confluent.tier.s3.auto.abort.threshold.bytes = 500000
	confluent.tier.s3.aws.endpoint.override = null
	confluent.tier.s3.aws.signer.override = null
	confluent.tier.s3.bucket = null
	confluent.tier.s3.cred.file.path = null
	confluent.tier.s3.force.path.style.access = false
	confluent.tier.s3.ipv6.enabled = true
	confluent.tier.s3.prefix =
	confluent.tier.s3.region = null
	confluent.tier.s3.security.providers = null
	confluent.tier.s3.sse.algorithm = AES256
	confluent.tier.s3.sse.customer.encryption.key = null
	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.tier.s3.ssl.key.password = null
	confluent.tier.s3.ssl.keystore.location = null
	confluent.tier.s3.ssl.keystore.password = null
	confluent.tier.s3.ssl.keystore.type = null
	confluent.tier.s3.ssl.protocol = TLSv1.3
	confluent.tier.s3.ssl.provider = null
	confluent.tier.s3.ssl.truststore.location = null
	confluent.tier.s3.ssl.truststore.password = null
	confluent.tier.s3.ssl.truststore.type = null
	confluent.tier.s3.storage.class.override =
	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
	confluent.tier.s3.v2.enabled = false
	confluent.tier.segment.hotset.roll.min.bytes = 104857600
	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
	confluent.tier.topic.data.loss.validation.fencing.enable = false
	confluent.tier.topic.delete.backoff.ms = 21600000
	confluent.tier.topic.delete.check.interval.ms = 300000
	confluent.tier.topic.delete.max.inprogress.partitions = 100
	confluent.tier.topic.head.data.loss.validation.enable = true
	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
	confluent.tier.topic.materialization.from.snapshot.enable = false
	confluent.tier.topic.producer.enable.idempotence = true
	confluent.tier.topic.snapshots.enable = false
	confluent.tier.topic.snapshots.interval.ms = 300000
	confluent.tier.topic.snapshots.max.records = 100000
	confluent.tier.topic.snapshots.retention.hours = 168
	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
	confluent.topic.partition.default.placement = 2
	confluent.topic.policy.use.computed.assignments = false
	confluent.topic.replica.assignor.builder.class =
	confluent.track.api.key.per.ip = false
	confluent.track.per.ip.max.size = 100000
	confluent.track.tenant.id.per.ip = false
	confluent.traffic.cdc.network.id.routes.enable = false
	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
	confluent.traffic.network.id =
	confluent.traffic.network.type =
	confluent.transaction.2pc.timeout.ms = -1
	confluent.transaction.logging.verbosity = 0
	confluent.transaction.state.log.placement.constraints =
	confluent.unique.deprecated.request.metrics.per.tenant = 1000
	confluent.valid.broker.rack.set = null
	confluent.valid.sni.hostnames =
	confluent.valid.sni.hostnames.exclude.suffix =
	confluent.verify.group.subscription.prefix = false
	confluent.virtual.topic.creation.enabled = false
	confluent.zone.tagged.request.metrics.enable = false
	connection.failed.authentication.delay.ms = 100
	connection.min.expire.interval.ms = 250
	connections.max.age.ms = 3153600000000
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@kafka:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.cluster.link.policy.class.name = null
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	enable.fips = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	floor.max.connection.creation.rate = null
	follower.replication.throttled.rate = 9223372036854775807
	follower.replication.throttled.replicas = none
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = SASL_PLAINTEXT
	k2.stack.builder.class.name = null
	k2.startup.timeout.ms = 60000
	k2.topic.metadata.refresh.ms = 10000
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.replication.throttled.rate = 9223372036854775807
	leader.replication.throttled.replicas = none
	listener.security.protocol.map = SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:PLAINTEXT
	listeners = SASL_PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.hash.algorithm = MD5
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.cleanup.policy.empty.validation = none
	log.deletion.max.segments.per.run = 2147483647
	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 1.7976931348623157E308
	max.connection.creation.rate.per.ip.enable.threshold = 0.0
	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.connections.per.tenant = 0
	max.connections.protected.listeners = []
	max.connections.reap.amount = 0
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	multitenant.authorizer.support.resource.ids = false
	multitenant.metadata.class = null
	multitenant.metadata.dir = null
	multitenant.metadata.reload.delay.ms = 120000
	multitenant.metadata.ssl.certs.path = null
	multitenant.tenant.delete.batch.size = 10
	multitenant.tenant.delete.check.ms = 120000
	multitenant.tenant.delete.delay = 604800000
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	otel.exporter.otlp.custom.endpoint = default
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	quotas.consumption.expiration.time.ms = 600000
	quotas.expiration.interval.ms = 3600000
	quotas.expiration.time.ms = 604800000
	quotas.lazy.evaluation.threshold = 0.5
	quotas.topic.append.timeout.ms = 5000
	quotas.topic.compression.codec = 3
	quotas.topic.load.buffer.size = 5242880
	quotas.topic.num.partitions = 50
	quotas.topic.placement.constraints =
	quotas.topic.replication.factor = 3
	quotas.topic.segment.bytes = 104857600
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [PLAIN]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.authn.async.enable = false
	sasl.server.authn.async.max.threads = 1
	sasl.server.authn.async.timeout.ms = 30000
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	throughput.quota.window.num = 11
	token.impersonation.validation = true
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.metadata.load.threads = 32
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,342] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-07-23 11:50:58,342] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-07-23 11:50:58,343] INFO [ControllerServer id=1] The request from broker 1 to unfence has been granted because it has caught up with the offset of its register broker record 7. (org.apache.kafka.controller.BrokerHeartbeatManager)
[2025-07-23 11:50:58,348] INFO [ControllerServer id=1] Replayed BrokerRegistrationChangeRecord modifying the registration for broker 1: BrokerRegistrationChangeRecord(brokerId=1, brokerEpoch=7, fenced=-1, inControlledShutdown=0, degradedComponents=null, logDirs=[]) (org.apache.kafka.controller.ClusterControlManager)
[2025-07-23 11:50:58,373] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,373] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-07-23 11:50:58,373] INFO SBC Event SbcMetadataUpdateEvent-9 generated 1 more events to enqueue in the following order - [SbcKraftBrokerAdditionEvent-10]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,373] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-07-23 11:50:58,373] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-07-23 11:50:58,373] INFO Handling event SbcConfigUpdateEvent-3 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,373] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-07-23 11:50:58,373] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-07-23 11:50:58,374] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2025-07-23 11:50:58,374] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2025-07-23 11:50:58,375] INFO Balancer notified of a config change: ConfigurationsDelta(changes={}) (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,375] INFO There were 0 change(s) and 0 deletion(s) to balancer configs. Changed Configs: {}, Deleted Configs: [] (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,375] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,375] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-07-23 11:50:58,375] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-07-23 11:50:58,375] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-07-23 11:50:58,375] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-07-23 11:50:58,375] INFO Configs metadata not yet available, SBC startup delayed. (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,375] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-07-23 11:50:58,375] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-07-23 11:50:58,375] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-07-23 11:50:58,375] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-07-23 11:50:58,375] INFO Handling event SbcKraftBrokerAdditionEvent-10 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:58,375] INFO Topics Image not present, pausing broker addition event of brokers (new brokers: [1]) until it is received. (io.confluent.databalancer.event.SbcKraftBrokerAdditionEvent)
[2025-07-23 11:50:58,409] INFO Application provider 'MetadataApiApplicationProvider' provided 1 instance(s). (io.confluent.http.server.KafkaHttpApplicationLoader)
[2025-07-23 11:50:58,409] INFO MetadataServerConfig values:
	confluent.http.server.listeners = [http://0.0.0.0:8090]
	confluent.metadata.server.advertised.listeners = [http://localhost:8090]
	confluent.metadata.server.enable = false
	confluent.metadata.server.kraft.controller.enabled = false
	confluent.metadata.server.listeners = [http://0.0.0.0:8090]
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,411] INFO Application provider 'RbacApplicationProvider' did not provide any instances. (io.confluent.http.server.KafkaHttpApplicationLoader)
[2025-07-23 11:50:58,415] INFO KafkaConfig values:
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = SASL_PLAINTEXT://kafka:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
	broker.rack = null
	broker.session.timeout.ms = 9000
	broker.session.uuid = 2yBYTgb0Tf6Hp4Sp67hPyg
	client.quota.callback.class = null
	client.quota.max.throttle.time.in.response.ms = 60000
	client.quota.max.throttle.time.ms = 5000
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	confluent.accp.enabled = false
	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
	confluent.alter.broker.health.max.demoted.brokers = 2147483647
	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
	confluent.ansible.managed = false
	confluent.api.visibility = DEFAULT
	confluent.append.record.interceptor.classes = []
	confluent.apply.create.topic.policy.to.create.partitions = false
	confluent.authorizer.authority.name =
	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
	confluent.backpressure.disk.enable = false
	confluent.backpressure.disk.free.threshold.bytes = 21474836480
	confluent.backpressure.disk.produce.bytes.per.second = 131072
	confluent.backpressure.disk.threshold.recovery.factor = 1.5
	confluent.backpressure.request.min.broker.limit = 200
	confluent.backpressure.request.queue.size.percentile = p95
	confluent.backpressure.types = null
	confluent.balancer.api.state.topic = _confluent_balancer_api_state
	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
	confluent.balancer.capacity.threshold.upper.limit = 0.95
	confluent.balancer.cell.load.upper.bound = 0.7
	confluent.balancer.cell.overload.detection.interval.ms = 3600000
	confluent.balancer.cell.overload.duration.ms = 86400000
	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.cpu.balance.threshold = 1.1
	confluent.balancer.cpu.goal.act.as.capacity.goal = false
	confluent.balancer.cpu.low.utilization.threshold = 0.2
	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
	confluent.balancer.disk.max.load = 0.85
	confluent.balancer.disk.min.free.space.gb = 0
	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
	confluent.balancer.disk.utilization.detector.duration.ms = 600000
	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
	confluent.balancer.enable = true
	confluent.balancer.enable.network.capacity.metric.ingestion = false
	confluent.balancer.exclude.topic.names = []
	confluent.balancer.exclude.topic.prefixes = []
	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	confluent.balancer.incremental.balancing.enabled = false
	confluent.balancer.incremental.balancing.goals = []
	confluent.balancer.incremental.balancing.lower.bound = 0.02
	confluent.balancer.incremental.balancing.min.valid.windows = 5
	confluent.balancer.incremental.balancing.step.ratio = 0.2
	confluent.balancer.inter.cell.balancing.enabled = false
	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
	confluent.balancer.max.replicas = 2147483647
	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.rebalancing.goals = []
	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.resource.utilization.detector.interval.ms = 60000
	confluent.balancer.sbc.metrics.parser.enabled = false
	confluent.balancer.self.healing.maximum.rounds = 1
	confluent.balancer.task.history.retention.days = 30
	confluent.balancer.tenant.maximum.movements = 0
	confluent.balancer.tenant.suspension.ms = 86400000
	confluent.balancer.throttle.bytes.per.second = 10485760
	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
	confluent.balancer.topic.partition.maximum.movements = 3
	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
	confluent.balancer.topic.partition.movements.history.limit = 900
	confluent.balancer.topic.partition.suspension.ms = 3600000
	confluent.balancer.topic.replication.factor = 1
	confluent.balancer.triggering.goals = []
	confluent.balancer.v2.addition.enabled = false
	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
	confluent.balancer.v2.executor.enabled = false
	confluent.basic.auth.credentials.source = null
	confluent.basic.auth.user.info = null
	confluent.bearer.assertion.claim.aud = null
	confluent.bearer.assertion.claim.exp.minutes = null
	confluent.bearer.assertion.claim.iss = null
	confluent.bearer.assertion.claim.jti.include = null
	confluent.bearer.assertion.claim.nbf.include = null
	confluent.bearer.assertion.claim.sub = null
	confluent.bearer.assertion.file = null
	confluent.bearer.assertion.private.key.file = null
	confluent.bearer.assertion.private.key.passphrase = null
	confluent.bearer.assertion.template.file = null
	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
	confluent.bearer.auth.client.id = null
	confluent.bearer.auth.client.secret = null
	confluent.bearer.auth.credentials.source = null
	confluent.bearer.auth.identity.pool.id = null
	confluent.bearer.auth.issuer.endpoint.url = null
	confluent.bearer.auth.logical.cluster = null
	confluent.bearer.auth.scope = null
	confluent.bearer.auth.scope.claim.name = scope
	confluent.bearer.auth.sub.claim.name = sub
	confluent.bearer.auth.token = null
	confluent.broker.health.manager.enabled = true
	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
	confluent.broker.health.manager.hard.kill.duration.ms = 60000
	confluent.broker.health.manager.mitigation.enabled = false
	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
	confluent.broker.health.manager.sample.duration.ms = 1000
	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
	confluent.broker.load.advertised.limit.load = 0.8
	confluent.broker.load.average.service.request.time.ms = 0.1
	confluent.broker.load.delay.metric.start.ms = 180000
	confluent.broker.load.enabled = false
	confluent.broker.load.num.samples = 60
	confluent.broker.load.tenant.metric.enable = false
	confluent.broker.load.update.metric.tags.interval.ms = 60000
	confluent.broker.load.window.size.ms = 60000
	confluent.broker.load.workload.coefficient = 20.0
	confluent.broker.registration.delay.ms = 0
	confluent.calling.resource.identity.type.map =
	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
	confluent.catalog.collector.enable = false
	confluent.catalog.collector.full.configs.enable = false
	confluent.catalog.collector.max.bytes.per.snapshot = 850000
	confluent.catalog.collector.max.topics.process = 500
	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
	confluent.catalog.collector.multitenant.topics.enable = true
	confluent.catalog.collector.snapshot.init.delay.sec = 60
	confluent.catalog.collector.snapshot.interval.sec = 300
	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
	confluent.cdc.api.keys.topic =
	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
	confluent.cdc.client.quotas.enable = false
	confluent.cdc.client.quotas.topic.name =
	confluent.cdc.lkc.metadata.topic =
	confluent.cdc.user.metadata.enable = false
	confluent.cdc.user.metadata.topic = _confluent-user_metadata
	confluent.cell.metrics.refresh.period.ms = 60000
	confluent.cells.default.size = 15
	confluent.cells.enable = false
	confluent.cells.implicit.creation.enable = false
	confluent.cells.k2.base.broker.index = -1
	confluent.cells.load.refresher.enable = true
	confluent.cells.max.size = 15
	confluent.cells.min.size = 6
	confluent.checksum.enabled.files = [none]
	confluent.client.topic.max.metrics.count = 1000
	confluent.client.topic.metrics.expiry.sec = 3600
	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
	confluent.clm.enabled = false
	confluent.clm.frequency.in.hours = 6
	confluent.clm.list.object.thread_pool.size = 1
	confluent.clm.max.backup.days = 3
	confluent.clm.min.delay.in.minutes = 30
	confluent.clm.thread.pool.size = 2
	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
	confluent.close.connections.on.credential.delete = false
	confluent.cluster.link.admin.max.in.flight.requests = 1000
	confluent.cluster.link.admin.request.batch.size = 1
	confluent.cluster.link.allow.config.providers = true
	confluent.cluster.link.allow.legacy.message.format = false
	confluent.cluster.link.allow.truncation.below.hwm = false
	confluent.cluster.link.availability.check.mode = ALL
	confluent.cluster.link.background.thread.affinity = LINK
	confluent.cluster.link.bootstrap.translation.feature.enable = true
	confluent.cluster.link.clients.max.idle.ms = 3153600000000
	confluent.cluster.link.enable = true
	confluent.cluster.link.enable.local.admin = false
	confluent.cluster.link.enable.metrics.reduction = false
	confluent.cluster.link.enable.metrics.reduction.advanced = false
	confluent.cluster.link.fetch.response.min.bytes = 1
	confluent.cluster.link.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.fetcher.auto.tune.enable = false
	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
	confluent.cluster.link.insync.fetch.response.min.bytes = 1
	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
	confluent.cluster.link.intranet.connectivity.enable = false
	confluent.cluster.link.intranet.connectivity.migration.enable = false
	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
	confluent.cluster.link.local.admin.multitenant.enable = false
	confluent.cluster.link.local.reverse.connection.listener.map = null
	confluent.cluster.link.max.client.connections = 2147483647
	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
	confluent.cluster.link.metadata.topic.enable = false
	confluent.cluster.link.metadata.topic.min.isr = 2
	confluent.cluster.link.metadata.topic.partitions = 50
	confluent.cluster.link.metadata.topic.replication.factor = 3
	confluent.cluster.link.mirror.transition.batch.size = 10
	confluent.cluster.link.num.background.threads = 1
	confluent.cluster.link.periodic.task.batch.size = 2147483647
	confluent.cluster.link.periodic.task.min.interval.ms = 1000
	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
	confluent.cluster.link.replica.fetch.connections.mode = combined
	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
	confluent.cluster.link.replication.quota.mode.per.tenant.overrides =
	confluent.cluster.link.replication.quota.window.num = 11
	confluent.cluster.link.replication.quota.window.size.seconds = 2
	confluent.cluster.link.request.quota.capacity = 400
	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
	confluent.cluster.link.switchover.disabled.principals = []
	confluent.cluster.link.switchover.enable = false
	confluent.cluster.link.switchover.listeners = []
	confluent.cluster.link.switchover.server.states = []
	confluent.cluster.link.tenant.replication.quota.enable = false
	confluent.cluster.link.tenant.request.quota.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
	confluent.cluster.metadata.snapshot.tier.upload.enable = false
	confluent.compacted.topic.prefer.tier.fetch.ms = -1
	confluent.connection.invalid.request.delay.enable = false
	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
	confluent.consumer.fetch.partition.pruning.enable = true
	confluent.consumer.lag.emitter.enabled = false
	confluent.consumer.lag.emitter.interval.ms = 60000
	confluent.dataflow.policy.watch.monitor.ms = 300000
	confluent.default.data.policy.enforcement = true
	confluent.defer.isr.shrink.enable = false
	confluent.describe.topic.partitions.enabled = true
	confluent.disk.io.manager.enable = false
	confluent.disk.throughput.headroom = 10485760
	confluent.disk.throughput.limit = 10485760000
	confluent.disk.throughput.quota.tier.archive = 1048576000
	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
	confluent.durability.audit.batch.flush.frequency.ms = 900000
	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
	confluent.durability.audit.enable = false
	confluent.durability.audit.idempotent.producer = false
	confluent.durability.audit.initial.job.delay.ms = 900000
	confluent.durability.audit.io.bytes.per.sec = 10485760
	confluent.durability.audit.log.ignored.event.types =
	confluent.durability.audit.reporting.batch.ms = 1800000
	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
	confluent.durability.topic.partition.count = 50
	confluent.durability.topic.replication.factor = 3
	confluent.e2e_checksum.protection.enabled = false
	confluent.e2e_checksum.protection.files = [none]
	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
	confluent.elastic.cku.enabled = false
	confluent.elastic.cku.scaletozero.enabled = false
	confluent.eligible.controllers = []
	confluent.enable.broker.reporting.min.usage.mode = true
	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.fail.unsatisfied.placement.constraints = false
	confluent.fetch.from.follower.require.leader.epoch.enable = false
	confluent.fetch.partition.pruning.enable = true
	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
	confluent.flexible.fanout.enabled = false
	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
	confluent.flexible.fanout.mode = TENANT_QUOTA
	confluent.floor.connection.rate.per.ip = -1.0
	confluent.floor.connection.rate.per.tenant = -1.0
	confluent.group.coordinator.dynamic.append.linger.enable = false
	confluent.group.coordinator.offsets.batching.enable = false
	confluent.group.coordinator.offsets.writer.threads = 2
	confluent.group.coordinator.txn.offset.validation.enable = false
	confluent.group.highest.offset.commit.rates.log.count = 10
	confluent.group.highest.offset.commit.rates.log.enable = false
	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
	confluent.group.metadata.load.threads = 32
	confluent.group.subscription.pattern.log.interval.ms = -1
	confluent.heap.tenured.notify.bytes = 0
	confluent.heap.tenured.notify.enabled = false
	confluent.hot.partition.ratio = 0.8
	confluent.http.server.start.timeout.ms = 60000
	confluent.http.server.stop.timeout.ms = 30000
	confluent.internal.metrics.enable = false
	confluent.internal.rest.server.bind.port = null
	confluent.internal.rest.server.ssl.enable = false
	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
	confluent.leader.epoch.checkpoint.checksum.enabled = false
	confluent.listener.protocol = TCP
	confluent.log.cleaner.timestamp.validation.enable = true
	confluent.log.placement.constraints =
	confluent.max.broker.load = 1.0
	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
	confluent.max.connection.rate.per.ip = -1.0
	confluent.max.connection.rate.per.tenant = -1.0
	confluent.max.connection.throttle.ms = null
	confluent.max.segment.ms = 9223372036854775807
	confluent.metadata.active.encryptor = null
	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
	confluent.metadata.encryptor.classes = null
	confluent.metadata.encryptor.required = false
	confluent.metadata.encryptor.secret.file = null
	confluent.metadata.encryptor.secrets = null
	confluent.metadata.jvm.warmup.ms = 60000
	confluent.metadata.leader.balance.slice.delay.ms = 100
	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
	confluent.metadata.max.leader.balance.changes.per.slice = 1000
	confluent.metadata.reject.when.throttled.enable = false
	confluent.metadata.server.cluster.registry.clusters = []
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.min.acks = 0
	confluent.min.connection.throttle.ms = 0
	confluent.min.segment.ms = 1
	confluent.missing.id.cache.ttl.sec = 60
	confluent.missing.id.query.range = 20000
	confluent.missing.schema.cache.ttl.sec = 60
	confluent.mtls.build.client.cert.chain.enable = false
	confluent.mtls.enable = false
	confluent.mtls.listener.name = EXTERNAL
	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
	confluent.mtls.truststore.manager.class.name = null
	confluent.multitenant.authorizer.enable.acl.state = false
	confluent.multitenant.interceptor.balancer.apis.enabled = false
	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
	confluent.multitenant.listener.names = null
	confluent.multitenant.parse.lkc.id.enable = false
	confluent.multitenant.parse.sni.host.name.enable = false
	confluent.network.health.manager.enabled = false
	confluent.network.health.manager.external.listener.name = EXTERNAL
	confluent.network.health.manager.externalconnectivitystartup.enabled = false
	confluent.network.health.manager.min.healthy.network.samples = 3
	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
	confluent.network.health.manager.mitigation.enabled = false
	confluent.network.health.manager.network.sample.window.size = 120
	confluent.network.health.manager.sample.duration.ms = 1000
	confluent.oauth.flat.networking.verification.enable = false
	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
	confluent.offsets.topic.placement.constraints =
	confluent.omit.network.processor.metric.tag = false
	confluent.operator.managed = false
	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings =
	confluent.ppv2.endpoint.scheme.enable = false
	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
	confluent.ppv2.endpoint.scheme.template.variable.cloud =
	confluent.ppv2.endpoint.scheme.template.variable.domain =
	confluent.ppv2.endpoint.scheme.template.variable.region =
	confluent.ppv2.endpoint.scheme.template.variables =
	confluent.ppv2.endpoint.scheme.templates =
	confluent.prefer.tier.fetch.ms = -1
	confluent.produce.throttle.pre.check.enable = false
	confluent.produce.throttle.pre.check.for.new.connection.enable = false
	confluent.producer.id.cache.broker.hard.limit = -1
	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
	confluent.producer.id.cache.extra.eviction.percentage = 0
	confluent.producer.id.cache.limit = 2147483647
	confluent.producer.id.cache.partition.hard.limit = -1
	confluent.producer.id.cache.tenant.hard.limit = -1
	confluent.producer.id.quota.manager.enable = false
	confluent.producer.id.quota.window.num = 11
	confluent.producer.id.quota.window.size.seconds = 1
	confluent.producer.id.throttle.enable = false
	confluent.producer.id.throttle.enable.threshold.percentage = 100
	confluent.proxy.mode.local.default = false
	confluent.proxy.protocol.fallback.enabled = false
	confluent.proxy.protocol.version = NONE
	confluent.quota.computing.usage.adjustment = 0.5
	confluent.quota.dynamic.adjustment.min.usage = 102400
	confluent.quota.dynamic.enable = false
	confluent.quota.dynamic.publishing.interval.ms = 60000
	confluent.quota.dynamic.reporting.interval.ms = 30000
	confluent.quota.tenant.broker.max.consumer.rate = 13107200
	confluent.quota.tenant.broker.max.producer.rate = 13107200
	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
	confluent.quota.tenant.fetch.multiplier = 1.0
	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
	confluent.quota.tenant.internal.throttling.enable = false
	confluent.quota.tenant.produce.multiplier = 1.0
	confluent.quota.tenant.user.quotas.enable = false
	confluent.rack.id.mapping = null
	confluent.regional.metadata.client.class = null
	confluent.regional.resource.manager.client.scheduler.threads = 2
	confluent.regional.resource.manager.endpoint = null
	confluent.regional.resource.manager.watch.endpoint = null
	confluent.replica.fetch.backoff.max.ms = 1000
	confluent.replica.fetch.connections.mode = combined
	confluent.replication.mode = PULL
	confluent.replication.push.feature.enable = false
	confluent.reporters.telemetry.auto.enable = true
	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
	confluent.request.pipelining.enable = true
	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
	confluent.require.calling.resource.identity = false
	confluent.require.compatible.keystore.updates = true
	confluent.require.confluent.issuer = false
	confluent.roll.check.interval.ms = 300000
	confluent.schema.registry.max.cache.size = 10000
	confluent.schema.registry.max.retries = 1
	confluent.schema.registry.retries.wait.ms = 0
	confluent.schema.registry.url = null
	confluent.schema.validation.context.name.enable = false
	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
	confluent.schema.validator.multitenant.enable = false
	confluent.schema.validator.samples.per.min = 0
	confluent.security.bc.approved.mode.enable = false
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.config =
	confluent.security.revoked.certificate.ids =
	confluent.segment.eager.roll.enable = false
	confluent.segment.speculative.prefetch.enable = false
	confluent.share.metadata.load.threads = 32
	confluent.spiffe.id.principal.extraction.rules =
	confluent.ssl.key.password = null
	confluent.ssl.keystore.location = null
	confluent.ssl.keystore.password = null
	confluent.ssl.keystore.type = null
	confluent.ssl.protocol = null
	confluent.ssl.truststore.location = null
	confluent.ssl.truststore.password = null
	confluent.ssl.truststore.type = null
	confluent.step.connection.rate.per.ip = -1.0
	confluent.step.connection.rate.per.tenant = -1.0
	confluent.storage.probe.period.ms = -1
	confluent.storage.probe.slow.write.threshold.ms = 5000
	confluent.stray.log.delete.delay.ms = 604800000
	confluent.stray.log.max.deletions.per.run = 72
	confluent.subdomain.prefix = null
	confluent.subdomain.separator.map = null
	confluent.subdomain.separator.variable = %sep
	confluent.system.time.roll.enable = false
	confluent.telemetry.enabled = false
	confluent.telemetry.external.client.metrics.delta.temporality = true
	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
	confluent.telemetry.external.client.metrics.push.enabled = false
	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
	confluent.telemetry.external.client.metrics.subscription.match.list = null
	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
	confluent.tenant.latency.metric.enabled = false
	confluent.tenantaware.encryption.key.manager.enable = false
	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
	confluent.tier.archiver.num.threads = 2
	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
	confluent.tier.azure.block.blob.container = null
	confluent.tier.azure.block.blob.cred.file.path = null
	confluent.tier.azure.block.blob.endpoint = null
	confluent.tier.azure.block.blob.prefix =
	confluent.tier.backend =
	confluent.tier.bucket.probe.period.ms = -1
	confluent.tier.cleaner.compact.min.efficiency = 0.5
	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
	confluent.tier.cleaner.dedupe.buffer.size = 134217728
	confluent.tier.cleaner.dual.compaction = false
	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
	confluent.tier.cleaner.dual.compaction.validation.percent = 0
	confluent.tier.cleaner.enable = false
	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
	confluent.tier.cleaner.feature.enable = false
	confluent.tier.cleaner.io.buffer.load.factor = 0.9
	confluent.tier.cleaner.io.buffer.size = 10485760
	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	confluent.tier.cleaner.min.cleanable.ratio = 0.75
	confluent.tier.cleaner.num.threads = 2
	confluent.tier.enable = false
	confluent.tier.feature = false
	confluent.tier.fenced.segment.delete.delay.ms = 600000
	confluent.tier.fetcher.async.enable = false
	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
	confluent.tier.fetcher.memorypool.bytes = 0
	confluent.tier.fetcher.num.threads = 4
	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
	confluent.tier.fetcher.offset.cache.period.ms = 60000
	confluent.tier.fetcher.offset.cache.size = 200000
	confluent.tier.gcs.bucket = null
	confluent.tier.gcs.cred.file.path = null
	confluent.tier.gcs.prefix =
	confluent.tier.gcs.region = null
	confluent.tier.gcs.sse.customer.encryption.key = null
	confluent.tier.gcs.write.chunk.size = 0
	confluent.tier.local.hotset.bytes = -1
	confluent.tier.local.hotset.ms = 86400000
	confluent.tier.max.partition.fetch.bytes.override = 0
	confluent.tier.metadata.bootstrap.servers = null
	confluent.tier.metadata.max.poll.ms = 100
	confluent.tier.metadata.namespace = null
	confluent.tier.metadata.num.partitions = 50
	confluent.tier.metadata.replication.factor = 3
	confluent.tier.metadata.request.timeout.ms = 30000
	confluent.tier.metadata.snapshots.enable = false
	confluent.tier.metadata.snapshots.interval.ms = 86400000
	confluent.tier.metadata.snapshots.retention.days = 7
	confluent.tier.metadata.snapshots.threads = 2
	confluent.tier.object.fetcher.num.threads = 1
	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
	confluent.tier.partition.state.cleanup.enable = false
	confluent.tier.partition.state.cleanup.interval.ms = 86400000
	confluent.tier.partition.state.commit.interval.ms = 15000
	confluent.tier.prefetch.cache.enable = false
	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
	confluent.tier.prefetch.cache.range.bytes = 5242880
	confluent.tier.prefetch.cache.total.size.bytes = 209715200
	confluent.tier.s3.assumerole.arn = null
	confluent.tier.s3.auto.abort.threshold.bytes = 500000
	confluent.tier.s3.aws.endpoint.override = null
	confluent.tier.s3.aws.signer.override = null
	confluent.tier.s3.bucket = null
	confluent.tier.s3.cred.file.path = null
	confluent.tier.s3.force.path.style.access = false
	confluent.tier.s3.ipv6.enabled = true
	confluent.tier.s3.prefix =
	confluent.tier.s3.region = null
	confluent.tier.s3.security.providers = null
	confluent.tier.s3.sse.algorithm = AES256
	confluent.tier.s3.sse.customer.encryption.key = null
	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.tier.s3.ssl.key.password = null
	confluent.tier.s3.ssl.keystore.location = null
	confluent.tier.s3.ssl.keystore.password = null
	confluent.tier.s3.ssl.keystore.type = null
	confluent.tier.s3.ssl.protocol = TLSv1.3
	confluent.tier.s3.ssl.provider = null
	confluent.tier.s3.ssl.truststore.location = null
	confluent.tier.s3.ssl.truststore.password = null
	confluent.tier.s3.ssl.truststore.type = null
	confluent.tier.s3.storage.class.override =
	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
	confluent.tier.s3.v2.enabled = false
	confluent.tier.segment.hotset.roll.min.bytes = 104857600
	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
	confluent.tier.topic.data.loss.validation.fencing.enable = false
	confluent.tier.topic.delete.backoff.ms = 21600000
	confluent.tier.topic.delete.check.interval.ms = 300000
	confluent.tier.topic.delete.max.inprogress.partitions = 100
	confluent.tier.topic.head.data.loss.validation.enable = true
	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
	confluent.tier.topic.materialization.from.snapshot.enable = false
	confluent.tier.topic.producer.enable.idempotence = true
	confluent.tier.topic.snapshots.enable = false
	confluent.tier.topic.snapshots.interval.ms = 300000
	confluent.tier.topic.snapshots.max.records = 100000
	confluent.tier.topic.snapshots.retention.hours = 168
	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
	confluent.topic.partition.default.placement = 2
	confluent.topic.policy.use.computed.assignments = false
	confluent.topic.replica.assignor.builder.class =
	confluent.track.api.key.per.ip = false
	confluent.track.per.ip.max.size = 100000
	confluent.track.tenant.id.per.ip = false
	confluent.traffic.cdc.network.id.routes.enable = false
	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
	confluent.traffic.network.id =
	confluent.traffic.network.type =
	confluent.transaction.2pc.timeout.ms = -1
	confluent.transaction.logging.verbosity = 0
	confluent.transaction.state.log.placement.constraints =
	confluent.unique.deprecated.request.metrics.per.tenant = 1000
	confluent.valid.broker.rack.set = null
	confluent.valid.sni.hostnames =
	confluent.valid.sni.hostnames.exclude.suffix =
	confluent.verify.group.subscription.prefix = false
	confluent.virtual.topic.creation.enabled = false
	confluent.zone.tagged.request.metrics.enable = false
	connection.failed.authentication.delay.ms = 100
	connection.min.expire.interval.ms = 250
	connections.max.age.ms = 3153600000000
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@kafka:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.cluster.link.policy.class.name = null
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	enable.fips = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	floor.max.connection.creation.rate = null
	follower.replication.throttled.rate = 9223372036854775807
	follower.replication.throttled.replicas = none
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = SASL_PLAINTEXT
	k2.stack.builder.class.name = null
	k2.startup.timeout.ms = 60000
	k2.topic.metadata.refresh.ms = 10000
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.replication.throttled.rate = 9223372036854775807
	leader.replication.throttled.replicas = none
	listener.security.protocol.map = SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:PLAINTEXT
	listeners = SASL_PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.hash.algorithm = MD5
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.cleanup.policy.empty.validation = none
	log.deletion.max.segments.per.run = 2147483647
	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 1.7976931348623157E308
	max.connection.creation.rate.per.ip.enable.threshold = 0.0
	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.connections.per.tenant = 0
	max.connections.protected.listeners = []
	max.connections.reap.amount = 0
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	multitenant.authorizer.support.resource.ids = false
	multitenant.metadata.class = null
	multitenant.metadata.dir = null
	multitenant.metadata.reload.delay.ms = 120000
	multitenant.metadata.ssl.certs.path = null
	multitenant.tenant.delete.batch.size = 10
	multitenant.tenant.delete.check.ms = 120000
	multitenant.tenant.delete.delay = 604800000
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	otel.exporter.otlp.custom.endpoint = default
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	quotas.consumption.expiration.time.ms = 600000
	quotas.expiration.interval.ms = 3600000
	quotas.expiration.time.ms = 604800000
	quotas.lazy.evaluation.threshold = 0.5
	quotas.topic.append.timeout.ms = 5000
	quotas.topic.compression.codec = 3
	quotas.topic.load.buffer.size = 5242880
	quotas.topic.num.partitions = 50
	quotas.topic.placement.constraints =
	quotas.topic.replication.factor = 3
	quotas.topic.segment.bytes = 104857600
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [PLAIN]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.authn.async.enable = false
	sasl.server.authn.async.max.threads = 1
	sasl.server.authn.async.timeout.ms = 30000
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	throughput.quota.window.num = 11
	token.impersonation.validation = true
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.metadata.load.threads = 32
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,426] INFO Unexpected credentials store injected: null (io.confluent.kafkarest.servlet.KafkaRestApplicationProvider)
[2025-07-23 11:50:58,428] INFO For rest-app with listener null, configuring custom request logging (io.confluent.kafkarest.KafkaRestApplication)
[2025-07-23 11:50:58,430] INFO EventEmitterConfig values:
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,430] INFO EventEmitterConfig values:
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,430] INFO ConfluentTelemetryConfig values:
	confluent.telemetry.api.key = null
	confluent.telemetry.api.secret = null
	confluent.telemetry.cluster.id = null
	confluent.telemetry.debug.enabled = false
	confluent.telemetry.enabled = false
	confluent.telemetry.events.collector.include = .*transaction.remove.expired.transaction.cleanup.interval.ms.*|.*transaction.state.log.load.buffer.size.*|.*transaction.state.log.min.isr.*|.*transaction.state.log.num.partitions.*|.*transaction.state.log.replication.factor.*|.*transaction.state.log.segment.bytes.*|.*transactional.id.expiration.ms.*|.*controlled.shutdown.enable.*|.*fetch.max.bytes.*|.*fetch.purgatory.purge.interval.requests.*|.*group.initial.rebalance.delay.ms.*|.*group.max.session.timeout.ms.*|.*group.max.size.*|.*group.min.session.timeout.ms.*|.*log.cleaner.backoff.ms.*|.*log.cleaner.dedupe.buffer.size.*|.*log.cleaner.delete.retention.ms.*|.*log.cleaner.enable.*|.*log.cleaner.io.buffer.load.factor.*|.*log.cleaner.io.buffer.size.*|.*log.cleaner.io.max.bytes.per.second.*|.*log.cleaner.max.compaction.lag.ms.*|.*log.cleaner.min.cleanable.ratio.*|.*log.cleaner.min.compaction.lag.ms.*|.*log.cleaner.threads.*|.*log.cleanup.policy.*|.*log.index.interval.bytes.*|.*log.index.size.max.bytes.*|.*log.message.downconversion.enable.*|.*log.message.format.version.*|.*log.message.timestamp.difference.max.ms.*|.*log.message.timestamp.type.*|.*max.connection.creation.rate.*|.*max.connections.*|.*max.connections.per.ip.*|.*max.incremental.fetch.session.cache.slots.*|.*replica.fetch.backoff.ms.*|.*replica.fetch.max.bytes.*|.*replica.fetch.min.bytes.*|.*replica.fetch.response.max.bytes.*|.*replica.fetch.wait.max.ms.*|.*replica.high.watermark.checkpoint.interval.ms.*|.*replica.lag.time.max.ms.*|.*replica.selector.class.*|.*replica.socket.receive.buffer.bytes.*|.*replica.socket.timeout.ms.*|.*alter.config.policy.class.name.*|.*alter.log.dirs.replication.quota.window.num.*|.*alter.log.dirs.replication.quota.window.size.seconds.*|.*metrics.num.samples.*|.*metrics.recording.level.*|.*metrics.sample.window.ms.*|.*quota.window.num.*|.*quota.window.size.seconds.*|.*replication.quota.window.num.*|.*replication.quota.window.size.seconds.*|.*confluent.balancer.enable.*|.*confluent.balancer.throttle.bytes.per.second.*|.*confluent.balancer.heal.uneven.load.trigger.*|.*confluent.balancer.heal.broker.failure.threshold.ms.*|.*confluent.balancer.disk.max.load.*|.*confluent.balancer.exclude.topic.prefixes.*|.*confluent.balancer.exclude.topic.names.*|.*confluent.tier.local.hotset.bytes.*|.*confluent.tier.local.hotset.ms.*|.*confluent.tier.archiver.num.threads.*|.*confluent.tier.backend.*|.*confluent.tier.enable.*|.*confluent.tier.feature.*|.*confluent.tier.fetcher.num.threads.*|.*confluent.tier.max.partition.fetch.bytes.override.*|.*confluent.tier.metadata.replication.factor.*|.*confluent.operator.managed.*|.*confluent.ansible.managed.*|.*confluent.license.*
	confluent.telemetry.events.enable = true
	confluent.telemetry.external.client.metrics.exclude.labels =
	confluent.telemetry.metrics.collector.include = .*io\.confluent\.system/(?:.*/)?(process_cpu_load|max_file_descriptor_count|open_file_descriptor_count|system_cpu_load|system_load_average|free_physical_memory_size|total_physical_memory_size|disk_total_bytes|disk_usable_bytes|jvm/mem|jvm/gc).*
	confluent.telemetry.metrics.collector.interval.ms = 60000
	confluent.telemetry.metrics.collector.slo.enabled = false
	confluent.telemetry.proxy.password = null
	confluent.telemetry.proxy.url = null
	confluent.telemetry.proxy.username = null
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,430] INFO VolumeMetricsCollectorConfig values:
	confluent.telemetry.metrics.collector.volume.update.ms = 15000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,430] INFO HttpClientConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = httpTelemetryClient
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,430] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client = _confluentClient
	client.attempts.max = null
	client.base.url = null
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = false
	events.enabled = true
	metrics.enabled = true
	metrics.include = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	remote.configurable = true
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,431] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
[2025-07-23 11:50:58,431] WARN no telemetry exporters are enabled (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-07-23 11:50:58,431] INFO PollingRemoteConfigurationConfig values:
	enabled = true
	refresh.interval.ms = 60000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,431] WARN Ignoring redefinition of existing telemetry label kafka_rest.version (io.confluent.telemetry.ResourceBuilderFacade)
[2025-07-23 11:50:58,431] INFO ConfluentTelemetryConfig values:
	confluent.telemetry.api.key = null
	confluent.telemetry.api.secret = null
	confluent.telemetry.cluster.id = null
	confluent.telemetry.debug.enabled = false
	confluent.telemetry.enabled = false
	confluent.telemetry.events.collector.include = .*transaction.remove.expired.transaction.cleanup.interval.ms.*|.*transaction.state.log.load.buffer.size.*|.*transaction.state.log.min.isr.*|.*transaction.state.log.num.partitions.*|.*transaction.state.log.replication.factor.*|.*transaction.state.log.segment.bytes.*|.*transactional.id.expiration.ms.*|.*controlled.shutdown.enable.*|.*fetch.max.bytes.*|.*fetch.purgatory.purge.interval.requests.*|.*group.initial.rebalance.delay.ms.*|.*group.max.session.timeout.ms.*|.*group.max.size.*|.*group.min.session.timeout.ms.*|.*log.cleaner.backoff.ms.*|.*log.cleaner.dedupe.buffer.size.*|.*log.cleaner.delete.retention.ms.*|.*log.cleaner.enable.*|.*log.cleaner.io.buffer.load.factor.*|.*log.cleaner.io.buffer.size.*|.*log.cleaner.io.max.bytes.per.second.*|.*log.cleaner.max.compaction.lag.ms.*|.*log.cleaner.min.cleanable.ratio.*|.*log.cleaner.min.compaction.lag.ms.*|.*log.cleaner.threads.*|.*log.cleanup.policy.*|.*log.index.interval.bytes.*|.*log.index.size.max.bytes.*|.*log.message.downconversion.enable.*|.*log.message.format.version.*|.*log.message.timestamp.difference.max.ms.*|.*log.message.timestamp.type.*|.*max.connection.creation.rate.*|.*max.connections.*|.*max.connections.per.ip.*|.*max.incremental.fetch.session.cache.slots.*|.*replica.fetch.backoff.ms.*|.*replica.fetch.max.bytes.*|.*replica.fetch.min.bytes.*|.*replica.fetch.response.max.bytes.*|.*replica.fetch.wait.max.ms.*|.*replica.high.watermark.checkpoint.interval.ms.*|.*replica.lag.time.max.ms.*|.*replica.selector.class.*|.*replica.socket.receive.buffer.bytes.*|.*replica.socket.timeout.ms.*|.*alter.config.policy.class.name.*|.*alter.log.dirs.replication.quota.window.num.*|.*alter.log.dirs.replication.quota.window.size.seconds.*|.*metrics.num.samples.*|.*metrics.recording.level.*|.*metrics.sample.window.ms.*|.*quota.window.num.*|.*quota.window.size.seconds.*|.*replication.quota.window.num.*|.*replication.quota.window.size.seconds.*|.*confluent.balancer.enable.*|.*confluent.balancer.throttle.bytes.per.second.*|.*confluent.balancer.heal.uneven.load.trigger.*|.*confluent.balancer.heal.broker.failure.threshold.ms.*|.*confluent.balancer.disk.max.load.*|.*confluent.balancer.exclude.topic.prefixes.*|.*confluent.balancer.exclude.topic.names.*|.*confluent.tier.local.hotset.bytes.*|.*confluent.tier.local.hotset.ms.*|.*confluent.tier.archiver.num.threads.*|.*confluent.tier.backend.*|.*confluent.tier.enable.*|.*confluent.tier.feature.*|.*confluent.tier.fetcher.num.threads.*|.*confluent.tier.max.partition.fetch.bytes.override.*|.*confluent.tier.metadata.replication.factor.*|.*confluent.operator.managed.*|.*confluent.ansible.managed.*|.*confluent.license.*
	confluent.telemetry.events.enable = true
	confluent.telemetry.external.client.metrics.exclude.labels =
	confluent.telemetry.metrics.collector.include = .*io.confluent.telemetry/.*.*|.*io\.confluent\.system/(?:.*/)?(process_cpu_load|max_file_descriptor_count|open_file_descriptor_count|system_cpu_load|system_load_average|free_physical_memory_size|total_physical_memory_size|disk_total_bytes|disk_usable_bytes|jvm/mem|jvm/gc).*|.*io.confluent.kafka.rest/.*(connections_active|connections_closed_rate|request_error_rate|request_latency_avg|request_latency_max|request_rate|response_size_avg|response_size_max).*
	confluent.telemetry.metrics.collector.interval.ms = 60000
	confluent.telemetry.metrics.collector.slo.enabled = false
	confluent.telemetry.proxy.password = null
	confluent.telemetry.proxy.url = null
	confluent.telemetry.proxy.username = null
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,431] INFO VolumeMetricsCollectorConfig values:
	confluent.telemetry.metrics.collector.volume.update.ms = 15000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,431] INFO HttpClientConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = httpTelemetryClient
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,431] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client = _confluentClient
	client.attempts.max = null
	client.base.url = null
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = false
	events.enabled = true
	metrics.enabled = true
	metrics.include = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	remote.configurable = true
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,431] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
[2025-07-23 11:50:58,432] WARN no telemetry exporters are enabled (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-07-23 11:50:58,432] INFO PollingRemoteConfigurationConfig values:
	enabled = true
	refresh.interval.ms = 60000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,432] INFO Initializing the event logger (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-07-23 11:50:58,432] INFO EventLoggerConfig values:
	event.logger.cloudevent.codec = structured
	event.logger.exporter.class = class io.confluent.telemetry.events.exporter.http.EventHttpExporter
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,432] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = true
	events.enabled = true
	filtering.enabled = false
	filtering.routes.allowed = []
	metrics.enabled = true
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,484] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:50:58,484] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:50:58,490] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:50:58,495] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 11:50:58,495] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 11:50:58,554] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = true
	events.enabled = true
	filtering.enabled = false
	filtering.routes.allowed = []
	metrics.enabled = true
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,554] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = true
	events.enabled = true
	filtering.enabled = false
	filtering.routes.allowed = []
	metrics.enabled = true
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,597] INFO Creating kafka exporter named '_local' (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-07-23 11:50:58,603] INFO Kafka Exporter _local getting producer client  (io.confluent.telemetry.exporter.kafka.KafkaExporter)
[2025-07-23 11:50:58,603] INFO Creating new non-static producer client (io.confluent.telemetry.exporter.kafka.KafkaClientFactory)
[2025-07-23 11:50:58,607] INFO ProducerConfig values:
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = confluent-telemetry-reporter-local-producer
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = zstd
	compression.zstd.level = 3
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 10485760
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = class io.confluent.telemetry.events.exporter.kafka.RandomBrokerPartitionSubsetPartitioner
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.telemetry.serde.OpenTelemetryMetricsSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,621] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:58,622] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:58,622] INFO Kafka startTimeMs: 1753271458621 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:58,630] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Cluster ID: 4L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-07-23 11:50:58,675] INFO Starting Confluent telemetry reporter with an interval of 60000 ms) (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-07-23 11:50:58,675] INFO Starting Confluent telemetry reporter with an interval of 60000 ms) (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-07-23 11:50:58,692] ERROR Unable to submit events without credentials (io.confluent.telemetry.events.exporter.http.HttpExporter)
[2025-07-23 11:50:58,692] ERROR Unable to submit events without credentials (io.confluent.telemetry.events.exporter.http.HttpExporter)
[2025-07-23 11:50:58,692] INFO Application provider 'KafkaRestApplicationProvider' provided 1 instance(s). (io.confluent.http.server.KafkaHttpApplicationLoader)
[2025-07-23 11:50:58,698] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2025-07-23 11:50:58,703] INFO DynamicMetricsReporters initiated successfully. (kafka.server.DynamicMetricsReportersScheduler)
[2025-07-23 11:50:58,703] INFO DynamicMetricsReporters initiated successfully. (kafka.server.DynamicMetricsReportersScheduler)
[2025-07-23 11:50:58,703] INFO Stopping DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
[2025-07-23 11:50:58,703] INFO Stopping DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
[2025-07-23 11:50:58,800] INFO Adding listener with HTTP/2: NamedURI{uri=http://0.0.0.0:8090, name='null'} (io.confluent.rest.ApplicationServer)
[2025-07-23 11:50:58,813] INFO Loaded KafkaHttpServer implementation class io.confluent.http.server.KafkaHttpServerImpl (io.confluent.kafka.http.server.KafkaHttpServerLoader)
[2025-07-23 11:50:58,814] INFO KafkaHttpServer transitioned from NEW to STARTING.. (io.confluent.http.server.KafkaHttpServerImpl)
[2025-07-23 11:50:58,818] INFO Registered CombinedNetworkTrafficListener to network connector null of listener: null (io.confluent.rest.ApplicationServer)
[2025-07-23 11:50:58,882] INFO Binding MetadataApiApplication to all listeners. (io.confluent.rest.Application)
[2025-07-23 11:50:58,891] INFO Registered CombinedNetworkTrafficListener to network connector null of listener: null (io.confluent.rest.ApplicationServer)
[2025-07-23 11:50:58,933] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-07-23 11:50:58,933] INFO SchemaRegistryConfig values:
	auto.register.schemas = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host =
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	schema.registry.url.randomize = false
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:58,940] INFO Binding EmbeddedKafkaRestApplication to all listeners. (io.confluent.rest.Application)
[2025-07-23 11:50:58,957] INFO jetty-12.0.16; built: 2024-12-09T21:02:54.535Z; git: c3f88bafb4e393f23204dc14dc57b042e84debc7; jvm 21.0.7+6-LTS (org.eclipse.jetty.server.Server)
[2025-07-23 11:50:59,000] INFO Session workerName=node0 (org.eclipse.jetty.session.DefaultSessionIdManager)
[2025-07-23 11:50:59,009] INFO Started oeje10s.ServletContextHandler@4a83758f{/v1/metadata,/v1/metadata,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@61654e67{STARTED}} (org.eclipse.jetty.server.handler.ContextHandler)
[2025-07-23 11:50:59,243] INFO HV000001: Hibernate Validator 8.0.1.Final (org.hibernate.validator.internal.util.Version)
[2025-07-23 11:50:59,378] INFO Started oeje10s.ServletContextHandler@4a83758f{/v1/metadata,/v1/metadata,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@61654e67{STARTED}} (org.eclipse.jetty.ee10.servlet.ServletContextHandler)
[2025-07-23 11:50:59,378] INFO Started oeje10s.ServletContextHandler@72f716f6{/kafka,/kafka,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@7f5688f5{STARTED}} (org.eclipse.jetty.server.handler.ContextHandler)
[2025-07-23 11:50:59,394] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-07-23 11:50:59,396] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-07-23 11:50:59,402] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-07-23 11:50:59,409] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-07-23 11:50:59,466] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:50:59,466] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:50:59,466] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:50:59,675] INFO Started oeje10s.ServletContextHandler@72f716f6{/kafka,/kafka,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@7f5688f5{STARTED}} (org.eclipse.jetty.ee10.servlet.ServletContextHandler)
[2025-07-23 11:50:59,706] INFO Started oeje10s.ServletContextHandler@3603863d{/ws,/ws,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@3772c472{STARTED}} (org.eclipse.jetty.server.handler.ContextHandler)
[2025-07-23 11:50:59,707] INFO Started oeje10s.ServletContextHandler@3603863d{/ws,/ws,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@3772c472{STARTED}} (org.eclipse.jetty.ee10.servlet.ServletContextHandler)
[2025-07-23 11:50:59,708] INFO Started oeje10s.ServletContextHandler@403a04f3{/ws,/ws,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@7489f5f3{STARTED}} (org.eclipse.jetty.server.handler.ContextHandler)
[2025-07-23 11:50:59,708] INFO Started oeje10s.ServletContextHandler@403a04f3{/ws,/ws,b=null,a=AVAILABLE,h=oeje10s.SessionHandler@7489f5f3{STARTED}} (org.eclipse.jetty.ee10.servlet.ServletContextHandler)
[2025-07-23 11:50:59,712] INFO Getter/setter type mismatch for mbean attribute formEncodedMethods in class org.eclipse.jetty.server.HttpConfiguration, attribute will be read-only (org.eclipse.jetty.jmx.MetaData)
[2025-07-23 11:50:59,721] INFO Started NetworkTrafficServerConnector@744fb110{HTTP/1.1, (http/1.1, h2c)}{0.0.0.0:8090} (org.eclipse.jetty.server.AbstractConnector)
[2025-07-23 11:50:59,723] INFO Started icr.ApplicationServer@62a41279{STARTING}[12.0.16,sto=5000] @3661ms (org.eclipse.jetty.server.Server)
[2025-07-23 11:50:59,723] INFO KafkaHttpServer transitioned from STARTING to RUNNING.. (io.confluent.http.server.KafkaHttpServerImpl)
[2025-07-23 11:50:59,730] INFO LicenseConfig values:
	confluent.license = [hidden]
	confluent.license.retry.backoff.max.ms = 100000
	confluent.license.retry.backoff.min.ms = 1000
	confluent.license.topic = _confluent-license
	confluent.license.topic.create.timeout.ms = 600000
	confluent.license.topic.replication.factor = 1
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,730] INFO LicenseConfig values:
	confluent.license = [hidden]
	confluent.license.retry.backoff.max.ms = 100000
	confluent.license.retry.backoff.min.ms = 1000
	confluent.license.topic = _confluent-license
	confluent.license.topic.create.timeout.ms = 600000
	confluent.license.topic.replication.factor = 1
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,742] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,744] INFO These configurations '[replication.factor, confluent.metadata.server.advertised.listeners, confluent.metrics.reporter.topic.replicas, confluent.metadata.server.listeners, confluent.metadata.server.authentication.method, min.insync.replicas, confluent.link.metadata.topic.replication, confluent.metadata.server.user.store, confluent.tier.metadata.replication, cluster.link.metadata.topic.replication, confluent.metadata.server.user.store.file.path, transaction.state.log.replication, confluent.metadata.server.user.store.file.hot.reload, confluent.balancer.topic.replication, confluent.durability.topic.replication, confluent.command.topic.replication, topic.replication, confluent.cluster.link.metadata.topic.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,744] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,744] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,744] INFO Kafka startTimeMs: 1753271459744 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,768] INFO App info kafka.admin.client for _confluent-license-admin-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,778] INFO Starting License Store (io.confluent.license.LicenseStore)
[2025-07-23 11:50:59,778] INFO Starting KafkaBasedLog with topic _confluent-command reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-07-23 11:50:59,778] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,779] INFO These configurations '[replication.factor, confluent.metadata.server.advertised.listeners, confluent.metrics.reporter.topic.replicas, confluent.metadata.server.listeners, confluent.metadata.server.authentication.method, min.insync.replicas, confluent.link.metadata.topic.replication, confluent.metadata.server.user.store, confluent.tier.metadata.replication, cluster.link.metadata.topic.replication, confluent.metadata.server.user.store.file.path, transaction.state.log.replication, confluent.metadata.server.user.store.file.hot.reload, confluent.balancer.topic.replication, confluent.durability.topic.replication, confluent.command.topic.replication, topic.replication, confluent.cluster.link.metadata.topic.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,779] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,779] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,779] INFO Kafka startTimeMs: 1753271459779 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,792] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-command. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:50:59,792] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-command. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:50:59,798] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-command', numPartitions=1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='1')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): SUCCESS (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:50:59,799] INFO [ControllerServer id=1] Replayed TopicRecord for topic _confluent-command with topic ID e5N4tcpzTACUGlK4qcj-4Q. (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:50:59,799] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-command') which set configuration cleanup.policy to compact (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:50:59,799] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-command') which set configuration min.insync.replicas to 1 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:50:59,801] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-command-0 with topic ID e5N4tcpzTACUGlK4qcj-4Q and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:50:59,807] INFO SBC Event SbcMetadataUpdateEvent-13 generated 1 more events to enqueue in the following order - [SbcConfigUpdateEvent-14]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:59,807] INFO Handling event SbcKraftStartupEvent-5 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:59,807] INFO Balancer Status state for brokers [1] transitioned from BALANCER_EVENT_RECEIVED to STARTING due to event INITIALIZING_CRUISE_CONTROL. (io.confluent.databalancer.operation.StateMachine)
[2025-07-23 11:50:59,807] INFO DataBalancer: Activating SBC with io.confluent.databalancer.BrokersMetadataSnapshot@7111236e (io.confluent.databalancer.KafkaDataBalanceManager)
[2025-07-23 11:50:59,808] INFO App info kafka.admin.client for _confluent-license-admin-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,808] INFO DataBalancer: Scheduling DataBalanceEngine Startup (io.confluent.databalancer.ConfluentDataBalanceEngine)
[2025-07-23 11:50:59,809] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:50:59,809] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:50:59,810] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-command-0) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:50:59,810] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-command-0) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:50:59,810] INFO ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-consumer-1
	client.rack =
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,811] INFO [Broker id=1] Creating new partition _confluent-command-0 with topic id e5N4tcpzTACUGlK4qcj-4Q. (state.change.logger)
[2025-07-23 11:50:59,811] INFO [Broker id=1] Creating new partition _confluent-command-0 with topic id e5N4tcpzTACUGlK4qcj-4Q. (state.change.logger)
[2025-07-23 11:50:59,811] INFO Handling event SbcKraftBrokerAdditionEvent-10 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:59,812] INFO Processing SbcKraftBrokerAdditionEvent-10 event with data: empty_brokers: [], new_brokers: [1] (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:59,812] WARN Notified of broker additions (empty broker ids [], new brokers [1]) but DataBalancer is disabled -- ignoring for now (io.confluent.databalancer.KafkaDataBalanceManager)
[2025-07-23 11:50:59,812] INFO Handling event SbcConfigUpdateEvent-14 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:59,812] INFO Balancer notified of a config change: ConfigurationsDelta(changes={ConfigResource(type=TOPIC, name='_confluent-command')=ConfigurationDelta(changedKeys=[cleanup.policy, min.insync.replicas])}) (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:59,812] INFO There were 0 change(s) and 0 deletion(s) to balancer configs. Changed Configs: {}, Deleted Configs: [] (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:50:59,813] INFO DataBalancer: Bootstrap server endpoint is Endpoint(listenerName='SASL_PLAINTEXT', securityProtocol=SASL_PLAINTEXT, host='kafka', port=9092) (io.confluent.databalancer.startup.CruiseControlStartable)
[2025-07-23 11:50:59,813] INFO DataBalancer: BOOTSTRAP_SERVERS determined to be kafka:9092 (io.confluent.databalancer.startup.CruiseControlStartable)
[2025-07-23 11:50:59,813] INFO KafkaCruiseControlConfig values:
	alter.configs.response.timeout.ms = 30000
	anomaly.detection.allow.capacity.estimation = true
	anomaly.detection.goals = [io.confluent.cruisecontrol.analyzer.goals.ReplicaPlacementGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal, io.confluent.cruisecontrol.analyzer.goals.CellAwareGoal, io.confluent.cruisecontrol.analyzer.goals.TenantAwareGoal, io.confluent.cruisecontrol.analyzer.goals.MaxReplicaMovementParallelismGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicationInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ProducerInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal]
	anomaly.detection.interval.ms = 60000
	bootstrap.servers = [kafka:9092]
	broker.addition.detector.allowed.topic.balancing.operation.time.threshold.min = 90
	broker.addition.elapsed.time.ms.completion.threshold = 57600000
	broker.addition.mean.cpu.percent.completion.threshold = 0.5
	broker.capacity.config.resolver.class = class com.linkedin.kafka.cruisecontrol.config.BrokerCapacityResolver
	broker.failure.alert.threshold.ms = 0
	broker.failure.exclude.recently.removed.brokers = true
	broker.failure.self.healing.threshold.ms = 3600000
	broker.metric.sample.aggregator.completeness.cache.size = 5
	broker.removal.shutdown.timeout.ms = 600000
	broker.replica.exclusion.timeout.ms = 120000
	bytes.cpu.contribution.weight = 0.2
	calculated.throttle.ratio = 0.8
	capacity.goal.minimum.improvement.step.percentage = 0.01
	capacity.threshold.upper.limit = 0.95
	cdbe.shutdown.wait.ms = 15000
	cell.load.upper.bound = 0.7
	cell.overload.detection.interval.ms = 3600000
	cell.overload.duration.ms = 86400000
	client.id = kafka-cruise-control
	confluent.balancer.additional.invalidation.duration.ms = 60000
	confluent.cells.enable = false
	confluent.rack.id.mapping = null
	connections.max.idle.ms = 540000
	consume.out.bound.should.balance.FFF.traffic = true
	consumer.out.max.bytes.per.second = 9223372036854775807
	consumer.outbound.capacity.threshold = 0.9
	cpu.balance.threshold = 1.1
	cpu.capacity.threshold = 1.0
	cpu.goal.act.as.capacity.goal = false
	cpu.low.utilization.threshold = 0.2
	cpu.low.utilization.threshold.for.broker.addition = 0.2
	cpu.utilization.detector.duration.ms = 600000
	cpu.utilization.detector.overutilization.threshold = 80.0
	cpu.utilization.detector.underutilization.threshold = 50.0
	default.api.timeout.ms = 60000
	default.replica.movement.strategies = [com.linkedin.kafka.cruisecontrol.executor.strategy.BaseReplicaMovementStrategy]
	describe.broker.exclusion.timeout.ms = 60000
	describe.cluster.response.timeout.ms = 30000
	describe.configs.batch.size = 1000
	describe.configs.response.timeout.ms = 30000
	describe.topics.response.timeout.ms = 30000
	disk.balance.threshold = 1.1
	disk.low.utilization.threshold = 0.2
	disk.max.load = 0.85
	disk.min.free.space.gb = 0
	disk.min.free.space.lower.limit.gb = 0
	disk.read.ratio = 0.2
	disk.utilization.detector.duration.ms = 600000
	disk.utilization.detector.overutilization.threshold = 80.0
	disk.utilization.detector.reserved.capacity = 150000.0
	disk.utilization.detector.underutilization.threshold = 35.0
	dynamic.throttling.enabled = true
	enable.network.capacity.metric.ingestion = false
	execution.progress.check.interval.ms = 7000
	executor.leader.action.timeout.ms = 180000
	executor.notifier.class = class com.linkedin.kafka.cruisecontrol.executor.ExecutorNoopNotifier
	executor.reservation.refresh.time.ms = 60000
	flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	goal.balancedness.priority.weight = 1.1
	goal.balancedness.strictness.weight = 1.5
	goal.violation.delay.on.new.brokers.ms = 1800000
	goal.violation.distribution.threshold.multiplier = 1.1
	goal.violation.exclude.recently.removed.brokers = true
	goals = [com.linkedin.kafka.cruisecontrol.analyzer.goals.MovementExclusionGoal, io.confluent.cruisecontrol.analyzer.goals.ReplicaPlacementGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal, io.confluent.cruisecontrol.analyzer.goals.CellAwareGoal, io.confluent.cruisecontrol.analyzer.goals.TenantAwareGoal, io.confluent.cruisecontrol.analyzer.goals.MaxReplicaMovementParallelismGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicationInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ProducerInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.MirrorInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ConsumerOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.SystemTopicEvenDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderReplicaDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundUsageDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.TopicReplicaDistributionGoal]
	hot.partition.capacity.utilization.threshold = 0.2
	incremental.balancing.cpu.top.proposal.tracking.enabled = true
	incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	incremental.balancing.enabled = false
	incremental.balancing.goals = [com.linkedin.kafka.cruisecontrol.analyzer.goals.MovementExclusionGoal, io.confluent.cruisecontrol.analyzer.goals.ReplicaPlacementGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal, io.confluent.cruisecontrol.analyzer.goals.CellAwareGoal, io.confluent.cruisecontrol.analyzer.goals.TenantAwareGoal, io.confluent.cruisecontrol.analyzer.goals.MaxReplicaMovementParallelismGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicationInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ProducerInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.MirrorInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ConsumerOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.IncrementalCPUResourceDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.IncrementalTopicReplicaDistributionGoal]
	incremental.balancing.lower.bound = 0.02
	incremental.balancing.min.valid.windows = 5
	incremental.balancing.step.ratio = 0.2
	inter.cell.balancing.enabled = false
	invalid.replica.assignment.retry.timeout.ms = 300000
	leader.replica.count.balance.threshold = 1.1
	logdir.response.timeout.ms = 30000
	max.allowed.extrapolations.per.broker = 5
	max.allowed.extrapolations.per.partition = 5
	max.capacity.balancing.delta.percentage = 0.0
	max.replicas = 2147483647
	max.volume.throughput.mb = 0
	maximum.allocated.percentage.for.network.in.capacity.bytes = 0.8
	metadata.client.timeout.ms = 180000
	metadata.ttl = 10000
	metric.sampler.class = class io.confluent.cruisecontrol.metricsreporter.ConfluentTelemetryReporterSampler
	min.samples.per.partition.metrics.window = 1
	min.valid.partition.ratio = 0.95
	minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	network.in.max.bytes.per.second = 9223372036854775807
	network.inbound.balance.threshold = 1.1
	network.inbound.capacity.threshold = 0.8
	network.inbound.low.utilization.threshold = 0.2
	network.out.max.bytes.per.second = 9223372036854775807
	network.outbound.balance.threshold = 1.1
	network.outbound.capacity.threshold = 0.8
	network.outbound.low.utilization.threshold = 0.2
	num.cached.recent.anomaly.states = 10
	num.concurrent.leader.movements = 1000
	num.concurrent.partition.movements.per.broker = 5
	num.concurrent.replica.movements.as.destination.per.broker = 18
	num.concurrent.replica.movements.as.source.per.broker = 12
	num.metric.fetchers = 1
	num.partition.metrics.windows = 12
	partition.metric.sample.aggregator.completeness.cache.size = 5
	partition.metrics.window.ms = 180000
	plan.computation.retry.timeout.ms = 3600000
	populate.default.disk.capacity.from.local = true
	producer.in.max.bytes.per.second = 9223372036854775807
	producer.inbound.capacity.threshold = 0.9
	read.throughput.multiplier = 1.0
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	removal.history.retention.time.ms = 86400000
	replica.count.balance.threshold = 1.1
	replica.movement.strategies = [com.linkedin.kafka.cruisecontrol.executor.strategy.PostponeUrpReplicaMovementStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizePartitionsWithMoreReplicaAdditionsStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizeLargeReplicaMovementStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizeSmallReplicaMovementStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.BaseReplicaMovementStrategy]
	replication.in.max.bytes.per.second = 9223372036854775807
	replication.inbound.capacity.threshold = 0.9
	request.cpu.contribution.weight = 0.8
	request.timeout.ms = 30000
	resource.utilization.detector.interval.ms = 60000
	sampling.allow.cpu.capacity.estimation = true
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sbc.metrics.parser.enabled = false
	security.protocol = SASL_PLAINTEXT
	self.healing.broker.failure.enabled = true
	self.healing.goal.violation.enabled = false
	self.healing.maximum.rounds = 1
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	startup.retry.delay.minutes = 5
	startup.retry.max.hours = 2
	static.throttle.rate.override.enabled = false
	tenant.maximum.movements = 0
	tenant.suspension.ms = 86400000
	throttle.bytes.per.second = 10485760
	topic.balancing.badly.imbalanced.topic.imbalance.score.threshold = 0.3
	topic.balancing.balance.threshold.multiplier = 1.0
	topic.balancing.broker.addition.detector.with.trdg.enabled = false
	topic.balancing.itrdg.with.hard.goals.enabled = false
	topic.balancing.max.reassignments.per.iteration = -1
	topic.balancing.slightly.imbalanced.topic.imbalance.score.threshold = 0.05
	topic.balancing.slightly.imbalanced.topics.percentage.trigger = 0.2
	topic.balancing.trigger.threshold.multiplier = 3.0
	topic.partition.maximum.movements = 3
	topic.partition.movement.expiration.ms = 3600000
	topic.partition.movements.history.limit = 900
	topic.partition.suspension.ms = 3600000
	topics.excluded.from.partition.movement =
	v2.addition.enabled = false
	v2.addition.reassignment.cancellations.enabled = false
	v2.executor.enabled = false
	write.throughput.multiplier = 1.0
	zookeeper.connect = null
	zookeeper.security.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,814] INFO DataBalancer: Instantiating DataBalanceEngine (io.confluent.databalancer.ConfluentDataBalanceEngine)
[2025-07-23 11:50:59,817] INFO DataBalancer: Checking startup components (io.confluent.databalancer.startup.CruiseControlStartable)
[2025-07-23 11:50:59,817] INFO DataBalancer: Checking startup component StartupComponent ConfluentTelemetryReporterSampler (io.confluent.databalancer.startup.StartupComponents)
[2025-07-23 11:50:59,819] WARN Disabling exponential reconnect backoff because reconnect.backoff.ms is set, but reconnect.backoff.max.ms is not. (org.apache.kafka.clients.CommonClientConfigs)
[2025-07-23 11:50:59,820] INFO ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-cruise-control
	client.rack =
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConfluentTelemetryReporterSampler-3298965975882467136
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 2147483647
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 50
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,822] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
[2025-07-23 11:50:59,822] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
[2025-07-23 11:50:59,832] INFO [MergedLog partition=_confluent-command-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:50:59,834] INFO Created log for partition _confluent-command-0 in /var/lib/kafka/data/_confluent-command-0 with properties {cleanup.policy=compact, min.insync.replicas=1} (kafka.log.LogManager)
[2025-07-23 11:50:59,834] INFO Created log for partition _confluent-command-0 in /var/lib/kafka/data/_confluent-command-0 with properties {cleanup.policy=compact, min.insync.replicas=1} (kafka.log.LogManager)
[2025-07-23 11:50:59,835] INFO [Partition _confluent-command-0 broker=1] No checkpointed highwatermark is found for partition _confluent-command-0 (kafka.cluster.Partition)
[2025-07-23 11:50:59,835] INFO [Partition _confluent-command-0 broker=1] No checkpointed highwatermark is found for partition _confluent-command-0 (kafka.cluster.Partition)
[2025-07-23 11:50:59,835] INFO [Partition _confluent-command-0 broker=1] Log loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:50:59,835] INFO [Partition _confluent-command-0 broker=1] Log loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:50:59,836] INFO Setting topicIdPartition e5N4tcpzTACUGlK4qcj-4Q:_confluent-command-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:50:59,836] INFO Setting topicIdPartition e5N4tcpzTACUGlK4qcj-4Q:_confluent-command-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:50:59,837] INFO These configurations '[confluent.metadata.server.advertised.listeners, confluent.metrics.reporter.topic.replicas, confluent.metadata.server.listeners, confluent.metadata.server.authentication.method, confluent.link.metadata.topic.replication, confluent.metadata.server.user.store, confluent.tier.metadata.replication, cluster.link.metadata.topic.replication, confluent.metadata.server.user.store.file.path, transaction.state.log.replication, confluent.metadata.server.user.store.file.hot.reload, confluent.balancer.topic.replication, confluent.durability.topic.replication, confluent.command.topic.replication, topic.replication, confluent.cluster.link.metadata.topic.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,837] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,837] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,837] INFO Kafka startTimeMs: 1753271459837 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,838] INFO [MergedLog partition=_confluent-command-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-command-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:50:59,838] INFO [MergedLog partition=_confluent-command-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-command-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:50:59,838] INFO These configurations '[sasl.oauthbearer.jwks.endpoint.refresh.ms, sasl.kerberos.ticket.renew.window.factor, sasl.oauthbearer.jti.validation.enabled, ssl.keystore.type, sasl.oauthbearer.header.urlencode, ssl.endpoint.identification.algorithm, sasl.login.refresh.buffer.seconds, sasl.login.retry.backoff.max.ms, ssl.truststore.type, sasl.oauthbearer.clock.skew.seconds, sasl.oauthbearer.assertion.claim.exp.minutes, sasl.login.refresh.min.period.seconds, sasl.oauthbearer.scope.claim.name, sasl.login.refresh.window.factor, sasl.login.retry.backoff.ms, sasl.kerberos.kinit.cmd, sasl.oauthbearer.assertion.claim.nbf.include, sasl.kerberos.ticket.renew.jitter, ssl.trustmanager.algorithm, sasl.kerberos.min.time.before.relogin, sasl.oauthbearer.iat.validation.enabled, ssl.protocol, ssl.enabled.protocols, sasl.oauthbearer.sub.claim.name, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms, ssl.keymanager.algorithm, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms, sasl.oauthbearer.assertion.claim.jti.include, sasl.login.refresh.window.jitter]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,838] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,838] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,838] INFO Kafka startTimeMs: 1753271459838 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,839] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler-3298965975882467136] Subscribed to pattern: '_confluent-telemetry-metrics' (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:50:59,843] INFO [Consumer clientId=_confluent-license-consumer-1, groupId=null] Cluster ID: 4L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-07-23 11:50:59,844] INFO [Broker id=1] Leader _confluent-command-0 with topic id Some(e5N4tcpzTACUGlK4qcj-4Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:50:59,844] INFO [Broker id=1] Leader _confluent-command-0 with topic id Some(e5N4tcpzTACUGlK4qcj-4Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:50:59,847] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler-3298965975882467136] Cluster ID: 4L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-07-23 11:50:59,847] INFO Waiting for 1 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:50:59,850] INFO App info kafka.consumer for _confluent-license-consumer-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,850] INFO ProducerConfig values:
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = false
	interceptor.classes = []
	key.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,852] INFO These configurations '[confluent.metadata.server.advertised.listeners, confluent.metrics.reporter.topic.replicas, confluent.metadata.server.listeners, confluent.metadata.server.authentication.method, confluent.link.metadata.topic.replication, confluent.metadata.server.user.store, confluent.tier.metadata.replication, cluster.link.metadata.topic.replication, confluent.metadata.server.user.store.file.path, transaction.state.log.replication, confluent.metadata.server.user.store.file.hot.reload, confluent.balancer.topic.replication, confluent.durability.topic.replication, confluent.command.topic.replication, topic.replication, confluent.cluster.link.metadata.topic.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,852] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,852] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,852] INFO Kafka startTimeMs: 1753271459852 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,852] INFO [DynamicConfigPublisher broker id=1] Updating topic _confluent-command with new configuration : cleanup.policy -> compact,min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
[2025-07-23 11:50:59,852] INFO [DynamicConfigPublisher broker id=1] Updating topic _confluent-command with new configuration : cleanup.policy -> compact,min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
[2025-07-23 11:50:59,853] INFO ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-consumer-1
	client.rack =
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,856] INFO These configurations '[confluent.metadata.server.advertised.listeners, confluent.metrics.reporter.topic.replicas, confluent.metadata.server.listeners, confluent.metadata.server.authentication.method, confluent.link.metadata.topic.replication, confluent.metadata.server.user.store, confluent.tier.metadata.replication, cluster.link.metadata.topic.replication, confluent.metadata.server.user.store.file.path, transaction.state.log.replication, confluent.metadata.server.user.store.file.hot.reload, confluent.balancer.topic.replication, confluent.durability.topic.replication, confluent.command.topic.replication, topic.replication, confluent.cluster.link.metadata.topic.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:50:59,856] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,856] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,856] INFO Kafka startTimeMs: 1753271459856 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:50:59,856] INFO [Producer clientId=_confluent-license-producer-1] Cluster ID: 4L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-07-23 11:50:59,866] INFO [Consumer clientId=_confluent-license-consumer-1, groupId=null] Cluster ID: 4L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-07-23 11:50:59,867] INFO [Consumer clientId=_confluent-license-consumer-1, groupId=null] Assigned to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:50:59,869] INFO [Consumer clientId=_confluent-license-consumer-1, groupId=null] Seeking to AutoOffsetResetStrategy{type=earliest} offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-07-23 11:50:59,894] INFO Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-07-23 11:50:59,894] INFO Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-07-23 11:50:59,894] INFO Started License Store (io.confluent.license.LicenseStore)
[2025-07-23 11:51:00,443] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:51:00,445] INFO These configurations '[replication.factor, confluent.metadata.server.advertised.listeners, confluent.metrics.reporter.topic.replicas, confluent.metadata.server.listeners, confluent.metadata.server.authentication.method, min.insync.replicas, confluent.link.metadata.topic.replication, confluent.metadata.server.user.store, confluent.tier.metadata.replication, cluster.link.metadata.topic.replication, confluent.metadata.server.user.store.file.path, transaction.state.log.replication, confluent.metadata.server.user.store.file.hot.reload, confluent.balancer.topic.replication, confluent.durability.topic.replication, confluent.command.topic.replication, topic.replication, confluent.cluster.link.metadata.topic.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:51:00,445] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,445] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,445] INFO Kafka startTimeMs: 1753271460445 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,454] INFO App info kafka.admin.client for _confluent-license-admin-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,511] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:51:00,512] INFO These configurations '[replication.factor, confluent.metadata.server.advertised.listeners, confluent.metrics.reporter.topic.replicas, confluent.metadata.server.listeners, confluent.metadata.server.authentication.method, min.insync.replicas, confluent.link.metadata.topic.replication, confluent.metadata.server.user.store, confluent.tier.metadata.replication, cluster.link.metadata.topic.replication, confluent.metadata.server.user.store.file.path, transaction.state.log.replication, confluent.metadata.server.user.store.file.hot.reload, confluent.balancer.topic.replication, confluent.durability.topic.replication, confluent.command.topic.replication, topic.replication, confluent.cluster.link.metadata.topic.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:51:00,512] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,513] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,513] INFO Kafka startTimeMs: 1753271460512 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,521] INFO App info kafka.admin.client for _confluent-license-admin-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,521] INFO License for single cluster, single node (io.confluent.license.LicenseManager)
[2025-07-23 11:51:00,524] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-07-23 11:51:00,524] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-07-23 11:51:00,524] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,524] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,524] INFO Kafka startTimeMs: 1753271460524 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:00,525] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
[2025-07-23 11:51:00,525] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
[2025-07-23 11:51:00,873] INFO Waiting for 2 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:51:01,345] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:01,345] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:01,346] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:02,879] INFO Waiting for 4 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:51:04,609] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:04,609] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:04,610] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:06,890] INFO Waiting for 8 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:51:12,920] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:12,920] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:12,922] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:14,903] INFO Waiting for 16 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:51:28,191] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 11:51:28,191] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 11:51:28,196] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 11:51:28,196] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 11:51:30,492] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:30,492] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:30,516] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:30,917] INFO Waiting for 32 seconds for metric reporter topic _confluent-telemetry-metrics to become available. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:51:36,268] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:51254-2-5) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:36,656] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:51264-0-6) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:37,215] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:51274-1-6) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:38,011] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:51276-2-6) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:39,070] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:51278-0-7) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:40,389] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:51294-1-7) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:41,711] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:51300-2-7) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:42,987] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:51306-0-8) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:44,311] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:51310-1-8) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:45,640] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:59692-2-8) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:46,831] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:59708-0-9) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:48,156] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:59720-1-9) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:49,471] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:59724-2-9) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:51:57,772] INFO [ControllerServer id=1] In the last 60000 ms period, 341 controller events were completed, which took an average of 12.20 ms each. The slowest event was createTopics(264611442), which took 75.56 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 11:51:57,819] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 11:51:58,796] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = confluent-telemetry-reporter-local-producer
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:51:58,799] INFO These configurations '[compression.type, enable.idempotence, acks, key.serializer, max.request.size, value.serializer, partitioner.class, interceptor.classes, max.in.flight.requests.per.connection, linger.ms]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:51:58,799] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:58,799] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:58,799] INFO Kafka startTimeMs: 1753271518799 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:58,848] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-telemetry-metrics. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:58,848] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-telemetry-metrics. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:51:58,850] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-telemetry-metrics', numPartitions=12, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='max.message.bytes', value='10485760'), CreatableTopicConfig(name='message.timestamp.type', value='CreateTime'), CreatableTopicConfig(name='min.insync.replicas', value='1'), CreatableTopicConfig(name='retention.ms', value='259200000'), CreatableTopicConfig(name='segment.ms', value='14400000'), CreatableTopicConfig(name='retention.bytes', value='-1')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): SUCCESS (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,850] INFO [ControllerServer id=1] Replayed TopicRecord for topic _confluent-telemetry-metrics with topic ID frYOQqa_RXO0r2eh1ezVKw. (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,850] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-telemetry-metrics') which set configuration max.message.bytes to 10485760 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-telemetry-metrics') which set configuration message.timestamp.type to CreateTime (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-telemetry-metrics') which set configuration min.insync.replicas to 1 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-telemetry-metrics') which set configuration retention.ms to 259200000 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-telemetry-metrics') which set configuration segment.ms to 14400000 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent-telemetry-metrics') which set configuration retention.bytes to -1 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-0 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-1 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-2 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-3 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,851] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-4 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,852] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-5 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,852] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-6 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,852] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-7 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,852] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-8 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,852] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-9 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,852] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-10 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,852] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent-telemetry-metrics-11 with topic ID frYOQqa_RXO0r2eh1ezVKw and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:51:58,878] INFO [Broker id=1] Transitioning 12 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:51:58,878] INFO SBC Event SbcMetadataUpdateEvent-132 generated 1 more events to enqueue in the following order - [SbcConfigUpdateEvent-133]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:51:58,878] INFO [Broker id=1] Transitioning 12 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:51:58,878] INFO Handling event SbcConfigUpdateEvent-133 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:51:58,878] INFO Balancer notified of a config change: ConfigurationsDelta(changes={ConfigResource(type=TOPIC, name='_confluent-telemetry-metrics')=ConfigurationDelta(changedKeys=[max.message.bytes, message.timestamp.type, min.insync.replicas, retention.ms, segment.ms, retention.bytes])}) (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:51:58,878] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-telemetry-metrics-3, _confluent-telemetry-metrics-4, _confluent-telemetry-metrics-5, _confluent-telemetry-metrics-6, _confluent-telemetry-metrics-7, _confluent-telemetry-metrics-8, _confluent-telemetry-metrics-9, _confluent-telemetry-metrics-10, _confluent-telemetry-metrics-11, _confluent-telemetry-metrics-0, _confluent-telemetry-metrics-1, _confluent-telemetry-metrics-2) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:51:58,878] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-telemetry-metrics-3, _confluent-telemetry-metrics-4, _confluent-telemetry-metrics-5, _confluent-telemetry-metrics-6, _confluent-telemetry-metrics-7, _confluent-telemetry-metrics-8, _confluent-telemetry-metrics-9, _confluent-telemetry-metrics-10, _confluent-telemetry-metrics-11, _confluent-telemetry-metrics-0, _confluent-telemetry-metrics-1, _confluent-telemetry-metrics-2) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:51:58,878] INFO There were 0 change(s) and 0 deletion(s) to balancer configs. Changed Configs: {}, Deleted Configs: [] (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:51:58,878] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-3 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,878] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-3 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,879] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-4 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,879] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-4 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,880] INFO Created telemetry topic _confluent-telemetry-metrics (io.confluent.telemetry.exporter.kafka.KafkaExporter)
[2025-07-23 11:51:58,880] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-5 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,880] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-5 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,880] INFO App info kafka.admin.client for confluent-telemetry-reporter-local-producer unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:51:58,881] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-6 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,881] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-6 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,882] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-7 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,882] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-7 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,883] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-8 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,883] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-8 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,884] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-9 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,884] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-9 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,886] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-10 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,886] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-10 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,887] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-11 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,887] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-11 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,887] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-0 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,887] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-0 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,888] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-1 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,888] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-1 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,889] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-2 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,889] INFO [Broker id=1] Creating new partition _confluent-telemetry-metrics-2 with topic id frYOQqa_RXO0r2eh1ezVKw. (state.change.logger)
[2025-07-23 11:51:58,889] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 12 partitions (state.change.logger)
[2025-07-23 11:51:58,889] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 12 partitions (state.change.logger)
[2025-07-23 11:51:58,897] INFO [MergedLog partition=_confluent-telemetry-metrics-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,898] INFO Created log for partition _confluent-telemetry-metrics-11 in /var/lib/kafka/data/_confluent-telemetry-metrics-11 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,898] INFO Created log for partition _confluent-telemetry-metrics-11 in /var/lib/kafka/data/_confluent-telemetry-metrics-11 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,898] INFO [Partition _confluent-telemetry-metrics-11 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-11 (kafka.cluster.Partition)
[2025-07-23 11:51:58,898] INFO [Partition _confluent-telemetry-metrics-11 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-11 (kafka.cluster.Partition)
[2025-07-23 11:51:58,898] INFO [Partition _confluent-telemetry-metrics-11 broker=1] Log loaded for partition _confluent-telemetry-metrics-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,898] INFO [Partition _confluent-telemetry-metrics-11 broker=1] Log loaded for partition _confluent-telemetry-metrics-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,899] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-11 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,899] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-11 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,899] INFO [MergedLog partition=_confluent-telemetry-metrics-11, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-11 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,899] INFO [MergedLog partition=_confluent-telemetry-metrics-11, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-11 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,899] INFO [Broker id=1] Leader _confluent-telemetry-metrics-11 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,899] INFO [Broker id=1] Leader _confluent-telemetry-metrics-11 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,903] INFO [MergedLog partition=_confluent-telemetry-metrics-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,903] INFO Created log for partition _confluent-telemetry-metrics-9 in /var/lib/kafka/data/_confluent-telemetry-metrics-9 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,903] INFO Created log for partition _confluent-telemetry-metrics-9 in /var/lib/kafka/data/_confluent-telemetry-metrics-9 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,903] INFO [Partition _confluent-telemetry-metrics-9 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-9 (kafka.cluster.Partition)
[2025-07-23 11:51:58,903] INFO [Partition _confluent-telemetry-metrics-9 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-9 (kafka.cluster.Partition)
[2025-07-23 11:51:58,904] INFO [Partition _confluent-telemetry-metrics-9 broker=1] Log loaded for partition _confluent-telemetry-metrics-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,904] INFO [Partition _confluent-telemetry-metrics-9 broker=1] Log loaded for partition _confluent-telemetry-metrics-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,904] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-9 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,904] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-9 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,904] INFO Partitioner has null list of partitions to produce to. Calculating partitions to produce to (io.confluent.telemetry.events.exporter.kafka.RandomBrokerPartitionSubsetPartitioner)
[2025-07-23 11:51:58,904] INFO [MergedLog partition=_confluent-telemetry-metrics-9, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-9 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,904] INFO [MergedLog partition=_confluent-telemetry-metrics-9, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-9 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,904] INFO [Broker id=1] Leader _confluent-telemetry-metrics-9 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,904] INFO [Broker id=1] Leader _confluent-telemetry-metrics-9 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,905] INFO Kafka Producer producing to the following subset partitions: {_confluent-telemetry-metrics=[6, 0]} (io.confluent.telemetry.events.exporter.kafka.RandomBrokerPartitionSubsetPartitioner)
[2025-07-23 11:51:58,906] INFO [MergedLog partition=_confluent-telemetry-metrics-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,907] INFO Created log for partition _confluent-telemetry-metrics-0 in /var/lib/kafka/data/_confluent-telemetry-metrics-0 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,907] INFO Created log for partition _confluent-telemetry-metrics-0 in /var/lib/kafka/data/_confluent-telemetry-metrics-0 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,907] INFO [Partition _confluent-telemetry-metrics-0 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,907] INFO [Partition _confluent-telemetry-metrics-0 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,907] INFO [Partition _confluent-telemetry-metrics-0 broker=1] Log loaded for partition _confluent-telemetry-metrics-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,907] INFO [Partition _confluent-telemetry-metrics-0 broker=1] Log loaded for partition _confluent-telemetry-metrics-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,908] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,908] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,908] INFO [MergedLog partition=_confluent-telemetry-metrics-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,908] INFO [MergedLog partition=_confluent-telemetry-metrics-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,908] INFO [Broker id=1] Leader _confluent-telemetry-metrics-0 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,908] INFO [Broker id=1] Leader _confluent-telemetry-metrics-0 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,911] INFO [MergedLog partition=_confluent-telemetry-metrics-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,911] INFO Created log for partition _confluent-telemetry-metrics-1 in /var/lib/kafka/data/_confluent-telemetry-metrics-1 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,911] INFO Created log for partition _confluent-telemetry-metrics-1 in /var/lib/kafka/data/_confluent-telemetry-metrics-1 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,912] INFO [Partition _confluent-telemetry-metrics-1 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-1 (kafka.cluster.Partition)
[2025-07-23 11:51:58,912] INFO [Partition _confluent-telemetry-metrics-1 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-1 (kafka.cluster.Partition)
[2025-07-23 11:51:58,912] INFO [Partition _confluent-telemetry-metrics-1 broker=1] Log loaded for partition _confluent-telemetry-metrics-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,912] INFO [Partition _confluent-telemetry-metrics-1 broker=1] Log loaded for partition _confluent-telemetry-metrics-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,913] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-1 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,913] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-1 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,913] INFO [MergedLog partition=_confluent-telemetry-metrics-1, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-1 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,913] INFO [MergedLog partition=_confluent-telemetry-metrics-1, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-1 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,914] INFO [Broker id=1] Leader _confluent-telemetry-metrics-1 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,914] INFO [Broker id=1] Leader _confluent-telemetry-metrics-1 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,915] INFO [MergedLog partition=_confluent-telemetry-metrics-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,915] INFO Created log for partition _confluent-telemetry-metrics-3 in /var/lib/kafka/data/_confluent-telemetry-metrics-3 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,915] INFO Created log for partition _confluent-telemetry-metrics-3 in /var/lib/kafka/data/_confluent-telemetry-metrics-3 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,915] INFO [Partition _confluent-telemetry-metrics-3 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-3 (kafka.cluster.Partition)
[2025-07-23 11:51:58,915] INFO [Partition _confluent-telemetry-metrics-3 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-3 (kafka.cluster.Partition)
[2025-07-23 11:51:58,915] INFO [Partition _confluent-telemetry-metrics-3 broker=1] Log loaded for partition _confluent-telemetry-metrics-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,915] INFO [Partition _confluent-telemetry-metrics-3 broker=1] Log loaded for partition _confluent-telemetry-metrics-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,916] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-3 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,916] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-3 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,916] INFO [MergedLog partition=_confluent-telemetry-metrics-3, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-3 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,916] INFO [MergedLog partition=_confluent-telemetry-metrics-3, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-3 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,916] INFO [Broker id=1] Leader _confluent-telemetry-metrics-3 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,916] INFO [Broker id=1] Leader _confluent-telemetry-metrics-3 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,918] INFO [MergedLog partition=_confluent-telemetry-metrics-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,919] INFO Created log for partition _confluent-telemetry-metrics-5 in /var/lib/kafka/data/_confluent-telemetry-metrics-5 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,919] INFO Created log for partition _confluent-telemetry-metrics-5 in /var/lib/kafka/data/_confluent-telemetry-metrics-5 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,919] INFO [Partition _confluent-telemetry-metrics-5 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-5 (kafka.cluster.Partition)
[2025-07-23 11:51:58,919] INFO [Partition _confluent-telemetry-metrics-5 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-5 (kafka.cluster.Partition)
[2025-07-23 11:51:58,919] INFO [Partition _confluent-telemetry-metrics-5 broker=1] Log loaded for partition _confluent-telemetry-metrics-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,919] INFO [Partition _confluent-telemetry-metrics-5 broker=1] Log loaded for partition _confluent-telemetry-metrics-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,919] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-5 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,919] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-5 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,919] INFO [MergedLog partition=_confluent-telemetry-metrics-5, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-5 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,919] INFO [MergedLog partition=_confluent-telemetry-metrics-5, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-5 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,919] INFO [Broker id=1] Leader _confluent-telemetry-metrics-5 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,919] INFO [Broker id=1] Leader _confluent-telemetry-metrics-5 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,922] INFO [MergedLog partition=_confluent-telemetry-metrics-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,923] INFO Created log for partition _confluent-telemetry-metrics-7 in /var/lib/kafka/data/_confluent-telemetry-metrics-7 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,923] INFO Created log for partition _confluent-telemetry-metrics-7 in /var/lib/kafka/data/_confluent-telemetry-metrics-7 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,924] INFO [Partition _confluent-telemetry-metrics-7 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-7 (kafka.cluster.Partition)
[2025-07-23 11:51:58,924] INFO [Partition _confluent-telemetry-metrics-7 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-7 (kafka.cluster.Partition)
[2025-07-23 11:51:58,924] INFO [Partition _confluent-telemetry-metrics-7 broker=1] Log loaded for partition _confluent-telemetry-metrics-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,924] INFO [Partition _confluent-telemetry-metrics-7 broker=1] Log loaded for partition _confluent-telemetry-metrics-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,924] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-7 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,924] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-7 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,924] INFO [MergedLog partition=_confluent-telemetry-metrics-7, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-7 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,924] INFO [MergedLog partition=_confluent-telemetry-metrics-7, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-7 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,925] INFO [Broker id=1] Leader _confluent-telemetry-metrics-7 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,925] INFO [Broker id=1] Leader _confluent-telemetry-metrics-7 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,930] INFO [MergedLog partition=_confluent-telemetry-metrics-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,931] INFO Created log for partition _confluent-telemetry-metrics-6 in /var/lib/kafka/data/_confluent-telemetry-metrics-6 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,931] INFO Created log for partition _confluent-telemetry-metrics-6 in /var/lib/kafka/data/_confluent-telemetry-metrics-6 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,932] INFO [Partition _confluent-telemetry-metrics-6 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-6 (kafka.cluster.Partition)
[2025-07-23 11:51:58,932] INFO [Partition _confluent-telemetry-metrics-6 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-6 (kafka.cluster.Partition)
[2025-07-23 11:51:58,932] INFO [Partition _confluent-telemetry-metrics-6 broker=1] Log loaded for partition _confluent-telemetry-metrics-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,932] INFO [Partition _confluent-telemetry-metrics-6 broker=1] Log loaded for partition _confluent-telemetry-metrics-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,932] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-6 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,932] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-6 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,932] INFO [MergedLog partition=_confluent-telemetry-metrics-6, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-6 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,932] INFO [MergedLog partition=_confluent-telemetry-metrics-6, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-6 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,932] INFO [Broker id=1] Leader _confluent-telemetry-metrics-6 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,932] INFO [Broker id=1] Leader _confluent-telemetry-metrics-6 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,935] INFO [MergedLog partition=_confluent-telemetry-metrics-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,937] INFO Created log for partition _confluent-telemetry-metrics-4 in /var/lib/kafka/data/_confluent-telemetry-metrics-4 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,937] INFO Created log for partition _confluent-telemetry-metrics-4 in /var/lib/kafka/data/_confluent-telemetry-metrics-4 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,937] INFO [Partition _confluent-telemetry-metrics-4 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-4 (kafka.cluster.Partition)
[2025-07-23 11:51:58,937] INFO [Partition _confluent-telemetry-metrics-4 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-4 (kafka.cluster.Partition)
[2025-07-23 11:51:58,937] INFO [Partition _confluent-telemetry-metrics-4 broker=1] Log loaded for partition _confluent-telemetry-metrics-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,937] INFO [Partition _confluent-telemetry-metrics-4 broker=1] Log loaded for partition _confluent-telemetry-metrics-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,937] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-4 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,937] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-4 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,938] INFO [MergedLog partition=_confluent-telemetry-metrics-4, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-4 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,938] INFO [MergedLog partition=_confluent-telemetry-metrics-4, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-4 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,942] INFO [MergedLog partition=_confluent-telemetry-metrics-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,942] INFO [Broker id=1] Leader _confluent-telemetry-metrics-4 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,942] INFO [Broker id=1] Leader _confluent-telemetry-metrics-4 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,943] INFO Created log for partition _confluent-telemetry-metrics-2 in /var/lib/kafka/data/_confluent-telemetry-metrics-2 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,943] INFO Created log for partition _confluent-telemetry-metrics-2 in /var/lib/kafka/data/_confluent-telemetry-metrics-2 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,943] INFO [Partition _confluent-telemetry-metrics-2 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-2 (kafka.cluster.Partition)
[2025-07-23 11:51:58,943] INFO [Partition _confluent-telemetry-metrics-2 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-2 (kafka.cluster.Partition)
[2025-07-23 11:51:58,943] INFO [Partition _confluent-telemetry-metrics-2 broker=1] Log loaded for partition _confluent-telemetry-metrics-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,943] INFO [Partition _confluent-telemetry-metrics-2 broker=1] Log loaded for partition _confluent-telemetry-metrics-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,944] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-2 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,944] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-2 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,944] INFO [MergedLog partition=_confluent-telemetry-metrics-2, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-2 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,944] INFO [MergedLog partition=_confluent-telemetry-metrics-2, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-2 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,945] INFO [Broker id=1] Leader _confluent-telemetry-metrics-2 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,945] INFO [Broker id=1] Leader _confluent-telemetry-metrics-2 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,947] INFO [MergedLog partition=_confluent-telemetry-metrics-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,948] INFO Created log for partition _confluent-telemetry-metrics-10 in /var/lib/kafka/data/_confluent-telemetry-metrics-10 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,948] INFO Created log for partition _confluent-telemetry-metrics-10 in /var/lib/kafka/data/_confluent-telemetry-metrics-10 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,948] INFO [Partition _confluent-telemetry-metrics-10 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-10 (kafka.cluster.Partition)
[2025-07-23 11:51:58,948] INFO [Partition _confluent-telemetry-metrics-10 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-10 (kafka.cluster.Partition)
[2025-07-23 11:51:58,948] INFO [Partition _confluent-telemetry-metrics-10 broker=1] Log loaded for partition _confluent-telemetry-metrics-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,948] INFO [Partition _confluent-telemetry-metrics-10 broker=1] Log loaded for partition _confluent-telemetry-metrics-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,948] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-10 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,948] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-10 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,949] INFO [MergedLog partition=_confluent-telemetry-metrics-10, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-10 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,949] INFO [MergedLog partition=_confluent-telemetry-metrics-10, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-10 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,949] INFO [Broker id=1] Leader _confluent-telemetry-metrics-10 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,949] INFO [Broker id=1] Leader _confluent-telemetry-metrics-10 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,952] INFO [MergedLog partition=_confluent-telemetry-metrics-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:51:58,952] INFO Created log for partition _confluent-telemetry-metrics-8 in /var/lib/kafka/data/_confluent-telemetry-metrics-8 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,952] INFO Created log for partition _confluent-telemetry-metrics-8 in /var/lib/kafka/data/_confluent-telemetry-metrics-8 with properties {max.message.bytes=10485760, message.timestamp.type="CreateTime", min.insync.replicas=1, retention.bytes=-1, retention.ms=259200000, segment.ms=14400000} (kafka.log.LogManager)
[2025-07-23 11:51:58,952] INFO [Partition _confluent-telemetry-metrics-8 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-8 (kafka.cluster.Partition)
[2025-07-23 11:51:58,952] INFO [Partition _confluent-telemetry-metrics-8 broker=1] No checkpointed highwatermark is found for partition _confluent-telemetry-metrics-8 (kafka.cluster.Partition)
[2025-07-23 11:51:58,952] INFO [Partition _confluent-telemetry-metrics-8 broker=1] Log loaded for partition _confluent-telemetry-metrics-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,952] INFO [Partition _confluent-telemetry-metrics-8 broker=1] Log loaded for partition _confluent-telemetry-metrics-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:51:58,952] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-8 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,952] INFO Setting topicIdPartition frYOQqa_RXO0r2eh1ezVKw:_confluent-telemetry-metrics-8 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:51:58,953] INFO [MergedLog partition=_confluent-telemetry-metrics-8, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-8 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,953] INFO [MergedLog partition=_confluent-telemetry-metrics-8, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-telemetry-metrics-8 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:51:58,953] INFO [Broker id=1] Leader _confluent-telemetry-metrics-8 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,953] INFO [Broker id=1] Leader _confluent-telemetry-metrics-8 with topic id Some(frYOQqa_RXO0r2eh1ezVKw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:51:58,955] INFO [DynamicConfigPublisher broker id=1] Updating topic _confluent-telemetry-metrics with new configuration : max.message.bytes -> 10485760,message.timestamp.type -> CreateTime,min.insync.replicas -> 1,retention.ms -> 259200000,segment.ms -> 14400000,retention.bytes -> -1 (kafka.server.metadata.DynamicConfigPublisher)
[2025-07-23 11:51:58,955] INFO [DynamicConfigPublisher broker id=1] Updating topic _confluent-telemetry-metrics with new configuration : max.message.bytes -> 10485760,message.timestamp.type -> CreateTime,min.insync.replicas -> 1,retention.ms -> 259200000,segment.ms -> 14400000,retention.bytes -> -1 (kafka.server.metadata.DynamicConfigPublisher)
[2025-07-23 11:51:58,987] INFO Broker Addition context is yet to be initialized, hence BrokerAddCount metrics will be reported as 0. (io.confluent.databalancer.ConfluentDataBalanceEngine)
[2025-07-23 11:51:59,448] INFO [Partition _confluent-telemetry-metrics-6 broker=1] roll: _confluent-telemetry-metrics-6: first produce received, lastOffset: 21, leaderEpoch: 0, numMessages:22, time diff: 526 (kafka.cluster.Partition)
[2025-07-23 11:51:59,448] INFO [Partition _confluent-telemetry-metrics-6 broker=1] roll: _confluent-telemetry-metrics-6: first produce received, lastOffset: 21, leaderEpoch: 0, numMessages:22, time diff: 526 (kafka.cluster.Partition)
[2025-07-23 11:51:59,450] INFO [Partition _confluent-telemetry-metrics-6 broker=1] roll: _confluent-telemetry-metrics-6: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 22, become leader time: 1753271518920 ms, time diff: 529 ms (kafka.cluster.Partition)
[2025-07-23 11:51:59,450] INFO [Partition _confluent-telemetry-metrics-6 broker=1] roll: _confluent-telemetry-metrics-6: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 22, become leader time: 1753271518920 ms, time diff: 529 ms (kafka.cluster.Partition)
[2025-07-23 11:51:59,452] INFO [Partition _confluent-telemetry-metrics-0 broker=1] roll: _confluent-telemetry-metrics-0: first produce received, lastOffset: 20, leaderEpoch: 0, numMessages:21, time diff: 558 (kafka.cluster.Partition)
[2025-07-23 11:51:59,452] INFO [Partition _confluent-telemetry-metrics-0 broker=1] roll: _confluent-telemetry-metrics-0: first produce received, lastOffset: 20, leaderEpoch: 0, numMessages:21, time diff: 558 (kafka.cluster.Partition)
[2025-07-23 11:51:59,452] INFO [Partition _confluent-telemetry-metrics-0 broker=1] roll: _confluent-telemetry-metrics-0: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 21, become leader time: 1753271518894 ms, time diff: 558 ms (kafka.cluster.Partition)
[2025-07-23 11:51:59,452] INFO [Partition _confluent-telemetry-metrics-0 broker=1] roll: _confluent-telemetry-metrics-0: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 21, become leader time: 1753271518894 ms, time diff: 558 ms (kafka.cluster.Partition)
[2025-07-23 11:52:02,555] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:52:02,555] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:52:02,556] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:02,930] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler-3298965975882467136] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:02,930] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler-3298965975882467136] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:02,932] INFO App info kafka.consumer for kafka-cruise-control unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:02,932] INFO Metric Reporter Sampler ready to start. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:52:02,933] INFO DataBalancer: Startup component StartupComponent ConfluentTelemetryReporterSampler ready to proceed (io.confluent.databalancer.startup.StartupComponents)
[2025-07-23 11:52:02,933] INFO DataBalancer: Checking startup component StartupComponent ApiStatePersistenceStore (io.confluent.databalancer.startup.StartupComponents)
[2025-07-23 11:52:02,936] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-cruise-control
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 5000
	reconnect.backoff.ms = 500
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:02,938] INFO These configurations '[sasl.oauthbearer.jwks.endpoint.refresh.ms, sasl.login.refresh.min.period.seconds, sasl.oauthbearer.scope.claim.name, sasl.login.refresh.window.factor, sasl.kerberos.ticket.renew.window.factor, sasl.oauthbearer.jti.validation.enabled, sasl.login.retry.backoff.ms, sasl.kerberos.kinit.cmd, sasl.oauthbearer.assertion.claim.nbf.include, sasl.kerberos.ticket.renew.jitter, ssl.keystore.type, ssl.trustmanager.algorithm, sasl.oauthbearer.header.urlencode, sasl.kerberos.min.time.before.relogin, ssl.endpoint.identification.algorithm, sasl.oauthbearer.iat.validation.enabled, ssl.protocol, sasl.login.refresh.buffer.seconds, sasl.login.retry.backoff.max.ms, ssl.enabled.protocols, sasl.oauthbearer.sub.claim.name, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms, ssl.truststore.type, sasl.oauthbearer.clock.skew.seconds, sasl.oauthbearer.assertion.claim.exp.minutes, ssl.keymanager.algorithm, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms, sasl.oauthbearer.assertion.claim.jti.include, sasl.login.refresh.window.jitter]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:02,938] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:02,938] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:02,938] INFO Kafka startTimeMs: 1753271522938 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:02,951] INFO DataBalancer: Creating topic _confluent_balancer_api_state  (com.linkedin.kafka.cruisecontrol.SbkTopicUtils)
[2025-07-23 11:52:02,955] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent_balancer_api_state. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:52:02,955] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent_balancer_api_state. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:52:02,956] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent_balancer_api_state', numPartitions=1, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='delete,compact'), CreatableTopicConfig(name='retention.ms', value='2592000000')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): SUCCESS (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:02,956] INFO [ControllerServer id=1] Replayed TopicRecord for topic _confluent_balancer_api_state with topic ID 64yLi3d5StuTBZ0Pgb5rSA. (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:02,956] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent_balancer_api_state') which set configuration cleanup.policy to delete,compact (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:52:02,956] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='_confluent_balancer_api_state') which set configuration retention.ms to 2592000000 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:52:02,956] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition _confluent_balancer_api_state-0 with topic ID 64yLi3d5StuTBZ0Pgb5rSA and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:02,988] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:52:02,988] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:52:02,988] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent_balancer_api_state-0) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:52:02,988] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent_balancer_api_state-0) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:52:02,988] INFO [Broker id=1] Creating new partition _confluent_balancer_api_state-0 with topic id 64yLi3d5StuTBZ0Pgb5rSA. (state.change.logger)
[2025-07-23 11:52:02,988] INFO [Broker id=1] Creating new partition _confluent_balancer_api_state-0 with topic id 64yLi3d5StuTBZ0Pgb5rSA. (state.change.logger)
[2025-07-23 11:52:02,988] INFO SBC Event SbcMetadataUpdateEvent-142 generated 1 more events to enqueue in the following order - [SbcConfigUpdateEvent-143]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:52:02,989] INFO Handling event SbcConfigUpdateEvent-143 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:52:02,989] INFO Balancer notified of a config change: ConfigurationsDelta(changes={ConfigResource(type=TOPIC, name='_confluent_balancer_api_state')=ConfigurationDelta(changedKeys=[cleanup.policy, retention.ms])}) (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:52:02,989] INFO There were 0 change(s) and 0 deletion(s) to balancer configs. Changed Configs: {}, Deleted Configs: [] (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:52:02,994] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
[2025-07-23 11:52:02,994] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
[2025-07-23 11:52:03,000] INFO App info kafka.admin.client for kafka-cruise-control unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:03,001] INFO [MergedLog partition=_confluent_balancer_api_state-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:03,002] INFO Created log for partition _confluent_balancer_api_state-0 in /var/lib/kafka/data/_confluent_balancer_api_state-0 with properties {cleanup.policy=delete,compact, retention.ms=2592000000} (kafka.log.LogManager)
[2025-07-23 11:52:03,002] INFO Created log for partition _confluent_balancer_api_state-0 in /var/lib/kafka/data/_confluent_balancer_api_state-0 with properties {cleanup.policy=delete,compact, retention.ms=2592000000} (kafka.log.LogManager)
[2025-07-23 11:52:03,002] INFO [Partition _confluent_balancer_api_state-0 broker=1] No checkpointed highwatermark is found for partition _confluent_balancer_api_state-0 (kafka.cluster.Partition)
[2025-07-23 11:52:03,002] INFO [Partition _confluent_balancer_api_state-0 broker=1] No checkpointed highwatermark is found for partition _confluent_balancer_api_state-0 (kafka.cluster.Partition)
[2025-07-23 11:52:03,002] INFO [Partition _confluent_balancer_api_state-0 broker=1] Log loaded for partition _confluent_balancer_api_state-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:03,002] INFO [Partition _confluent_balancer_api_state-0 broker=1] Log loaded for partition _confluent_balancer_api_state-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:03,002] INFO Setting topicIdPartition 64yLi3d5StuTBZ0Pgb5rSA:_confluent_balancer_api_state-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:03,002] INFO Setting topicIdPartition 64yLi3d5StuTBZ0Pgb5rSA:_confluent_balancer_api_state-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:03,003] INFO [MergedLog partition=_confluent_balancer_api_state-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent_balancer_api_state-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:03,003] INFO [MergedLog partition=_confluent_balancer_api_state-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent_balancer_api_state-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:03,003] INFO [Broker id=1] Leader _confluent_balancer_api_state-0 with topic id Some(64yLi3d5StuTBZ0Pgb5rSA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:03,003] INFO [Broker id=1] Leader _confluent_balancer_api_state-0 with topic id Some(64yLi3d5StuTBZ0Pgb5rSA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:03,003] INFO [DynamicConfigPublisher broker id=1] Updating topic _confluent_balancer_api_state with new configuration : cleanup.policy -> delete,compact,retention.ms -> 2592000000 (kafka.server.metadata.DynamicConfigPublisher)
[2025-07-23 11:52:03,003] INFO [DynamicConfigPublisher broker id=1] Updating topic _confluent_balancer_api_state with new configuration : cleanup.policy -> delete,compact,retention.ms -> 2592000000 (kafka.server.metadata.DynamicConfigPublisher)
[2025-07-23 11:52:03,005] INFO Waiting for 1 seconds to ensure that api persistent store topic is created/exists. (io.confluent.databalancer.persistence.ApiStatePersistenceStore)
[2025-07-23 11:52:04,007] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-cruise-control
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 5000
	reconnect.backoff.ms = 500
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:04,017] INFO These configurations '[sasl.oauthbearer.jwks.endpoint.refresh.ms, sasl.login.refresh.min.period.seconds, sasl.oauthbearer.scope.claim.name, sasl.login.refresh.window.factor, sasl.kerberos.ticket.renew.window.factor, sasl.oauthbearer.jti.validation.enabled, sasl.login.retry.backoff.ms, sasl.kerberos.kinit.cmd, sasl.oauthbearer.assertion.claim.nbf.include, sasl.kerberos.ticket.renew.jitter, ssl.keystore.type, ssl.trustmanager.algorithm, sasl.oauthbearer.header.urlencode, sasl.kerberos.min.time.before.relogin, ssl.endpoint.identification.algorithm, sasl.oauthbearer.iat.validation.enabled, ssl.protocol, sasl.login.refresh.buffer.seconds, sasl.login.retry.backoff.max.ms, ssl.enabled.protocols, sasl.oauthbearer.sub.claim.name, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms, ssl.truststore.type, sasl.oauthbearer.clock.skew.seconds, sasl.oauthbearer.assertion.claim.exp.minutes, ssl.keymanager.algorithm, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms, sasl.oauthbearer.assertion.claim.jti.include, sasl.login.refresh.window.jitter]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:04,018] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,018] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,019] INFO Kafka startTimeMs: 1753271524018 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,041] INFO DataBalancer: Adjusting topic _confluent_balancer_api_state configuration (com.linkedin.kafka.cruisecontrol.SbkTopicUtils)
[2025-07-23 11:52:04,071] INFO App info kafka.admin.client for kafka-cruise-control unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,072] INFO Confirmed that topic _confluent_balancer_api_state exists. (io.confluent.databalancer.persistence.ApiStatePersistenceStore)
[2025-07-23 11:52:04,072] INFO DataBalancer: Startup component StartupComponent ApiStatePersistenceStore ready to proceed (io.confluent.databalancer.startup.StartupComponents)
[2025-07-23 11:52:04,072] INFO DataBalancer: Startup checking succeeded, proceeding to full validation. (io.confluent.databalancer.startup.StartupComponents)
[2025-07-23 11:52:04,072] INFO DataBalancer: Creating CruiseControl (io.confluent.databalancer.startup.CruiseControlStartable)
[2025-07-23 11:52:04,087] INFO DataBalancer: Bootstrap server endpoint is Endpoint(listenerName='SASL_PLAINTEXT', securityProtocol=SASL_PLAINTEXT, host='kafka', port=9092) (io.confluent.databalancer.startup.CruiseControlStartable)
[2025-07-23 11:52:04,089] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = null-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 5000
	reconnect.backoff.ms = 500
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:04,090] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,090] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,090] INFO Kafka startTimeMs: 1753271524090 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,092] INFO Starting KafkaBasedLog with topic _confluent_balancer_api_state reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-07-23 11:52:04,092] INFO ProducerConfig values:
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent_balancer_api_state-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = false
	interceptor.classes = []
	key.serializer = class io.confluent.databalancer.persistence.ApiStatePersistenceStore$SbkApiStatusKeySerde
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.databalancer.persistence.ApiStatePersistenceStore$SbkApiStatusMessageSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:04,097] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,097] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,097] INFO Kafka startTimeMs: 1753271524097 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,098] INFO ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent_balancer_api_state-consumer-1
	client.rack =
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.databalancer.persistence.ApiStatePersistenceStore$SbkApiStatusKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.databalancer.persistence.ApiStatePersistenceStore$SbkApiStatusMessageSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:04,100] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,100] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,100] INFO Kafka startTimeMs: 1753271524099 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,101] INFO [Producer clientId=_confluent_balancer_api_state-producer-1] Cluster ID: 4L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-07-23 11:52:04,103] INFO [Consumer clientId=_confluent_balancer_api_state-consumer-1, groupId=null] Cluster ID: 4L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-07-23 11:52:04,103] INFO [Consumer clientId=_confluent_balancer_api_state-consumer-1, groupId=null] Assigned to partition(s): _confluent_balancer_api_state-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:04,103] INFO [Consumer clientId=_confluent_balancer_api_state-consumer-1, groupId=null] Seeking to AutoOffsetResetStrategy{type=earliest} offset of partition _confluent_balancer_api_state-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-07-23 11:52:04,119] INFO Finished reading KafkaBasedLog for topic _confluent_balancer_api_state (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-07-23 11:52:04,119] INFO Started KafkaBasedLog for topic _confluent_balancer_api_state (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-07-23 11:52:04,120] INFO Started DataBalancer Api State Persistence Store (io.confluent.databalancer.persistence.ApiStatePersistenceStore)
[2025-07-23 11:52:04,123] INFO Starting Kafka Cruise Control... (com.linkedin.kafka.cruisecontrol.KafkaCruiseControl)
[2025-07-23 11:52:04,123] INFO Initializing DataBalancer with goals UpdatableSbcGoalsConfig{rebalancingGoals=GoalsConfig{requirements=(requiredNumWindows=6, minMonitoredPartitionPercentage=0.950, includedAllTopics=true, fetchTopicPlacements=true), goals=[MovementExclusionGoal, ReplicaPlacementGoal, RackAwareGoal, CellAwareGoal, TenantAwareGoal, MaxReplicaMovementParallelismGoal, ReplicaCapacityGoal, DiskCapacityGoal, NetworkInboundCapacityGoal, NetworkOutboundCapacityGoal, ReplicationInboundCapacityGoal, ProducerInboundCapacityGoal, MirrorInboundCapacityGoal, ConsumerOutboundCapacityGoal, SystemTopicEvenDistributionGoal, ReplicaDistributionGoal, DiskUsageDistributionGoal, LeaderReplicaDistributionGoal, NetworkInboundUsageDistributionGoal, NetworkOutboundUsageDistributionGoal, TopicReplicaDistributionGoal]}, triggeringGoals=GoalsConfig{requirements=(requiredNumWindows=1, minMonitoredPartitionPercentage=0.950, includedAllTopics=true, fetchTopicPlacements=true), goals=[ReplicaPlacementGoal, RackAwareGoal, CellAwareGoal, TenantAwareGoal, MaxReplicaMovementParallelismGoal, ReplicaCapacityGoal, DiskCapacityGoal, NetworkInboundCapacityGoal, NetworkOutboundCapacityGoal, ReplicationInboundCapacityGoal, ProducerInboundCapacityGoal, ReplicaDistributionGoal, DiskUsageDistributionGoal]}, incrementalBalancingEnabled=false, incrementalBalancingGoals=GoalsConfig{requirements=(requiredNumWindows=5, minMonitoredPartitionPercentage=0.950, includedAllTopics=true, fetchTopicPlacements=true), goals=[MovementExclusionGoal, ReplicaPlacementGoal, RackAwareGoal, CellAwareGoal, TenantAwareGoal, MaxReplicaMovementParallelismGoal, ReplicaCapacityGoal, DiskCapacityGoal, NetworkInboundCapacityGoal, NetworkOutboundCapacityGoal, ReplicationInboundCapacityGoal, ProducerInboundCapacityGoal, MirrorInboundCapacityGoal, ConsumerOutboundCapacityGoal, IncrementalCPUResourceDistributionGoal, IncrementalTopicReplicaDistributionGoal]}} (com.linkedin.kafka.cruisecontrol.KafkaCruiseControl)
[2025-07-23 11:52:04,125] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id =
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 5000
	reconnect.backoff.ms = 500
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:04,126] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,126] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,126] INFO Kafka startTimeMs: 1753271524126 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,132] INFO CruiseControl: Attempting to configure Broker Capacity from config properties (com.linkedin.kafka.cruisecontrol.config.BrokerCapacityResolver)
[2025-07-23 11:52:04,157] INFO Set throttle rate 10485760. Will not override static throttles when setting the rate. (com.linkedin.kafka.cruisecontrol.executor.ReplicationThrottleHelper)
[2025-07-23 11:52:04,154] WARN Load monitor sensor updater received exception  (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
java.util.NoSuchElementException: null
	at java.base/java.util.HashMap$HashIterator.nextNode(HashMap.java:1607) ~[?:?]
	at java.base/java.util.HashMap$ValueIterator.next(HashMap.java:1633) ~[?:?]
	at com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor$SensorUpdater.run(LoadMonitor.java:781) ~[ce-sbk_ce-sbk-project.jar:?]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at com.linkedin.kafka.cruisecontrol.common.KafkaCruiseControlThreadFactory.lambda$newThread$1(KafkaCruiseControlThreadFactory.java:46) ~[ce-sbk_ce-sbk-project.jar:?]
	at java.base/java.lang.Thread.run(Thread.java:1583) [?:?]
[2025-07-23 11:52:04,185] INFO Notifying listeners about metadata change. (com.linkedin.kafka.cruisecontrol.common.MetadataClient)
[2025-07-23 11:52:04,191] INFO [Partition _confluent_balancer_api_state-0 broker=1] roll: _confluent_balancer_api_state-0: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 1197 (kafka.cluster.Partition)
[2025-07-23 11:52:04,191] INFO [Partition _confluent_balancer_api_state-0 broker=1] roll: _confluent_balancer_api_state-0: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 1197 (kafka.cluster.Partition)
[2025-07-23 11:52:04,191] INFO [Partition _confluent_balancer_api_state-0 broker=1] roll: _confluent_balancer_api_state-0: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271522994 ms, time diff: 1197 ms (kafka.cluster.Partition)
[2025-07-23 11:52:04,191] INFO [Partition _confluent_balancer_api_state-0 broker=1] roll: _confluent_balancer_api_state-0: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271522994 ms, time diff: 1197 ms (kafka.cluster.Partition)
[2025-07-23 11:52:04,200] INFO Loaded an even cluster load state record EvenClusterLoadStateRecord{ currentState=null, currentStateCreatedAt=0, currentStateLastUpdatedAt=0, currentStateException=null, previousState=null, previousStateCreatedAt=0, previousStateLastUpdatedAt=0, previousStateException=null} (io.confluent.databalancer.persistence.ApiStatePersistenceStore)
[2025-07-23 11:52:04,226] INFO Removed throttled replicas config for topics: [_confluent_balancer_api_state, _confluent-command, _confluent-telemetry-metrics] (com.linkedin.kafka.cruisecontrol.executor.ReplicationThrottleHelper)
[2025-07-23 11:52:04,238] INFO Removed throttle rate config from 0 brokers (com.linkedin.kafka.cruisecontrol.executor.ReplicationThrottleHelper)
[2025-07-23 11:52:04,238] INFO Starting anomaly detector. (com.linkedin.kafka.cruisecontrol.detector.AnomalyDetector)
[2025-07-23 11:52:04,238] INFO Starting metric sampling task. (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:52:04,238] INFO [SBK_BrokerFailureDetector]: Starting (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 11:52:04,239] INFO KafkaCruiseControlConfig values:
	alter.configs.response.timeout.ms = 30000
	anomaly.detection.allow.capacity.estimation = true
	anomaly.detection.goals = [io.confluent.cruisecontrol.analyzer.goals.ReplicaPlacementGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal, io.confluent.cruisecontrol.analyzer.goals.CellAwareGoal, io.confluent.cruisecontrol.analyzer.goals.TenantAwareGoal, io.confluent.cruisecontrol.analyzer.goals.MaxReplicaMovementParallelismGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicationInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ProducerInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal]
	anomaly.detection.interval.ms = 60000
	bootstrap.servers = [kafka:9092]
	broker.addition.detector.allowed.topic.balancing.operation.time.threshold.min = 90
	broker.addition.elapsed.time.ms.completion.threshold = 57600000
	broker.addition.mean.cpu.percent.completion.threshold = 0.5
	broker.capacity.config.resolver.class = class com.linkedin.kafka.cruisecontrol.config.BrokerCapacityResolver
	broker.failure.alert.threshold.ms = 0
	broker.failure.exclude.recently.removed.brokers = true
	broker.failure.self.healing.threshold.ms = 3600000
	broker.metric.sample.aggregator.completeness.cache.size = 5
	broker.removal.shutdown.timeout.ms = 600000
	broker.replica.exclusion.timeout.ms = 120000
	bytes.cpu.contribution.weight = 0.2
	calculated.throttle.ratio = 0.8
	capacity.goal.minimum.improvement.step.percentage = 0.01
	capacity.threshold.upper.limit = 0.95
	cdbe.shutdown.wait.ms = 15000
	cell.load.upper.bound = 0.7
	cell.overload.detection.interval.ms = 3600000
	cell.overload.duration.ms = 86400000
	client.id = kafka-cruise-control
	confluent.balancer.additional.invalidation.duration.ms = 60000
	confluent.cells.enable = false
	confluent.rack.id.mapping = null
	connections.max.idle.ms = 540000
	consume.out.bound.should.balance.FFF.traffic = true
	consumer.out.max.bytes.per.second = 9223372036854775807
	consumer.outbound.capacity.threshold = 0.9
	cpu.balance.threshold = 1.1
	cpu.capacity.threshold = 1.0
	cpu.goal.act.as.capacity.goal = false
	cpu.low.utilization.threshold = 0.2
	cpu.low.utilization.threshold.for.broker.addition = 0.2
	cpu.utilization.detector.duration.ms = 600000
	cpu.utilization.detector.overutilization.threshold = 80.0
	cpu.utilization.detector.underutilization.threshold = 50.0
	default.api.timeout.ms = 60000
	default.replica.movement.strategies = [com.linkedin.kafka.cruisecontrol.executor.strategy.BaseReplicaMovementStrategy]
	describe.broker.exclusion.timeout.ms = 60000
	describe.cluster.response.timeout.ms = 30000
	describe.configs.batch.size = 1000
	describe.configs.response.timeout.ms = 30000
	describe.topics.response.timeout.ms = 30000
	disk.balance.threshold = 1.1
	disk.low.utilization.threshold = 0.2
	disk.max.load = 0.85
	disk.min.free.space.gb = 0
	disk.min.free.space.lower.limit.gb = 0
	disk.read.ratio = 0.2
	disk.utilization.detector.duration.ms = 600000
	disk.utilization.detector.overutilization.threshold = 80.0
	disk.utilization.detector.reserved.capacity = 150000.0
	disk.utilization.detector.underutilization.threshold = 35.0
	dynamic.throttling.enabled = true
	enable.network.capacity.metric.ingestion = false
	execution.progress.check.interval.ms = 7000
	executor.leader.action.timeout.ms = 180000
	executor.notifier.class = class com.linkedin.kafka.cruisecontrol.executor.ExecutorNoopNotifier
	executor.reservation.refresh.time.ms = 60000
	flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	goal.balancedness.priority.weight = 1.1
	goal.balancedness.strictness.weight = 1.5
	goal.violation.delay.on.new.brokers.ms = 1800000
	goal.violation.distribution.threshold.multiplier = 1.1
	goal.violation.exclude.recently.removed.brokers = true
	goals = [com.linkedin.kafka.cruisecontrol.analyzer.goals.MovementExclusionGoal, io.confluent.cruisecontrol.analyzer.goals.ReplicaPlacementGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal, io.confluent.cruisecontrol.analyzer.goals.CellAwareGoal, io.confluent.cruisecontrol.analyzer.goals.TenantAwareGoal, io.confluent.cruisecontrol.analyzer.goals.MaxReplicaMovementParallelismGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicationInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ProducerInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.MirrorInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ConsumerOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.SystemTopicEvenDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskUsageDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.LeaderReplicaDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundUsageDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundUsageDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.TopicReplicaDistributionGoal]
	hot.partition.capacity.utilization.threshold = 0.2
	incremental.balancing.cpu.top.proposal.tracking.enabled = true
	incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	incremental.balancing.enabled = false
	incremental.balancing.goals = [com.linkedin.kafka.cruisecontrol.analyzer.goals.MovementExclusionGoal, io.confluent.cruisecontrol.analyzer.goals.ReplicaPlacementGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal, io.confluent.cruisecontrol.analyzer.goals.CellAwareGoal, io.confluent.cruisecontrol.analyzer.goals.TenantAwareGoal, io.confluent.cruisecontrol.analyzer.goals.MaxReplicaMovementParallelismGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicationInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ProducerInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.MirrorInboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.ConsumerOutboundCapacityGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.IncrementalCPUResourceDistributionGoal, com.linkedin.kafka.cruisecontrol.analyzer.goals.IncrementalTopicReplicaDistributionGoal]
	incremental.balancing.lower.bound = 0.02
	incremental.balancing.min.valid.windows = 5
	incremental.balancing.step.ratio = 0.2
	inter.cell.balancing.enabled = false
	invalid.replica.assignment.retry.timeout.ms = 300000
	leader.replica.count.balance.threshold = 1.1
	logdir.response.timeout.ms = 30000
	max.allowed.extrapolations.per.broker = 5
	max.allowed.extrapolations.per.partition = 5
	max.capacity.balancing.delta.percentage = 0.0
	max.replicas = 2147483647
	max.volume.throughput.mb = 0
	maximum.allocated.percentage.for.network.in.capacity.bytes = 0.8
	metadata.client.timeout.ms = 180000
	metadata.ttl = 10000
	metric.sampler.class = class io.confluent.cruisecontrol.metricsreporter.ConfluentTelemetryReporterSampler
	min.samples.per.partition.metrics.window = 1
	min.valid.partition.ratio = 0.95
	minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	network.in.max.bytes.per.second = 9223372036854775807
	network.inbound.balance.threshold = 1.1
	network.inbound.capacity.threshold = 0.8
	network.inbound.low.utilization.threshold = 0.2
	network.out.max.bytes.per.second = 9223372036854775807
	network.outbound.balance.threshold = 1.1
	network.outbound.capacity.threshold = 0.8
	network.outbound.low.utilization.threshold = 0.2
	num.cached.recent.anomaly.states = 10
	num.concurrent.leader.movements = 1000
	num.concurrent.partition.movements.per.broker = 5
	num.concurrent.replica.movements.as.destination.per.broker = 18
	num.concurrent.replica.movements.as.source.per.broker = 12
	num.metric.fetchers = 1
	num.partition.metrics.windows = 12
	partition.metric.sample.aggregator.completeness.cache.size = 5
	partition.metrics.window.ms = 180000
	plan.computation.retry.timeout.ms = 3600000
	populate.default.disk.capacity.from.local = true
	producer.in.max.bytes.per.second = 9223372036854775807
	producer.inbound.capacity.threshold = 0.9
	read.throughput.multiplier = 1.0
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	removal.history.retention.time.ms = 86400000
	replica.count.balance.threshold = 1.1
	replica.movement.strategies = [com.linkedin.kafka.cruisecontrol.executor.strategy.PostponeUrpReplicaMovementStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizePartitionsWithMoreReplicaAdditionsStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizeLargeReplicaMovementStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizeSmallReplicaMovementStrategy, com.linkedin.kafka.cruisecontrol.executor.strategy.BaseReplicaMovementStrategy]
	replication.in.max.bytes.per.second = 9223372036854775807
	replication.inbound.capacity.threshold = 0.9
	request.cpu.contribution.weight = 0.8
	request.timeout.ms = 30000
	resource.utilization.detector.interval.ms = 60000
	sampling.allow.cpu.capacity.estimation = true
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sbc.metrics.parser.enabled = false
	security.protocol = SASL_PLAINTEXT
	self.healing.broker.failure.enabled = true
	self.healing.goal.violation.enabled = false
	self.healing.maximum.rounds = 1
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	startup.retry.delay.minutes = 5
	startup.retry.max.hours = 2
	static.throttle.rate.override.enabled = false
	tenant.maximum.movements = 0
	tenant.suspension.ms = 86400000
	throttle.bytes.per.second = 10485760
	topic.balancing.badly.imbalanced.topic.imbalance.score.threshold = 0.3
	topic.balancing.balance.threshold.multiplier = 1.0
	topic.balancing.broker.addition.detector.with.trdg.enabled = false
	topic.balancing.itrdg.with.hard.goals.enabled = false
	topic.balancing.max.reassignments.per.iteration = -1
	topic.balancing.slightly.imbalanced.topic.imbalance.score.threshold = 0.05
	topic.balancing.slightly.imbalanced.topics.percentage.trigger = 0.2
	topic.balancing.trigger.threshold.multiplier = 3.0
	topic.partition.maximum.movements = 3
	topic.partition.movement.expiration.ms = 3600000
	topic.partition.movements.history.limit = 900
	topic.partition.suspension.ms = 3600000
	topics.excluded.from.partition.movement =
	v2.addition.enabled = false
	v2.addition.reassignment.cancellations.enabled = false
	v2.executor.enabled = false
	write.throughput.multiplier = 1.0
	zookeeper.connect = null
	zookeeper.security.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:04,239] INFO Kafka Cruise Control started. (com.linkedin.kafka.cruisecontrol.KafkaCruiseControl)
[2025-07-23 11:52:04,240] INFO TrailingFanoutTotalCapacityProcessor is configured with a fanout averaging window of 1800000 ms (com.linkedin.kafka.cruisecontrol.monitor.sampling.TrailingFanoutTotalCapacityProcessor)
[2025-07-23 11:52:04,240] INFO Starting anomaly handler (com.linkedin.kafka.cruisecontrol.detector.AnomalyDetector)
[2025-07-23 11:52:04,240] INFO No pending DataBalancer operations found at startup. (io.confluent.databalancer.ConfluentDataBalanceEngine)
[2025-07-23 11:52:04,240] INFO Balancer Status state for brokers [1] transitioned from STARTING to RUNNING due to event CRUISE_CONTROL_INITIALIZATION_COMPLETED. (io.confluent.databalancer.operation.StateMachine)
[2025-07-23 11:52:04,240] INFO Alive brokers: [1], failed brokers: [] (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 11:52:04,240] INFO DataBalancer: Scheduling DataBalanceEngine auto-heal update (setting to false) (io.confluent.databalancer.ConfluentDataBalanceEngine)
[2025-07-23 11:52:04,241] INFO Updated list of failed broker: {} (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 11:52:04,241] INFO Broker capacities updater is configured to not ingest network capacities (com.linkedin.kafka.cruisecontrol.monitor.sampling.BrokerCapacitiesUpdater)
[2025-07-23 11:52:04,241] INFO DataBalancer: DataBalanceEngine started (io.confluent.databalancer.ConfluentDataBalanceEngine)
[2025-07-23 11:52:04,241] INFO Databalancer: Updating auto-heal mode to (false) (io.confluent.databalancer.ConfluentDataBalanceEngine)
[2025-07-23 11:52:04,241] INFO Changing GOAL_VIOLATION anomaly self-healing actions to false (io.confluent.databalancer.ConfluentDataBalanceEngine)
[2025-07-23 11:52:04,241] INFO Goal violation self-healing left disabled (no change) (com.linkedin.kafka.cruisecontrol.KafkaCruiseControl)
[2025-07-23 11:52:04,241] WARN Disabling exponential reconnect backoff because reconnect.backoff.ms is set, but reconnect.backoff.max.ms is not. (org.apache.kafka.clients.CommonClientConfigs)
[2025-07-23 11:52:04,242] INFO ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [kafka:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-cruise-control
	client.rack =
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConfluentTelemetryReporterSampler--5988689947570755077
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 2147483647
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 50
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:04,243] INFO These configurations '[sasl.oauthbearer.jwks.endpoint.refresh.ms, sasl.kerberos.ticket.renew.window.factor, sasl.oauthbearer.jti.validation.enabled, ssl.keystore.type, sasl.oauthbearer.header.urlencode, ssl.endpoint.identification.algorithm, sasl.login.refresh.buffer.seconds, sasl.login.retry.backoff.max.ms, ssl.truststore.type, sasl.oauthbearer.clock.skew.seconds, sasl.oauthbearer.assertion.claim.exp.minutes, sasl.login.refresh.min.period.seconds, sasl.oauthbearer.scope.claim.name, sasl.login.refresh.window.factor, sasl.login.retry.backoff.ms, sasl.kerberos.kinit.cmd, sasl.oauthbearer.assertion.claim.nbf.include, sasl.kerberos.ticket.renew.jitter, ssl.trustmanager.algorithm, sasl.kerberos.min.time.before.relogin, sasl.oauthbearer.iat.validation.enabled, ssl.protocol, ssl.enabled.protocols, sasl.oauthbearer.sub.claim.name, sasl.oauthbearer.jwks.endpoint.retry.backoff.ms, ssl.keymanager.algorithm, sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms, sasl.oauthbearer.assertion.claim.jti.include, sasl.login.refresh.window.jitter]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-07-23 11:52:04,243] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,243] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,243] INFO Kafka startTimeMs: 1753271524243 (org.apache.kafka.common.utils.AppInfoParser)
[2025-07-23 11:52:04,243] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Subscribed to pattern: '_confluent-telemetry-metrics' (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:04,248] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Cluster ID: 4L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
[2025-07-23 11:52:04,252] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753271280000, endMs=1753271460000, endMsInclusive=1753271459999, index=9740397, baseTimestamp=0}(11:48:00 - 11:50:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:52:04,258] INFO Sent auto-creation request for Set(__consumer_offsets) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2025-07-23 11:52:04,258] INFO Sent auto-creation request for Set(__consumer_offsets) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
[2025-07-23 11:52:04,259] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic __consumer_offsets. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:52:04,259] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic __consumer_offsets. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:52:04,260] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=1, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='max.compaction.lag.ms', value='9223372036854775807'), CreatableTopicConfig(name='segment.bytes', value='104857600'), CreatableTopicConfig(name='min.cleanable.dirty.ratio', value='0.5'), CreatableTopicConfig(name='delete.retention.ms', value='86400000')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): SUCCESS (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,261] INFO [ControllerServer id=1] Replayed TopicRecord for topic __consumer_offsets with topic ID dAQBfY-7SdCA1yFk8DbP8g. (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,261] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration compression.type to producer (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:52:04,261] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration cleanup.policy to compact (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:52:04,261] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration max.compaction.lag.ms to 9223372036854775807 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:52:04,261] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration segment.bytes to 104857600 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:52:04,261] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration min.cleanable.dirty.ratio to 0.5 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:52:04,261] INFO [ControllerServer id=1] Replayed ConfigRecord for ConfigResource(type=TOPIC, name='__consumer_offsets') which set configuration delete.retention.ms to 86400000 (org.apache.kafka.controller.ConfigurationControlManager)
[2025-07-23 11:52:04,262] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-0 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,262] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-1 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,262] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-2 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,262] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-3 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,262] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-4 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,262] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-5 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,262] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-6 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,262] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-7 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,262] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-8 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-9 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-10 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-11 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-12 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-13 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-14 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-15 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-16 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-17 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-18 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,263] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-19 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-20 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-21 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-22 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-23 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-24 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-25 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-26 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-27 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-28 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,264] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-29 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-30 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-31 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-32 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-33 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-34 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-35 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-36 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-37 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-38 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-39 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-40 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-41 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-42 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,265] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-43 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,266] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-44 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,266] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-45 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,266] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-46 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,266] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-47 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,266] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-48 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,266] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition __consumer_offsets-49 with topic ID dAQBfY-7SdCA1yFk8DbP8g and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:04,289] INFO SBC Event SbcMetadataUpdateEvent-147 generated 1 more events to enqueue in the following order - [SbcConfigUpdateEvent-148]. Enqueuing... (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:52:04,289] INFO [Broker id=1] Transitioning 50 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:52:04,289] INFO [Broker id=1] Transitioning 50 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:52:04,289] INFO Handling event SbcConfigUpdateEvent-148 (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:52:04,289] INFO Balancer notified of a config change: ConfigurationsDelta(changes={ConfigResource(type=TOPIC, name='__consumer_offsets')=ConfigurationDelta(changedKeys=[compression.type, cleanup.policy, max.compaction.lag.ms, segment.bytes, min.cleanable.dirty.ratio, delete.retention.ms])}) (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:52:04,289] INFO There were 0 change(s) and 0 deletion(s) to balancer configs. Changed Configs: {}, Deleted Configs: [] (io.confluent.databalancer.event.SbcEvent)
[2025-07-23 11:52:04,289] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:52:04,289] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:52:04,289] INFO [Broker id=1] Creating new partition __consumer_offsets-13 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,289] INFO [Broker id=1] Creating new partition __consumer_offsets-13 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,290] INFO [Broker id=1] Creating new partition __consumer_offsets-46 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,290] INFO [Broker id=1] Creating new partition __consumer_offsets-46 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,291] INFO [Broker id=1] Creating new partition __consumer_offsets-9 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,291] INFO [Broker id=1] Creating new partition __consumer_offsets-9 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,291] INFO [Broker id=1] Creating new partition __consumer_offsets-42 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,291] INFO [Broker id=1] Creating new partition __consumer_offsets-42 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,291] INFO [Broker id=1] Creating new partition __consumer_offsets-21 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,291] INFO [Broker id=1] Creating new partition __consumer_offsets-21 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,292] INFO [Broker id=1] Creating new partition __consumer_offsets-17 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,292] INFO [Broker id=1] Creating new partition __consumer_offsets-17 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,292] INFO [Broker id=1] Creating new partition __consumer_offsets-30 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,292] INFO [Broker id=1] Creating new partition __consumer_offsets-30 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,293] INFO [Broker id=1] Creating new partition __consumer_offsets-26 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,293] INFO [Broker id=1] Creating new partition __consumer_offsets-26 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,293] INFO [Broker id=1] Creating new partition __consumer_offsets-5 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,293] INFO [Broker id=1] Creating new partition __consumer_offsets-5 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,293] INFO [Broker id=1] Creating new partition __consumer_offsets-38 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,293] INFO [Broker id=1] Creating new partition __consumer_offsets-38 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,293] INFO [Broker id=1] Creating new partition __consumer_offsets-1 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,293] INFO [Broker id=1] Creating new partition __consumer_offsets-1 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,294] INFO [Broker id=1] Creating new partition __consumer_offsets-34 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,294] INFO [Broker id=1] Creating new partition __consumer_offsets-34 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,294] INFO [Broker id=1] Creating new partition __consumer_offsets-16 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,294] INFO [Broker id=1] Creating new partition __consumer_offsets-16 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,294] INFO [Broker id=1] Creating new partition __consumer_offsets-45 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,294] INFO [Broker id=1] Creating new partition __consumer_offsets-45 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,295] INFO [Broker id=1] Creating new partition __consumer_offsets-12 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,295] INFO [Broker id=1] Creating new partition __consumer_offsets-12 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,295] INFO [Broker id=1] Creating new partition __consumer_offsets-41 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,295] INFO [Broker id=1] Creating new partition __consumer_offsets-41 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,295] INFO [Broker id=1] Creating new partition __consumer_offsets-24 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,295] INFO [Broker id=1] Creating new partition __consumer_offsets-24 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,295] INFO [Broker id=1] Creating new partition __consumer_offsets-20 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,295] INFO [Broker id=1] Creating new partition __consumer_offsets-20 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,296] INFO [Broker id=1] Creating new partition __consumer_offsets-49 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,296] INFO [Broker id=1] Creating new partition __consumer_offsets-49 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,296] INFO [Broker id=1] Creating new partition __consumer_offsets-0 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,296] INFO [Broker id=1] Creating new partition __consumer_offsets-0 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,296] INFO [Broker id=1] Creating new partition __consumer_offsets-29 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,296] INFO [Broker id=1] Creating new partition __consumer_offsets-29 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,297] INFO [Broker id=1] Creating new partition __consumer_offsets-25 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,297] INFO [Broker id=1] Creating new partition __consumer_offsets-25 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,297] INFO [Broker id=1] Creating new partition __consumer_offsets-8 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,297] INFO [Broker id=1] Creating new partition __consumer_offsets-8 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,298] INFO [Broker id=1] Creating new partition __consumer_offsets-37 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,298] INFO [Broker id=1] Creating new partition __consumer_offsets-37 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,298] INFO [Broker id=1] Creating new partition __consumer_offsets-4 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,298] INFO [Broker id=1] Creating new partition __consumer_offsets-4 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,298] INFO [Broker id=1] Creating new partition __consumer_offsets-33 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,298] INFO [Broker id=1] Creating new partition __consumer_offsets-33 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,298] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,299] INFO [Broker id=1] Creating new partition __consumer_offsets-15 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,299] INFO [Broker id=1] Creating new partition __consumer_offsets-15 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,299] INFO [Broker id=1] Creating new partition __consumer_offsets-48 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,299] INFO [Broker id=1] Creating new partition __consumer_offsets-48 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,300] INFO [Broker id=1] Creating new partition __consumer_offsets-11 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,300] INFO [Broker id=1] Creating new partition __consumer_offsets-11 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,300] INFO [Broker id=1] Creating new partition __consumer_offsets-44 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,300] INFO [Broker id=1] Creating new partition __consumer_offsets-44 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,301] INFO [Broker id=1] Creating new partition __consumer_offsets-23 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,301] INFO [Broker id=1] Creating new partition __consumer_offsets-23 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,302] INFO [Broker id=1] Creating new partition __consumer_offsets-19 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,302] INFO [Broker id=1] Creating new partition __consumer_offsets-19 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,302] INFO [Broker id=1] Creating new partition __consumer_offsets-32 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,302] INFO [Broker id=1] Creating new partition __consumer_offsets-32 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,302] INFO [Broker id=1] Creating new partition __consumer_offsets-28 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,302] INFO [Broker id=1] Creating new partition __consumer_offsets-28 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,303] INFO [Broker id=1] Creating new partition __consumer_offsets-7 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,303] INFO [Broker id=1] Creating new partition __consumer_offsets-7 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,303] INFO [Broker id=1] Creating new partition __consumer_offsets-40 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,303] INFO [Broker id=1] Creating new partition __consumer_offsets-40 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,303] INFO [Broker id=1] Creating new partition __consumer_offsets-3 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,303] INFO [Broker id=1] Creating new partition __consumer_offsets-3 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,304] INFO [Broker id=1] Creating new partition __consumer_offsets-36 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,304] INFO [Broker id=1] Creating new partition __consumer_offsets-36 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,304] INFO [Broker id=1] Creating new partition __consumer_offsets-47 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,304] INFO [Broker id=1] Creating new partition __consumer_offsets-47 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,304] INFO [Broker id=1] Creating new partition __consumer_offsets-14 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,304] INFO [Broker id=1] Creating new partition __consumer_offsets-14 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,305] INFO [Broker id=1] Creating new partition __consumer_offsets-43 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,305] INFO [Broker id=1] Creating new partition __consumer_offsets-43 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,306] INFO [Broker id=1] Creating new partition __consumer_offsets-10 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,306] INFO [Broker id=1] Creating new partition __consumer_offsets-10 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,306] INFO [Broker id=1] Creating new partition __consumer_offsets-22 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,306] INFO [Broker id=1] Creating new partition __consumer_offsets-22 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,307] INFO [Broker id=1] Creating new partition __consumer_offsets-18 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,307] INFO [Broker id=1] Creating new partition __consumer_offsets-18 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,308] INFO [Broker id=1] Creating new partition __consumer_offsets-31 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,308] INFO [Broker id=1] Creating new partition __consumer_offsets-31 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,308] INFO [Broker id=1] Creating new partition __consumer_offsets-27 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,308] INFO [Broker id=1] Creating new partition __consumer_offsets-27 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,309] INFO [Broker id=1] Creating new partition __consumer_offsets-39 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,309] INFO [Broker id=1] Creating new partition __consumer_offsets-39 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,309] INFO [Broker id=1] Creating new partition __consumer_offsets-6 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,309] INFO [Broker id=1] Creating new partition __consumer_offsets-6 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,309] INFO [Broker id=1] Creating new partition __consumer_offsets-35 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,309] INFO [Broker id=1] Creating new partition __consumer_offsets-35 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,310] INFO [Broker id=1] Creating new partition __consumer_offsets-2 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,310] INFO [Broker id=1] Creating new partition __consumer_offsets-2 with topic id dAQBfY-7SdCA1yFk8DbP8g. (state.change.logger)
[2025-07-23 11:52:04,311] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 50 partitions (state.change.logger)
[2025-07-23 11:52:04,311] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 50 partitions (state.change.logger)
[2025-07-23 11:52:04,315] INFO [MergedLog partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,316] INFO Created log for partition __consumer_offsets-8 in /var/lib/kafka/data/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,316] INFO Created log for partition __consumer_offsets-8 in /var/lib/kafka/data/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,316] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2025-07-23 11:52:04,316] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2025-07-23 11:52:04,317] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,317] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,317] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-8 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,317] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-8 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,317] INFO [MergedLog partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-8 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,317] INFO [MergedLog partition=__consumer_offsets-8, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-8 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,317] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,317] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,318] INFO [MergedLog partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,319] INFO Created log for partition __consumer_offsets-27 in /var/lib/kafka/data/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,319] INFO Created log for partition __consumer_offsets-27 in /var/lib/kafka/data/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,319] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2025-07-23 11:52:04,319] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2025-07-23 11:52:04,319] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,319] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,319] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-27 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,319] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-27 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,319] INFO [MergedLog partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-27 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,319] INFO [MergedLog partition=__consumer_offsets-27, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-27 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,319] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,319] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,321] INFO [MergedLog partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,322] INFO Created log for partition __consumer_offsets-16 in /var/lib/kafka/data/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,322] INFO Created log for partition __consumer_offsets-16 in /var/lib/kafka/data/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,322] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2025-07-23 11:52:04,322] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2025-07-23 11:52:04,322] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,322] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,322] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-16 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,322] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-16 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,322] INFO [MergedLog partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-16 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,322] INFO [MergedLog partition=__consumer_offsets-16, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-16 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,322] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,322] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,324] INFO [MergedLog partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,326] INFO Created log for partition __consumer_offsets-26 in /var/lib/kafka/data/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,326] INFO Created log for partition __consumer_offsets-26 in /var/lib/kafka/data/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,326] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2025-07-23 11:52:04,326] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2025-07-23 11:52:04,326] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,326] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,326] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-26 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,326] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-26 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,326] INFO [MergedLog partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-26 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,326] INFO [MergedLog partition=__consumer_offsets-26, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-26 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,326] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,326] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,328] INFO [MergedLog partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,328] INFO Created log for partition __consumer_offsets-24 in /var/lib/kafka/data/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,328] INFO Created log for partition __consumer_offsets-24 in /var/lib/kafka/data/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,329] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2025-07-23 11:52:04,329] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2025-07-23 11:52:04,329] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,329] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,329] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-24 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,329] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-24 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,329] INFO [MergedLog partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-24 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,329] INFO [MergedLog partition=__consumer_offsets-24, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-24 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,329] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,329] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,330] INFO [MergedLog partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,331] INFO Created log for partition __consumer_offsets-20 in /var/lib/kafka/data/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,331] INFO Created log for partition __consumer_offsets-20 in /var/lib/kafka/data/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,331] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2025-07-23 11:52:04,331] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2025-07-23 11:52:04,331] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,331] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,331] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-20 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,331] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-20 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,331] INFO [MergedLog partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-20 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,331] INFO [MergedLog partition=__consumer_offsets-20, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-20 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,331] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,331] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,333] INFO [MergedLog partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,333] INFO Created log for partition __consumer_offsets-25 in /var/lib/kafka/data/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,333] INFO Created log for partition __consumer_offsets-25 in /var/lib/kafka/data/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,333] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2025-07-23 11:52:04,333] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2025-07-23 11:52:04,334] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,334] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,334] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-25 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,334] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-25 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,334] INFO [MergedLog partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-25 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,334] INFO [MergedLog partition=__consumer_offsets-25, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-25 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,334] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,334] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,336] INFO [MergedLog partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,336] INFO Created log for partition __consumer_offsets-12 in /var/lib/kafka/data/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,336] INFO Created log for partition __consumer_offsets-12 in /var/lib/kafka/data/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,337] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2025-07-23 11:52:04,337] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2025-07-23 11:52:04,337] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,337] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,337] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-12 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,337] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-12 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,337] INFO [MergedLog partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-12 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,337] INFO [MergedLog partition=__consumer_offsets-12, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-12 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,337] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,337] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,339] INFO [MergedLog partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,340] INFO Created log for partition __consumer_offsets-4 in /var/lib/kafka/data/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,340] INFO Created log for partition __consumer_offsets-4 in /var/lib/kafka/data/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,340] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2025-07-23 11:52:04,340] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2025-07-23 11:52:04,340] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,340] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,340] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-4 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,340] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-4 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,340] INFO [MergedLog partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-4 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,340] INFO [MergedLog partition=__consumer_offsets-4, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-4 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,340] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,340] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,343] INFO [MergedLog partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,343] INFO Created log for partition __consumer_offsets-28 in /var/lib/kafka/data/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,343] INFO Created log for partition __consumer_offsets-28 in /var/lib/kafka/data/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,343] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2025-07-23 11:52:04,343] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2025-07-23 11:52:04,343] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,343] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,344] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-28 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,344] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-28 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,344] INFO [MergedLog partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-28 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,344] INFO [MergedLog partition=__consumer_offsets-28, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-28 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,344] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,344] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,346] INFO [MergedLog partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,346] INFO Created log for partition __consumer_offsets-33 in /var/lib/kafka/data/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,346] INFO Created log for partition __consumer_offsets-33 in /var/lib/kafka/data/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,346] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2025-07-23 11:52:04,346] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2025-07-23 11:52:04,346] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,346] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,346] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-33 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,346] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-33 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,346] INFO [MergedLog partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-33 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,346] INFO [MergedLog partition=__consumer_offsets-33, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-33 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,347] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,347] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,348] INFO [MergedLog partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,348] INFO Created log for partition __consumer_offsets-41 in /var/lib/kafka/data/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,348] INFO Created log for partition __consumer_offsets-41 in /var/lib/kafka/data/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,348] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2025-07-23 11:52:04,348] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2025-07-23 11:52:04,349] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,349] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,349] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-41 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,349] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-41 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,349] INFO [MergedLog partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-41 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,349] INFO [MergedLog partition=__consumer_offsets-41, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-41 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,349] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,349] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,350] INFO [MergedLog partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,351] INFO Created log for partition __consumer_offsets-0 in /var/lib/kafka/data/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,351] INFO Created log for partition __consumer_offsets-0 in /var/lib/kafka/data/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,351] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,351] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,351] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,351] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,351] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,351] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,351] INFO [MergedLog partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,351] INFO [MergedLog partition=__consumer_offsets-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,351] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,351] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,354] INFO [MergedLog partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,354] INFO Created log for partition __consumer_offsets-49 in /var/lib/kafka/data/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,354] INFO Created log for partition __consumer_offsets-49 in /var/lib/kafka/data/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,355] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2025-07-23 11:52:04,355] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2025-07-23 11:52:04,355] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,355] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,355] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-49 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,355] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-49 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,355] INFO [MergedLog partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-49 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,355] INFO [MergedLog partition=__consumer_offsets-49, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-49 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,355] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,355] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,357] INFO [MergedLog partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,357] INFO Created log for partition __consumer_offsets-23 in /var/lib/kafka/data/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,357] INFO Created log for partition __consumer_offsets-23 in /var/lib/kafka/data/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,357] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2025-07-23 11:52:04,357] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2025-07-23 11:52:04,357] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,357] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,357] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-23 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,357] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-23 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,358] INFO [MergedLog partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-23 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,358] INFO [MergedLog partition=__consumer_offsets-23, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-23 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,358] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,358] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,359] INFO [MergedLog partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,360] INFO Created log for partition __consumer_offsets-30 in /var/lib/kafka/data/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,360] INFO Created log for partition __consumer_offsets-30 in /var/lib/kafka/data/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,360] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2025-07-23 11:52:04,360] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2025-07-23 11:52:04,360] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,360] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,360] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-30 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,360] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-30 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,360] INFO [MergedLog partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-30 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,360] INFO [MergedLog partition=__consumer_offsets-30, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-30 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,361] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,361] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,361] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,362] INFO [MergedLog partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,362] INFO Created log for partition __consumer_offsets-45 in /var/lib/kafka/data/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,362] INFO Created log for partition __consumer_offsets-45 in /var/lib/kafka/data/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,362] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2025-07-23 11:52:04,362] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2025-07-23 11:52:04,362] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,362] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,363] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-45 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,363] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-45 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,363] INFO [MergedLog partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-45 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,363] INFO [MergedLog partition=__consumer_offsets-45, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-45 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,363] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,363] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,365] INFO [MergedLog partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,365] INFO Created log for partition __consumer_offsets-31 in /var/lib/kafka/data/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,365] INFO Created log for partition __consumer_offsets-31 in /var/lib/kafka/data/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,365] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2025-07-23 11:52:04,365] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2025-07-23 11:52:04,365] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,365] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,365] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-31 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,365] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-31 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,366] INFO [MergedLog partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-31 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,366] INFO [MergedLog partition=__consumer_offsets-31, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-31 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,366] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,366] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,368] INFO [MergedLog partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,368] INFO Created log for partition __consumer_offsets-37 in /var/lib/kafka/data/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,368] INFO Created log for partition __consumer_offsets-37 in /var/lib/kafka/data/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,368] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2025-07-23 11:52:04,368] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2025-07-23 11:52:04,368] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,368] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,368] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-37 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,368] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-37 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,368] INFO [MergedLog partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-37 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,368] INFO [MergedLog partition=__consumer_offsets-37, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-37 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,369] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,369] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,371] INFO [MergedLog partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,371] INFO Created log for partition __consumer_offsets-35 in /var/lib/kafka/data/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,371] INFO Created log for partition __consumer_offsets-35 in /var/lib/kafka/data/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,371] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2025-07-23 11:52:04,371] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2025-07-23 11:52:04,372] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,372] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,372] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-35 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,372] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-35 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,372] INFO [MergedLog partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-35 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,372] INFO [MergedLog partition=__consumer_offsets-35, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-35 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,372] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,372] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,372] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,372] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,374] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,374] INFO [MergedLog partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,374] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 11:52:04,374] INFO Created log for partition __consumer_offsets-15 in /var/lib/kafka/data/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,374] INFO Created log for partition __consumer_offsets-15 in /var/lib/kafka/data/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,374] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2025-07-23 11:52:04,374] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2025-07-23 11:52:04,374] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,374] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,375] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-15 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,375] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-15 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,375] INFO [MergedLog partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-15 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,375] INFO [MergedLog partition=__consumer_offsets-15, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-15 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,375] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,375] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,376] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,376] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,376] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,377] INFO [MergedLog partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,377] INFO Created log for partition __consumer_offsets-1 in /var/lib/kafka/data/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,377] INFO Created log for partition __consumer_offsets-1 in /var/lib/kafka/data/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,378] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2025-07-23 11:52:04,378] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2025-07-23 11:52:04,378] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,378] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,378] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-1 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,378] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-1 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,378] INFO [MergedLog partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-1 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,378] INFO [MergedLog partition=__consumer_offsets-1, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-1 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,378] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,378] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,379] INFO [MergedLog partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,380] INFO Created log for partition __consumer_offsets-3 in /var/lib/kafka/data/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,380] INFO Created log for partition __consumer_offsets-3 in /var/lib/kafka/data/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,380] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2025-07-23 11:52:04,380] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2025-07-23 11:52:04,380] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,380] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,380] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-3 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,380] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-3 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,380] INFO [MergedLog partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-3 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,380] INFO [MergedLog partition=__consumer_offsets-3, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-3 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,380] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,380] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,381] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,381] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,381] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,382] INFO [MergedLog partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,383] INFO Created log for partition __consumer_offsets-36 in /var/lib/kafka/data/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,383] INFO Created log for partition __consumer_offsets-36 in /var/lib/kafka/data/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,383] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2025-07-23 11:52:04,383] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2025-07-23 11:52:04,383] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,383] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,383] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-36 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,383] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-36 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,383] INFO [MergedLog partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-36 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,383] INFO [MergedLog partition=__consumer_offsets-36, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-36 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,383] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,383] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,385] INFO [MergedLog partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,385] INFO Created log for partition __consumer_offsets-9 in /var/lib/kafka/data/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,385] INFO Created log for partition __consumer_offsets-9 in /var/lib/kafka/data/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,385] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2025-07-23 11:52:04,385] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2025-07-23 11:52:04,386] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,386] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,386] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-9 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,386] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-9 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,386] INFO [MergedLog partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-9 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,386] INFO [MergedLog partition=__consumer_offsets-9, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-9 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,386] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,386] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,388] INFO [MergedLog partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,388] INFO Created log for partition __consumer_offsets-42 in /var/lib/kafka/data/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,388] INFO Created log for partition __consumer_offsets-42 in /var/lib/kafka/data/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,388] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2025-07-23 11:52:04,388] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2025-07-23 11:52:04,388] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,388] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,388] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-42 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,388] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-42 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,389] INFO [MergedLog partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-42 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,389] INFO [MergedLog partition=__consumer_offsets-42, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-42 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,389] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,389] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,390] INFO [MergedLog partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,390] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,390] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,391] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,391] INFO Created log for partition __consumer_offsets-19 in /var/lib/kafka/data/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,391] INFO Created log for partition __consumer_offsets-19 in /var/lib/kafka/data/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,391] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2025-07-23 11:52:04,391] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2025-07-23 11:52:04,391] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,391] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,391] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-19 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,391] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-19 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,392] INFO [MergedLog partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-19 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,392] INFO [MergedLog partition=__consumer_offsets-19, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-19 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,392] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,392] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,393] INFO [MergedLog partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,393] INFO Created log for partition __consumer_offsets-29 in /var/lib/kafka/data/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,393] INFO Created log for partition __consumer_offsets-29 in /var/lib/kafka/data/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,393] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2025-07-23 11:52:04,393] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2025-07-23 11:52:04,393] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,393] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,393] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-29 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,393] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-29 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,394] INFO [MergedLog partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-29 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,394] INFO [MergedLog partition=__consumer_offsets-29, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-29 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,394] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,394] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,395] INFO [MergedLog partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,395] INFO Created log for partition __consumer_offsets-11 in /var/lib/kafka/data/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,395] INFO Created log for partition __consumer_offsets-11 in /var/lib/kafka/data/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,395] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2025-07-23 11:52:04,395] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2025-07-23 11:52:04,396] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,396] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,396] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-11 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,396] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-11 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,396] INFO [MergedLog partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-11 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,396] INFO [MergedLog partition=__consumer_offsets-11, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-11 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,396] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,396] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,397] INFO [MergedLog partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,398] INFO Created log for partition __consumer_offsets-21 in /var/lib/kafka/data/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,398] INFO Created log for partition __consumer_offsets-21 in /var/lib/kafka/data/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,398] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2025-07-23 11:52:04,398] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2025-07-23 11:52:04,398] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,398] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,398] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-21 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,398] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-21 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,398] INFO [MergedLog partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-21 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,398] INFO [MergedLog partition=__consumer_offsets-21, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-21 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,398] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,398] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,400] INFO [MergedLog partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,400] INFO Created log for partition __consumer_offsets-32 in /var/lib/kafka/data/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,400] INFO Created log for partition __consumer_offsets-32 in /var/lib/kafka/data/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,400] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2025-07-23 11:52:04,400] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2025-07-23 11:52:04,401] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,401] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,401] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-32 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,401] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-32 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,401] INFO [MergedLog partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-32 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,401] INFO [MergedLog partition=__consumer_offsets-32, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-32 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,401] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,401] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,402] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,402] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,402] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,405] INFO [MergedLog partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,405] INFO Created log for partition __consumer_offsets-43 in /var/lib/kafka/data/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,405] INFO Created log for partition __consumer_offsets-43 in /var/lib/kafka/data/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,406] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2025-07-23 11:52:04,406] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2025-07-23 11:52:04,406] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,406] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,406] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-43 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,406] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-43 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,406] INFO [MergedLog partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-43 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,406] INFO [MergedLog partition=__consumer_offsets-43, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-43 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,406] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,406] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,408] INFO [MergedLog partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,409] INFO Created log for partition __consumer_offsets-5 in /var/lib/kafka/data/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,409] INFO Created log for partition __consumer_offsets-5 in /var/lib/kafka/data/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,409] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2025-07-23 11:52:04,409] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2025-07-23 11:52:04,409] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,409] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,409] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-5 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,409] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-5 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,409] INFO [MergedLog partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-5 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,409] INFO [MergedLog partition=__consumer_offsets-5, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-5 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,409] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,409] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,412] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,412] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,412] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,413] INFO [MergedLog partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,414] INFO Created log for partition __consumer_offsets-38 in /var/lib/kafka/data/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,414] INFO Created log for partition __consumer_offsets-38 in /var/lib/kafka/data/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,414] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2025-07-23 11:52:04,414] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2025-07-23 11:52:04,414] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,414] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,414] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-38 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,414] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-38 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,414] INFO [MergedLog partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-38 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,414] INFO [MergedLog partition=__consumer_offsets-38, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-38 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,414] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,414] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,417] INFO [MergedLog partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,417] INFO Created log for partition __consumer_offsets-44 in /var/lib/kafka/data/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,417] INFO Created log for partition __consumer_offsets-44 in /var/lib/kafka/data/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,417] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2025-07-23 11:52:04,417] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2025-07-23 11:52:04,417] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,417] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,417] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-44 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,417] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-44 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,417] INFO [MergedLog partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-44 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,417] INFO [MergedLog partition=__consumer_offsets-44, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-44 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,417] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,417] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,420] INFO [MergedLog partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,420] INFO Created log for partition __consumer_offsets-17 in /var/lib/kafka/data/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,420] INFO Created log for partition __consumer_offsets-17 in /var/lib/kafka/data/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,420] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2025-07-23 11:52:04,420] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2025-07-23 11:52:04,420] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,420] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,420] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-17 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,420] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-17 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,420] INFO [MergedLog partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-17 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,420] INFO [MergedLog partition=__consumer_offsets-17, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-17 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,420] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,420] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,423] INFO [MergedLog partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,423] INFO Created log for partition __consumer_offsets-22 in /var/lib/kafka/data/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,424] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,423] INFO Created log for partition __consumer_offsets-22 in /var/lib/kafka/data/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,424] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2025-07-23 11:52:04,424] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2025-07-23 11:52:04,424] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,424] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,424] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-22 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,424] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-22 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,424] INFO [MergedLog partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-22 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,424] INFO [MergedLog partition=__consumer_offsets-22, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-22 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,424] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,424] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,426] INFO [MergedLog partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,427] INFO Created log for partition __consumer_offsets-13 in /var/lib/kafka/data/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,427] INFO Created log for partition __consumer_offsets-13 in /var/lib/kafka/data/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,428] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,428] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,428] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,428] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 11:52:04,429] INFO [MergedLog partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,429] INFO Created log for partition __consumer_offsets-34 in /var/lib/kafka/data/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,429] INFO Created log for partition __consumer_offsets-34 in /var/lib/kafka/data/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,429] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2025-07-23 11:52:04,429] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2025-07-23 11:52:04,429] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,429] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,429] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,429] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-34 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,429] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-34 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,429] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,429] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,429] INFO [MergedLog partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-34 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,429] INFO [MergedLog partition=__consumer_offsets-34, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-34 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,429] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,429] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,430] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2025-07-23 11:52:04,430] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2025-07-23 11:52:04,430] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,430] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,430] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-13 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,430] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-13 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,430] INFO [MergedLog partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-13 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,430] INFO [MergedLog partition=__consumer_offsets-13, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-13 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,430] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,430] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,431] INFO [MergedLog partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,432] INFO Created log for partition __consumer_offsets-48 in /var/lib/kafka/data/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,432] INFO Created log for partition __consumer_offsets-48 in /var/lib/kafka/data/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,432] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2025-07-23 11:52:04,432] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2025-07-23 11:52:04,432] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,432] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,432] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-48 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,432] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-48 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,432] INFO [MergedLog partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-48 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,432] INFO [MergedLog partition=__consumer_offsets-48, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-48 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,432] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,432] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,433] INFO [MergedLog partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,433] INFO Created log for partition __consumer_offsets-2 in /var/lib/kafka/data/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,433] INFO Created log for partition __consumer_offsets-2 in /var/lib/kafka/data/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,434] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,434] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2025-07-23 11:52:04,434] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2025-07-23 11:52:04,434] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,434] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,434] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,434] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,434] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-2 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,434] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-2 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,434] INFO [MergedLog partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-2 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,434] INFO [MergedLog partition=__consumer_offsets-2, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-2 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,434] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,434] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,435] INFO [MergedLog partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,435] INFO Created log for partition __consumer_offsets-7 in /var/lib/kafka/data/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,435] INFO Created log for partition __consumer_offsets-7 in /var/lib/kafka/data/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,435] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2025-07-23 11:52:04,435] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2025-07-23 11:52:04,435] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,435] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,436] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-7 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,436] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-7 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,436] INFO [MergedLog partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-7 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,436] INFO [MergedLog partition=__consumer_offsets-7, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-7 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,436] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,436] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,437] INFO [MergedLog partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,437] INFO Created log for partition __consumer_offsets-46 in /var/lib/kafka/data/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,437] INFO Created log for partition __consumer_offsets-46 in /var/lib/kafka/data/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,437] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2025-07-23 11:52:04,437] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2025-07-23 11:52:04,437] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,437] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,437] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-46 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,437] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-46 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,437] INFO [MergedLog partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-46 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,437] INFO [MergedLog partition=__consumer_offsets-46, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-46 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,438] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,438] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,439] INFO [MergedLog partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,440] INFO Created log for partition __consumer_offsets-18 in /var/lib/kafka/data/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,440] INFO Created log for partition __consumer_offsets-18 in /var/lib/kafka/data/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,440] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2025-07-23 11:52:04,440] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2025-07-23 11:52:04,440] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,440] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,440] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-18 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,440] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-18 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,440] INFO [MergedLog partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-18 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,440] INFO [MergedLog partition=__consumer_offsets-18, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-18 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,440] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,440] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,442] INFO [MergedLog partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,442] INFO Created log for partition __consumer_offsets-39 in /var/lib/kafka/data/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,442] INFO Created log for partition __consumer_offsets-39 in /var/lib/kafka/data/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,442] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2025-07-23 11:52:04,442] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2025-07-23 11:52:04,443] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,443] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,443] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-39 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,443] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-39 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,443] INFO [MergedLog partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-39 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,443] INFO [MergedLog partition=__consumer_offsets-39, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-39 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,443] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,443] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,444] INFO [MergedLog partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,444] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,444] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,444] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,444] INFO Created log for partition __consumer_offsets-47 in /var/lib/kafka/data/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,444] INFO Created log for partition __consumer_offsets-47 in /var/lib/kafka/data/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,445] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2025-07-23 11:52:04,445] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2025-07-23 11:52:04,445] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,445] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,445] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-47 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,445] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-47 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,445] INFO [MergedLog partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-47 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,445] INFO [MergedLog partition=__consumer_offsets-47, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-47 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,445] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,445] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,446] INFO [MergedLog partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,447] INFO Created log for partition __consumer_offsets-10 in /var/lib/kafka/data/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,447] INFO Created log for partition __consumer_offsets-10 in /var/lib/kafka/data/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,447] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2025-07-23 11:52:04,447] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2025-07-23 11:52:04,447] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,447] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,447] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-10 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,447] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-10 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,447] INFO [MergedLog partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-10 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,447] INFO [MergedLog partition=__consumer_offsets-10, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-10 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,447] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,447] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,448] INFO [MergedLog partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,449] INFO Created log for partition __consumer_offsets-14 in /var/lib/kafka/data/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,449] INFO Created log for partition __consumer_offsets-14 in /var/lib/kafka/data/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,449] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2025-07-23 11:52:04,449] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2025-07-23 11:52:04,449] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,449] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,449] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-14 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,449] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-14 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,449] INFO [MergedLog partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-14 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,449] INFO [MergedLog partition=__consumer_offsets-14, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-14 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,450] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,450] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,451] INFO [MergedLog partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,452] INFO Created log for partition __consumer_offsets-6 in /var/lib/kafka/data/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,452] INFO Created log for partition __consumer_offsets-6 in /var/lib/kafka/data/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,452] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2025-07-23 11:52:04,452] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2025-07-23 11:52:04,452] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,452] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,452] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-6 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,452] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-6 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,452] INFO [MergedLog partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-6 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,452] INFO [MergedLog partition=__consumer_offsets-6, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-6 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,452] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,452] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,454] INFO [MergedLog partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:52:04,454] INFO Created log for partition __consumer_offsets-40 in /var/lib/kafka/data/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,454] INFO Created log for partition __consumer_offsets-40 in /var/lib/kafka/data/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", delete.retention.ms=86400000, max.compaction.lag.ms=9223372036854775807, min.cleanable.dirty.ratio=0.5, segment.bytes=104857600} (kafka.log.LogManager)
[2025-07-23 11:52:04,454] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2025-07-23 11:52:04,454] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2025-07-23 11:52:04,454] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,454] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:52:04,454] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-40 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,454] INFO Setting topicIdPartition dAQBfY-7SdCA1yFk8DbP8g:__consumer_offsets-40 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:52:04,454] INFO [MergedLog partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-40 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,454] INFO [MergedLog partition=__consumer_offsets-40, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for __consumer_offsets-40 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:52:04,455] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,455] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(dAQBfY-7SdCA1yFk8DbP8g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:52:04,455] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,455] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,455] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,456] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-13 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,458] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-46 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-9 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-42 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-21 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-17 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-30 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-26 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-5 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-38 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-1 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-34 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-16 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-45 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-12 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-41 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-24 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,459] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-20 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-49 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-0 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-29 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-25 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-8 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-37 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-4 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-33 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-15 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-48 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-11 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-44 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,460] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-23 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-19 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-32 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-28 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-7 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-40 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-3 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-36 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-47 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-14 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-43 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-10 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-22 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-18 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-31 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-27 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-39 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,461] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-6 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,462] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-35 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,462] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-2 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,462] INFO [DynamicConfigPublisher broker id=1] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,max.compaction.lag.ms -> 9223372036854775807,segment.bytes -> 104857600,min.cleanable.dirty.ratio -> 0.5,delete.retention.ms -> 86400000 (kafka.server.metadata.DynamicConfigPublisher)
[2025-07-23 11:52:04,462] INFO [DynamicConfigPublisher broker id=1] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,max.compaction.lag.ms -> 9223372036854775807,segment.bytes -> 104857600,min.cleanable.dirty.ratio -> 0.5,delete.retention.ms -> 86400000 (kafka.server.metadata.DynamicConfigPublisher)
[2025-07-23 11:52:04,465] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,465] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,465] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,476] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,476] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,476] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,483] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-20 with epoch 0 in 5ms where 5ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,483] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-8 with epoch 0 in 8ms where 7ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,483] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-28 with epoch 0 in 9ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,483] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-48 with epoch 0 in 9ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,483] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-25 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,483] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-30 with epoch 0 in 8ms where 7ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-15 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-38 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-34 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-16 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-1 with epoch 0 in 14ms where 14ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-6 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-46 with epoch 0 in 10ms where 10ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-13 with epoch 0 in 10ms where 10ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-45 with epoch 0 in 4ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-24 with epoch 0 in 14ms where 14ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-21 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,484] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-39 with epoch 0 in 5ms where 5ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-42 with epoch 0 in 16ms where 16ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-37 with epoch 0 in 13ms where 13ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-29 with epoch 0 in 15ms where 15ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-40 with epoch 0 in 13ms where 13ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-9 with epoch 0 in 10ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-12 with epoch 0 in 14ms where 14ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-36 with epoch 0 in 12ms where 12ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-4 with epoch 0 in 9ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-43 with epoch 0 in 5ms where 5ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-18 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-33 with epoch 0 in 13ms where 13ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-26 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-32 with epoch 0 in 14ms where 14ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-35 with epoch 0 in 12ms where 12ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-5 with epoch 0 in 6ms where 6ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-31 with epoch 0 in 5ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-2 with epoch 0 in 14ms where 14ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-3 with epoch 0 in 11ms where 11ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-7 with epoch 0 in 5ms where 5ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,485] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-10 with epoch 0 in 14ms where 14ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-49 with epoch 0 in 9ms where 6ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-0 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-47 with epoch 0 in 5ms where 4ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-19 with epoch 0 in 13ms where 13ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-14 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-22 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-11 with epoch 0 in 9ms where 9ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-41 with epoch 0 in 13ms where 13ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-44 with epoch 0 in 11ms where 11ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-27 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-23 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,486] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-17 with epoch 0 in 8ms where 8ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
[2025-07-23 11:52:04,487] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,488] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,494] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=12] Dynamic member with unknown member id joins group ConfluentTelemetryReporterSampler--5988689947570755077 in Empty state. Created a new member id kafka-cruise-control-8e59f077-a451-4e99-b109-3494f3c2b619 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:52:04,495] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Request joining group due to: need to re-join with the given member-id: kafka-cruise-control-8e59f077-a451-4e99-b109-3494f3c2b619 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,495] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:04,498] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=12] Pending dynamic member with id kafka-cruise-control-8e59f077-a451-4e99-b109-3494f3c2b619 joins group ConfluentTelemetryReporterSampler--5988689947570755077 in Empty state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:52:04,500] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=12] Preparing to rebalance group ConfluentTelemetryReporterSampler--5988689947570755077 in state PreparingRebalance with old generation 0 (reason: Adding new member kafka-cruise-control-8e59f077-a451-4e99-b109-3494f3c2b619 with group instance id null; client reason: need to re-join with the given member-id: kafka-cruise-control-8e59f077-a451-4e99-b109-3494f3c2b619). (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:52:04,504] INFO [Partition __consumer_offsets-12 broker=1] roll: __consumer_offsets-12: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 192 (kafka.cluster.Partition)
[2025-07-23 11:52:04,504] INFO [Partition __consumer_offsets-12 broker=1] roll: __consumer_offsets-12: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 192 (kafka.cluster.Partition)
[2025-07-23 11:52:04,505] INFO [Partition __consumer_offsets-12 broker=1] roll: __consumer_offsets-12: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271524312 ms, time diff: 193 ms (kafka.cluster.Partition)
[2025-07-23 11:52:04,505] INFO [Partition __consumer_offsets-12 broker=1] roll: __consumer_offsets-12: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271524312 ms, time diff: 193 ms (kafka.cluster.Partition)
[2025-07-23 11:52:07,508] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=12] Stabilized group ConfluentTelemetryReporterSampler--5988689947570755077 generation 1 with 1 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:52:07,511] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Successfully joined group with generation Generation{generationId=1, memberId='kafka-cruise-control-8e59f077-a451-4e99-b109-3494f3c2b619', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,520] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Finished assignment for group at generation 1: {kafka-cruise-control-8e59f077-a451-4e99-b109-3494f3c2b619=Assignment(partitions=[_confluent-telemetry-metrics-0, _confluent-telemetry-metrics-1, _confluent-telemetry-metrics-2, _confluent-telemetry-metrics-3, _confluent-telemetry-metrics-4, _confluent-telemetry-metrics-5, _confluent-telemetry-metrics-6, _confluent-telemetry-metrics-7, _confluent-telemetry-metrics-8, _confluent-telemetry-metrics-9, _confluent-telemetry-metrics-10, _confluent-telemetry-metrics-11])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,524] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=12] Assignment received from leader kafka-cruise-control-8e59f077-a451-4e99-b109-3494f3c2b619 for group ConfluentTelemetryReporterSampler--5988689947570755077 for generation 1. The group has 1 members, 0 of which are static. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:52:07,534] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Successfully synced group in generation Generation{generationId=1, memberId='kafka-cruise-control-8e59f077-a451-4e99-b109-3494f3c2b619', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,535] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Notifying assignor about the new Assignment(partitions=[_confluent-telemetry-metrics-0, _confluent-telemetry-metrics-1, _confluent-telemetry-metrics-2, _confluent-telemetry-metrics-3, _confluent-telemetry-metrics-4, _confluent-telemetry-metrics-5, _confluent-telemetry-metrics-6, _confluent-telemetry-metrics-7, _confluent-telemetry-metrics-8, _confluent-telemetry-metrics-9, _confluent-telemetry-metrics-10, _confluent-telemetry-metrics-11]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,535] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Adding newly assigned partitions: _confluent-telemetry-metrics-0, _confluent-telemetry-metrics-1, _confluent-telemetry-metrics-2, _confluent-telemetry-metrics-3, _confluent-telemetry-metrics-4, _confluent-telemetry-metrics-5, _confluent-telemetry-metrics-6, _confluent-telemetry-metrics-7, _confluent-telemetry-metrics-8, _confluent-telemetry-metrics-9, _confluent-telemetry-metrics-10, _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,542] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Found no committed offset for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 11:52:07,555] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,555] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,555] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,556] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,556] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,556] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,556] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,556] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,556] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,556] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,556] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,556] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:52:07,569] INFO Finished sampling for 12 partitions - processed 31 metrics over 1 polls for the time range [11:48:00,11:50:59.999], with 0 of them added to the metrics processor, having the following distribution {},  31 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:52:07,570] WARN Zero replica samples were added! Collected 0 (0 discarded, 0 added) replica metric samples for 0 replicas. Total partition assigned: 14. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 11:52:07,570] WARN Zero partition samples were added! Collected 0 (0 discarded, 0 added) partition metric samples for 0 partitions. Total partition assigned: 14. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 11:52:07,570] INFO Successfully finished metric sampling for time period 11:48:00 to 11:50:59.999 (1753271280000 to 1753271459999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:52:07,571] INFO Sleeping the SamplingScheduler until 11:53:59.999 (for 112429ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740397, 11:48:00 - 11:50:59.999), currentWindow: (index: 9740398, 11:51:00 - 11:53:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:52:31,762] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:52:31,762] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:52:31,762] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:52:40,424] INFO Notifying listeners about metadata change. (com.linkedin.kafka.cruisecontrol.common.MetadataClient)
[2025-07-23 11:52:40,424] INFO Skipping detection because there are not enough valid metric windows. (com.linkedin.kafka.cruisecontrol.detector.AnomalyDetector)
com.linkedin.cruisecontrol.exception.NotEnoughValidWindowsException: There is no window available in range [-1, 1753271560424] (<none> - 11:52:40.424). In other words calculated window indices: (fromWindowIndex: 1, toWindowIndex: -1) are out of range (currentWindowIndex: 0, startWindowIndex: 0)
	at com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator.aggregate(MetricSampleAggregator.java:269) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator.aggregate(MetricSampleAggregator.java:314) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.kafka.cruisecontrol.monitor.sampling.aggregator.KafkaPartitionMetricSampleAggregator.aggregate(KafkaPartitionMetricSampleAggregator.java:142) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor.createClusterModel(LoadMonitor.java:315) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor.createClusterModelToleratingPartitionReassignments(LoadMonitor.java:276) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.kafka.cruisecontrol.detector.AnomalyDetector$DetectorTask.run(AnomalyDetector.java:238) ~[ce-sbk_ce-sbk-project.jar:?]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at com.linkedin.kafka.cruisecontrol.common.KafkaCruiseControlThreadFactory.lambda$newThread$1(KafkaCruiseControlThreadFactory.java:46) ~[ce-sbk_ce-sbk-project.jar:?]
	at java.base/java.lang.Thread.run(Thread.java:1583) [?:?]
[2025-07-23 11:52:57,771] INFO [ControllerServer id=1] In the last 60000 ms period, 340 controller events were completed, which took an average of 11.72 ms each. The slowest event was writeNoOpRecord(535309948), which took 41.77 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 11:52:57,815] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 11:53:00,485] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:53:00,485] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:53:00,486] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:53:27,800] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic test. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:53:27,800] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic test. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:53:27,805] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='test', numPartitions=-1, replicationFactor=-1, assignments=[], configs=[], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): SUCCESS (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:53:27,806] INFO [ControllerServer id=1] Replayed TopicRecord for topic test with topic ID 7v9YvshOT86qAHdL0DiZ4Q. (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:53:27,806] INFO [ControllerServer id=1] Replayed PartitionRecord for new partition test-0 with topic ID 7v9YvshOT86qAHdL0DiZ4Q and PartitionRegistration(replicas=[1], observers=[], directories=[8faM4DwJIg-uLt0nW5zqpw], isr=[1], removingReplicas=[], addingReplicas=[], removingObservers=[], addingObservers=[], elr=[], lastKnownElr=[], leader=1, leaderRecoveryState=RECOVERED, leaderEpoch=0, partitionEpoch=0, linkedLeaderEpoch=-1, linkState=NOT_MIRROR). (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:53:27,823] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:53:27,823] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2025-07-23 11:53:27,824] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-0) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:53:27,824] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test-0) (kafka.server.ReplicaFetcherManager)
[2025-07-23 11:53:27,824] INFO [Broker id=1] Creating new partition test-0 with topic id 7v9YvshOT86qAHdL0DiZ4Q. (state.change.logger)
[2025-07-23 11:53:27,824] INFO [Broker id=1] Creating new partition test-0 with topic id 7v9YvshOT86qAHdL0DiZ4Q. (state.change.logger)
[2025-07-23 11:53:27,832] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
[2025-07-23 11:53:27,832] INFO [Broker id=1] Stopped fetchers as part of become-leader transition for 1 partitions (state.change.logger)
[2025-07-23 11:53:27,840] INFO [MergedLog partition=test-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-07-23 11:53:27,841] INFO Created log for partition test-0 in /var/lib/kafka/data/test-0 with properties {} (kafka.log.LogManager)
[2025-07-23 11:53:27,841] INFO Created log for partition test-0 in /var/lib/kafka/data/test-0 with properties {} (kafka.log.LogManager)
[2025-07-23 11:53:27,842] INFO [Partition test-0 broker=1] No checkpointed highwatermark is found for partition test-0 (kafka.cluster.Partition)
[2025-07-23 11:53:27,842] INFO [Partition test-0 broker=1] No checkpointed highwatermark is found for partition test-0 (kafka.cluster.Partition)
[2025-07-23 11:53:27,842] INFO [Partition test-0 broker=1] Log loaded for partition test-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:53:27,842] INFO [Partition test-0 broker=1] Log loaded for partition test-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-07-23 11:53:27,842] INFO Setting topicIdPartition 7v9YvshOT86qAHdL0DiZ4Q:test-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:53:27,842] INFO Setting topicIdPartition 7v9YvshOT86qAHdL0DiZ4Q:test-0 (kafka.tier.state.FileTierPartitionState)
[2025-07-23 11:53:27,842] INFO [MergedLog partition=test-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for test-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:53:27,842] INFO [MergedLog partition=test-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for test-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-07-23 11:53:27,842] INFO [Broker id=1] Leader test-0 with topic id Some(7v9YvshOT86qAHdL0DiZ4Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:53:27,842] INFO [Broker id=1] Leader test-0 with topic id Some(7v9YvshOT86qAHdL0DiZ4Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [], removing replicas [] , and recovery state RECOVERED. Previous leader epoch was -1. (state.change.logger)
[2025-07-23 11:53:32,510] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:53:32,510] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:53:32,510] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:53:40,617] INFO Notifying listeners about metadata change. (com.linkedin.kafka.cruisecontrol.common.MetadataClient)
[2025-07-23 11:53:40,625] INFO Skipping detection because there are not enough valid metric windows. (com.linkedin.kafka.cruisecontrol.detector.AnomalyDetector)
com.linkedin.cruisecontrol.exception.NotEnoughValidWindowsException: There is no window available in range [-1, 1753271620624] (<none> - 11:53:40.624). In other words calculated window indices: (fromWindowIndex: 1, toWindowIndex: -1) are out of range (currentWindowIndex: 0, startWindowIndex: 0)
	at com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator.aggregate(MetricSampleAggregator.java:269) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator.aggregate(MetricSampleAggregator.java:314) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.kafka.cruisecontrol.monitor.sampling.aggregator.KafkaPartitionMetricSampleAggregator.aggregate(KafkaPartitionMetricSampleAggregator.java:142) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor.createClusterModel(LoadMonitor.java:315) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor.createClusterModelToleratingPartitionReassignments(LoadMonitor.java:276) ~[ce-sbk_ce-sbk-project.jar:?]
	at com.linkedin.kafka.cruisecontrol.detector.AnomalyDetector$DetectorTask.run(AnomalyDetector.java:238) ~[ce-sbk_ce-sbk-project.jar:?]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358) ~[?:?]
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at com.linkedin.kafka.cruisecontrol.common.KafkaCruiseControlThreadFactory.lambda$newThread$1(KafkaCruiseControlThreadFactory.java:46) ~[ce-sbk_ce-sbk-project.jar:?]
	at java.base/java.lang.Thread.run(Thread.java:1583) [?:?]
[2025-07-23 11:53:56,981] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38502-2-18) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:53:57,392] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38518-0-19) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:53:57,709] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38522-1-19) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:53:57,780] INFO [ControllerServer id=1] In the last 60000 ms period, 334 controller events were completed, which took an average of 11.62 ms each. The slowest event was writeNoOpRecord(1544125637), which took 61.82 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 11:53:57,822] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 11:53:58,224] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38536-2-19) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:53:58,668] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38542-0-20) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:53:59,189] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38546-1-20) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:53:59,604] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38558-2-20) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:00,020] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753271460000, endMs=1753271640000, endMsInclusive=1753271639999, index=9740398, baseTimestamp=0}(11:51:00 - 11:53:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:54:00,030] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38568-0-21) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:00,057] INFO Finished sampling for 12 partitions - processed 224 metrics over 1 polls for the time range [11:51:00,11:53:59.999], with 224 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=145, TOPIC_BYTES_IN=6, TOPIC_FETCH_REQUEST_RATE=7, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_OUT=7, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, TOPIC_MESSAGES_IN_PER_SEC=6, ALL_TOPIC_REPLICATION_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=6, BROKER_PRODUCE_REQUEST_RATE=2, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:54:00,074] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 11:51:58.751 to 11:53:58.791 (1753271518751 to 1753271638791). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 11:54:00,078] INFO REPLICA Aggregator rolled out a new window, reset 0 windows and bumped generation from 0->1,current window range [1753269300000, 1753271460000, 11:15:00 to 11:51:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 11:54:00,085] INFO PARTITION Aggregator rolled out a new window, reset 0 windows and bumped generation from 0->1,current window range [1753269300000, 1753271460000, 11:15:00 to 11:51:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 11:54:00,087] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 11:54:00,087] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 11:54:00,088] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 1->2,current window range [1753269480000, 1753271640000, 11:18:00 to 11:54:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 11:54:00,089] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 1->2,current window range [1753269480000, 1753271640000, 11:18:00 to 11:54:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 11:54:00,089] INFO Successfully finished metric sampling for time period 11:51:00 to 11:53:59.999 (1753271460000 to 1753271639999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:54:00,089] INFO Sleeping the SamplingScheduler until 11:56:59.999 (for 179910ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740398, 11:51:00 - 11:53:59.999), currentWindow: (index: 9740399, 11:54:00 - 11:56:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:54:00,403] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38576-1-21) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:00,728] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38592-2-21) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:01,346] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38598-0-22) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:01,932] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38604-1-22) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:02,461] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38608-2-22) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:02,903] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38618-0-23) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:03,433] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:38620-1-23) (errorMessage=Unexpected Kafka request of type INIT_PRODUCER_ID during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:04,163] INFO Saving metric sample completeness to cache for generation 2 and from/to indices 9740387-9740398 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 11:54:04,168] INFO Saving metric sample completeness to cache for generation 2 and from/to indices 9740387-9740398 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 11:54:04,170] INFO Saving metric sample completeness to cache for generation 2 and from/to indices 9740387-9740398 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 11:54:04,178] INFO Saving metric sample completeness to cache for generation 2 and from/to indices 9740387-9740398 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 11:54:04,512] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:54:04,512] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:54:04,513] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:54:11,147] INFO [ControllerServer id=1] Replaying ProducerIdsRecord ProducerIdsRecord(brokerId=1, brokerEpoch=7, nextProducerId=1000) (org.apache.kafka.controller.ProducerIdControlManager)
[2025-07-23 11:54:18,261] INFO [Partition test-0 broker=1] roll: test-0: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 50428 (kafka.cluster.Partition)
[2025-07-23 11:54:18,261] INFO [Partition test-0 broker=1] roll: test-0: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 50428 (kafka.cluster.Partition)
[2025-07-23 11:54:18,261] INFO [Partition test-0 broker=1] roll: test-0: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271607833 ms, time diff: 50428 ms (kafka.cluster.Partition)
[2025-07-23 11:54:18,261] INFO [Partition test-0 broker=1] roll: test-0: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271607833 ms, time diff: 50428 ms (kafka.cluster.Partition)
[2025-07-23 11:54:36,503] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:54:36,503] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:54:36,504] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:54:40,433] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:54:40,449] INFO Generated cluster model in 36 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:54:40,454] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:54:40,454] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:54:50,791] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:45282-1-24) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:51,231] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:45294-2-24) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:51,734] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:45300-0-25) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:52,512] INFO [SocketServer listenerType=BROKER, nodeId=1] Failed authentication with /192.168.128.2 (channelId=192.168.128.3:9092-192.168.128.2:45304-1-25) (errorMessage=Unexpected Kafka request of type METADATA during SASL handshake.) (org.apache.kafka.common.network.Selector)
[2025-07-23 11:54:57,776] INFO [ControllerServer id=1] In the last 60000 ms period, 334 controller events were completed, which took an average of 11.64 ms each. The slowest event was writeNoOpRecord(2007229631), which took 89.33 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 11:54:57,818] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 11:55:04,522] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:55:04,522] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:55:04,523] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:55:33,395] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Dynamic member with unknown member id joins group console-consumer-82332 in Empty state. Created a new member id console-consumer-d5ae771c-f917-4fcb-9be5-a193d974a2c7 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:33,398] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Pending dynamic member with id console-consumer-d5ae771c-f917-4fcb-9be5-a193d974a2c7 joins group console-consumer-82332 in Empty state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:33,398] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Preparing to rebalance group console-consumer-82332 in state PreparingRebalance with old generation 0 (reason: Adding new member console-consumer-d5ae771c-f917-4fcb-9be5-a193d974a2c7 with group instance id null; client reason: need to re-join with the given member-id: console-consumer-d5ae771c-f917-4fcb-9be5-a193d974a2c7). (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:33,405] INFO [Partition __consumer_offsets-19 broker=1] roll: __consumer_offsets-19: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 209050 (kafka.cluster.Partition)
[2025-07-23 11:55:33,405] INFO [Partition __consumer_offsets-19 broker=1] roll: __consumer_offsets-19: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 209050 (kafka.cluster.Partition)
[2025-07-23 11:55:33,405] INFO [Partition __consumer_offsets-19 broker=1] roll: __consumer_offsets-19: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271524355 ms, time diff: 209050 ms (kafka.cluster.Partition)
[2025-07-23 11:55:33,405] INFO [Partition __consumer_offsets-19 broker=1] roll: __consumer_offsets-19: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271524355 ms, time diff: 209050 ms (kafka.cluster.Partition)
[2025-07-23 11:55:35,763] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:55:35,763] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:55:35,765] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:55:36,401] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Stabilized group console-consumer-82332 generation 1 with 1 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:36,440] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Assignment received from leader console-consumer-d5ae771c-f917-4fcb-9be5-a193d974a2c7 for group console-consumer-82332 for generation 1. The group has 1 members, 0 of which are static. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:38,725] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] [Group console-consumer-82332] Member console-consumer-d5ae771c-f917-4fcb-9be5-a193d974a2c7 has left group through explicit `LeaveGroup` request; client reason: the consumer is being closed (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:38,730] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Preparing to rebalance group console-consumer-82332 in state PreparingRebalance with old generation 1 (reason: explicit `LeaveGroup` request for (console-consumer-d5ae771c-f917-4fcb-9be5-a193d974a2c7) members.). (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:38,730] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Group console-consumer-82332 with generation 2 is now empty. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:40,435] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:55:40,442] INFO Generated cluster model in 8 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:55:40,443] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:55:40,443] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:55:48,260] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=45] Dynamic member with unknown member id joins group console-consumer-65940 in Empty state. Created a new member id console-consumer-ccd3995e-04a3-4a36-b160-7d7a96255435 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:48,265] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=45] Pending dynamic member with id console-consumer-ccd3995e-04a3-4a36-b160-7d7a96255435 joins group console-consumer-65940 in Empty state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:48,265] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=45] Preparing to rebalance group console-consumer-65940 in state PreparingRebalance with old generation 0 (reason: Adding new member console-consumer-ccd3995e-04a3-4a36-b160-7d7a96255435 with group instance id null; client reason: need to re-join with the given member-id: console-consumer-ccd3995e-04a3-4a36-b160-7d7a96255435). (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:48,269] INFO [Partition __consumer_offsets-45 broker=1] roll: __consumer_offsets-45: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 223947 (kafka.cluster.Partition)
[2025-07-23 11:55:48,269] INFO [Partition __consumer_offsets-45 broker=1] roll: __consumer_offsets-45: first produce received, lastOffset: 0, leaderEpoch: 0, numMessages:1, time diff: 223947 (kafka.cluster.Partition)
[2025-07-23 11:55:48,270] INFO [Partition __consumer_offsets-45 broker=1] roll: __consumer_offsets-45: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271524322 ms, time diff: 223948 ms (kafka.cluster.Partition)
[2025-07-23 11:55:48,270] INFO [Partition __consumer_offsets-45 broker=1] roll: __consumer_offsets-45: first HWM advanced, leaderEpoch: 0, old HW: 0, new HW: 1, become leader time: 1753271524322 ms, time diff: 223948 ms (kafka.cluster.Partition)
[2025-07-23 11:55:51,268] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=45] Stabilized group console-consumer-65940 generation 1 with 1 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:51,310] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=45] Assignment received from leader console-consumer-ccd3995e-04a3-4a36-b160-7d7a96255435 for group console-consumer-65940 for generation 1. The group has 1 members, 0 of which are static. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:55:57,767] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 138 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 11:55:57,780] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 11.81 ms each. The slowest event was writeNoOpRecord(1990639426), which took 162.32 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 11:55:57,819] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 11:56:01,791] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=45] [Group console-consumer-65940] Member console-consumer-ccd3995e-04a3-4a36-b160-7d7a96255435 has left group through explicit `LeaveGroup` request; client reason: the consumer is being closed (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:56:01,791] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=45] Preparing to rebalance group console-consumer-65940 in state PreparingRebalance with old generation 1 (reason: explicit `LeaveGroup` request for (console-consumer-ccd3995e-04a3-4a36-b160-7d7a96255435) members.). (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:56:01,791] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=45] Group console-consumer-65940 with generation 2 is now empty. (org.apache.kafka.coordinator.group.GroupMetadataManager)
[2025-07-23 11:56:02,019] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:56:02,019] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:56:02,019] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:56:28,165] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 11:56:28,165] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 11:56:28,167] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 11:56:28,167] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 11:56:32,728] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:56:32,728] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:56:32,730] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:56:40,435] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:56:40,442] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:56:40,442] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:56:40,442] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:56:57,786] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 11.68 ms each. The slowest event was writeNoOpRecord(277922231), which took 51.68 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 11:56:57,824] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 11:57:00,000] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753271640000, endMs=1753271820000, endMsInclusive=1753271819999, index=9740399, baseTimestamp=0}(11:54:00 - 11:56:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 156 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 124 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 11:57:00,061] INFO Finished sampling for 12 partitions - processed 304 metrics over 1 polls for the time range [11:54:00,11:56:59.999], with 304 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=11, TOPIC_BYTES_OUT=11, ALL_TOPIC_BYTES_OUT=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, BROKER_CPU_UTIL=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_BYTES_IN=3, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, ALL_MIRROR_TOPIC_BYTES_IN=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 11:57:00,064] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 11:54:58.689 to 11:56:58.8 (1753271698689 to 1753271818800). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 11:57:00,065] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 11:57:00,065] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 11:57:00,065] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 2->3,current window range [1753269660000, 1753271820000, 11:21:00 to 11:57:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 11:57:00,066] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 2->3,current window range [1753269660000, 1753271820000, 11:21:00 to 11:57:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 11:57:00,066] INFO Successfully finished metric sampling for time period 11:54:00 to 11:56:59.999 (1753271640000 to 1753271819999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:57:00,066] INFO Sleeping the SamplingScheduler until 11:59:59.999 (for 179933ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740399, 11:54:00 - 11:56:59.999), currentWindow: (index: 9740400, 11:57:00 - 11:59:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 11:57:04,153] INFO Saving metric sample completeness to cache for generation 3 and from/to indices 9740388-9740399 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 11:57:04,156] INFO Saving metric sample completeness to cache for generation 3 and from/to indices 9740388-9740399 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 11:57:04,158] INFO Saving metric sample completeness to cache for generation 3 and from/to indices 9740388-9740399 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 11:57:04,160] INFO Saving metric sample completeness to cache for generation 3 and from/to indices 9740388-9740399 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 11:57:04,746] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:57:04,746] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:57:04,747] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:57:33,647] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:57:33,647] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:57:33,650] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:57:40,441] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:57:40,446] INFO Generated cluster model in 6 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:57:40,448] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:57:40,448] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:57:57,784] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 11.29 ms each. The slowest event was writeNoOpRecord(1316497316), which took 50.24 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 11:57:57,823] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 11:58:01,461] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:58:01,461] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:58:01,462] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:58:30,870] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:58:30,870] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:58:30,870] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:58:40,432] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:58:40,435] INFO Generated cluster model in 4 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:58:40,436] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:58:40,436] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:58:57,792] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 11.33 ms each. The slowest event was writeNoOpRecord(1312424621), which took 39.59 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 11:58:57,827] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 11:59:00,892] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:59:00,892] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:59:00,894] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:59:32,937] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:59:32,937] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 11:59:32,939] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 11:59:40,442] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:59:40,447] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 11:59:40,448] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:59:40,448] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 11:59:57,795] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.08 ms each. The slowest event was writeNoOpRecord(1177390071), which took 50.94 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 11:59:57,829] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:00:00,020] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753271820000, endMs=1753272000000, endMsInclusive=1753271999999, index=9740400, baseTimestamp=0}(11:57:00 - 11:59:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 328 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 330 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:00:00,068] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [11:57:00,11:59:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:00:00,070] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 11:57:58.689 to 11:59:58.8 (1753271878689 to 1753271998800). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:00:00,071] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:00:00,071] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:00:00,072] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 3->4,current window range [1753269840000, 1753272000000, 11:24:00 to 12:00:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:00:00,072] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 3->4,current window range [1753269840000, 1753272000000, 11:24:00 to 12:00:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:00:00,072] INFO Successfully finished metric sampling for time period 11:57:00 to 11:59:59.999 (1753271820000 to 1753271999999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:00:00,072] INFO Sleeping the SamplingScheduler until 12:02:59.999 (for 179927ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740400, 11:57:00 - 11:59:59.999), currentWindow: (index: 9740401, 12:00:00 - 12:02:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:00:02,514] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:00:02,514] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:00:02,514] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:00:04,151] INFO Saving metric sample completeness to cache for generation 4 and from/to indices 9740389-9740400 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:00:04,153] INFO Saving metric sample completeness to cache for generation 4 and from/to indices 9740389-9740400 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:00:04,154] INFO Saving metric sample completeness to cache for generation 4 and from/to indices 9740389-9740400 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:00:04,157] INFO Saving metric sample completeness to cache for generation 4 and from/to indices 9740389-9740400 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:00:34,536] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:00:34,536] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:00:34,536] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:00:40,431] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:00:40,433] INFO Generated cluster model in 3 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:00:40,434] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:00:40,434] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:00:57,770] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 165 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 12:00:57,797] INFO [ControllerServer id=1] In the last 60000 ms period, 337 controller events were completed, which took an average of 11.21 ms each. The slowest event was writeNoOpRecord(857829693), which took 48.99 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:00:57,829] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:00:58,071] INFO [NodeToControllerChannelManager id=1 name=registration] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-07-23 12:01:06,542] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:01:06,542] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:01:06,542] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:01:28,178] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:01:28,178] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:01:28,179] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:01:28,179] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:01:34,332] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:01:34,332] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:01:34,332] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:01:40,470] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:01:40,476] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:01:40,478] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:01:40,478] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:01:57,804] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.50 ms each. The slowest event was writeNoOpRecord(1623197328), which took 122.41 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:01:57,830] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:02:04,489] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=45] Generated 1 tombstone records while cleaning up group metadata in 0 milliseconds. (org.apache.kafka.coordinator.group.GroupCoordinatorShard)
[2025-07-23 12:02:04,489] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=19] Generated 1 tombstone records while cleaning up group metadata in 0 milliseconds. (org.apache.kafka.coordinator.group.GroupCoordinatorShard)
[2025-07-23 12:02:06,347] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:02:06,347] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:02:06,349] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:02:34,130] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:02:34,130] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:02:34,131] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:02:40,432] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:02:40,445] INFO Generated cluster model in 16 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:02:40,446] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:02:40,446] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:02:57,814] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.10 ms each. The slowest event was writeNoOpRecord(108792945), which took 42.54 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:02:57,839] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:03:00,023] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753272000000, endMs=1753272180000, endMsInclusive=1753272179999, index=9740401, baseTimestamp=0}(12:00:00 - 12:02:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 533 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 506 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,053] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:03:00,069] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:00:00,12:02:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:03:00,070] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:00:58.692 to 12:02:58.769 (1753272058692 to 1753272178769). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:03:00,072] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:03:00,072] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:03:00,073] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 4->5,current window range [1753270020000, 1753272180000, 11:27:00 to 12:03:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:03:00,073] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 4->5,current window range [1753270020000, 1753272180000, 11:27:00 to 12:03:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:03:00,074] INFO Successfully finished metric sampling for time period 12:00:00 to 12:02:59.999 (1753272000000 to 1753272179999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:03:00,074] INFO Sleeping the SamplingScheduler until 12:05:59.999 (for 179925ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740401, 12:00:00 - 12:02:59.999), currentWindow: (index: 9740402, 12:03:00 - 12:05:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:03:02,932] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:03:02,932] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:03:02,933] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:03:04,152] INFO Saving metric sample completeness to cache for generation 5 and from/to indices 9740390-9740401 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:03:04,153] INFO Saving metric sample completeness to cache for generation 5 and from/to indices 9740390-9740401 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:03:04,154] INFO Saving metric sample completeness to cache for generation 5 and from/to indices 9740390-9740401 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:03:04,156] INFO Saving metric sample completeness to cache for generation 5 and from/to indices 9740390-9740401 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:03:34,938] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:03:34,938] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:03:34,939] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:03:40,472] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:03:40,485] INFO Generated cluster model in 20 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:03:40,485] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:03:40,485] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:03:57,817] INFO [ControllerServer id=1] In the last 60000 ms period, 336 controller events were completed, which took an average of 11.17 ms each. The slowest event was writeNoOpRecord(235767984), which took 47.71 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:03:57,840] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:04:04,391] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:04:04,391] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:04:04,392] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:04:04,394] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 12:04:04,394] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 12:04:35,588] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:04:35,588] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:04:35,588] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:04:40,431] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:04:40,436] INFO Generated cluster model in 7 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:04:40,436] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:04:40,436] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:04:57,824] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 11.52 ms each. The slowest event was writeNoOpRecord(1280890486), which took 56.03 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:04:57,846] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:05:04,514] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:05:04,514] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:05:04,515] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:05:33,717] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:05:33,717] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:05:33,718] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:05:40,453] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:05:40,457] INFO Generated cluster model in 5 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:05:40,458] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:05:40,458] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:05:57,778] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 1113 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 12:05:57,828] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 11.44 ms each. The slowest event was writeNoOpRecord(1149507286), which took 50.37 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:05:57,853] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:05:59,875] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:05:59,875] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:05:59,878] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:06:00,018] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753272180000, endMs=1753272360000, endMsInclusive=1753272359999, index=9740402, baseTimestamp=0}(12:03:00 - 12:05:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 738 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 682 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:06:00,075] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:03:00,12:05:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_OUT=12, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_BYTES_IN=3, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, ALL_MIRROR_TOPIC_BYTES_IN=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:06:00,082] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:03:58.688 to 12:05:58.775 (1753272238688 to 1753272358775). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:06:00,083] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:06:00,083] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:06:00,083] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 5->6,current window range [1753270200000, 1753272360000, 11:30:00 to 12:06:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:06:00,083] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 5->6,current window range [1753270200000, 1753272360000, 11:30:00 to 12:06:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:06:00,083] INFO Successfully finished metric sampling for time period 12:03:00 to 12:05:59.999 (1753272180000 to 1753272359999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:06:00,083] INFO Sleeping the SamplingScheduler until 12:08:59.999 (for 179916ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740402, 12:03:00 - 12:05:59.999), currentWindow: (index: 9740403, 12:06:00 - 12:08:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:06:04,156] INFO Saving metric sample completeness to cache for generation 6 and from/to indices 9740391-9740402 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:06:04,158] INFO Saving metric sample completeness to cache for generation 6 and from/to indices 9740391-9740402 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:06:04,159] INFO Saving metric sample completeness to cache for generation 6 and from/to indices 9740391-9740402 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:06:04,162] INFO Saving metric sample completeness to cache for generation 6 and from/to indices 9740391-9740402 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:06:28,170] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:06:28,170] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:06:28,171] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:06:28,171] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:06:31,894] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:06:31,894] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:06:31,895] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:06:40,433] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:06:40,443] INFO Generated cluster model in 13 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:06:40,444] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:06:40,444] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:06:57,836] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.76 ms each. The slowest event was writeNoOpRecord(1739651332), which took 59.28 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:06:57,854] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:07:02,898] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:07:02,898] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:07:02,900] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:07:34,921] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:07:34,921] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:07:34,922] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:07:40,458] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:07:40,464] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:07:40,464] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:07:40,465] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:07:57,841] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.88 ms each. The slowest event was writeNoOpRecord(886633009), which took 54.69 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:07:57,866] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:08:06,940] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:08:06,940] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:08:06,940] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:08:38,956] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:08:38,956] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:08:38,962] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:08:40,450] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:08:40,454] INFO Generated cluster model in 6 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:08:40,455] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:08:40,455] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:08:57,849] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 11.91 ms each. The slowest event was writeNoOpRecord(1414281789), which took 54.11 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:08:57,875] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:09:00,002] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753272360000, endMs=1753272540000, endMsInclusive=1753272539999, index=9740403, baseTimestamp=0}(12:06:00 - 12:08:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 912 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 889 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,019] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:09:00,043] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:06:00,12:08:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:09:00,044] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:06:58.705 to 12:08:58.78 (1753272418705 to 1753272538780). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:09:00,045] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:09:00,045] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:09:00,045] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 6->7,current window range [1753270380000, 1753272540000, 11:33:00 to 12:09:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:09:00,046] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 6->7,current window range [1753270380000, 1753272540000, 11:33:00 to 12:09:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:09:00,046] INFO Successfully finished metric sampling for time period 12:06:00 to 12:08:59.999 (1753272360000 to 1753272539999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:09:00,046] INFO Sleeping the SamplingScheduler until 12:11:59.999 (for 179953ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740403, 12:06:00 - 12:08:59.999), currentWindow: (index: 9740404, 12:09:00 - 12:11:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:09:04,156] INFO Saving metric sample completeness to cache for generation 7 and from/to indices 9740392-9740403 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:09:04,158] INFO Saving metric sample completeness to cache for generation 7 and from/to indices 9740392-9740403 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:09:04,159] INFO Saving metric sample completeness to cache for generation 7 and from/to indices 9740392-9740403 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:09:04,162] INFO Saving metric sample completeness to cache for generation 7 and from/to indices 9740392-9740403 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:09:10,972] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:09:10,972] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:09:10,973] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:09:40,442] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:09:40,446] INFO Generated cluster model in 6 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:09:40,446] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:09:40,446] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:09:42,992] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:09:42,992] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:09:42,993] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:09:57,853] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 11.11 ms each. The slowest event was writeNoOpRecord(1775375018), which took 46.65 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:09:57,878] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:10:15,012] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:10:15,012] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:10:15,014] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:10:40,354] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:10:40,358] INFO Generated cluster model in 6 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:10:40,358] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:10:40,358] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:10:46,964] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:10:46,964] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:10:46,966] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:10:57,722] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 259 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 12:10:57,791] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 10.85 ms each. The slowest event was writeNoOpRecord(391273135), which took 64.33 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:10:57,821] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:11:19,014] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:11:19,014] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:11:19,015] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:11:28,110] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:11:28,110] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:11:28,121] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:11:28,121] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:11:40,377] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:11:40,380] INFO Generated cluster model in 5 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:11:40,381] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:11:40,381] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:11:51,071] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:11:51,071] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:11:51,074] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:11:57,790] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.37 ms each. The slowest event was writeNoOpRecord(35717817), which took 58.89 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:11:57,818] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:11:59,933] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753272540000, endMs=1753272720000, endMsInclusive=1753272719999, index=9740404, baseTimestamp=0}(12:09:00 - 12:11:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:11:59,966] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1106 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1076 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:11:59,993] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:09:00,12:11:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_OUT=12, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:11:59,995] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:09:58.701 to 12:11:58.738 (1753272598701 to 1753272718738). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:11:59,996] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:11:59,996] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:11:59,996] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 7->8,current window range [1753270560000, 1753272720000, 11:36:00 to 12:12:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:11:59,996] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 7->8,current window range [1753270560000, 1753272720000, 11:36:00 to 12:12:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:11:59,996] INFO Successfully finished metric sampling for time period 12:09:00 to 12:11:59.999 (1753272540000 to 1753272719999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:11:59,996] WARN Tried to sample a window that we've already sampled. This is unexpected - might it be due to clock skew? Sleeping until the end of the next window we haven't sampled...  (nowMs: 1753272719996(12:11:59.996), normalizedTargetWindowTimestamp:1753272719996(12:11:59.996) currentWindow: MetricsWindow{sizeMs=180000, startMs=1753272540000, endMs=1753272720000, endMsInclusive=1753272719999, index=9740404, baseTimestamp=0}(12:09:00 - 12:11:59.999), lastSampledWindow: MetricsWindow{sizeMs=180000, startMs=1753272540000, endMs=1753272720000, endMsInclusive=1753272719999, index=9740404, baseTimestamp=0}(12:09:00 - 12:11:59.999)), next window: MetricsWindow{sizeMs=180000, startMs=1753272720000, endMs=1753272900000, endMsInclusive=1753272899999, index=9740405, baseTimestamp=0}(12:12:00 - 12:14:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:11:59,997] INFO Sleeping the SamplingScheduler until 12:14:59.999 (for 180003ms) as instructed due to reason The SamplingScheduler's current window is either behind or exactly at what it has already sampled. The SamplingScheduler should sleep until the window after the last sampled window passes. (currentWindow: (index: 9740404, 12:09:00 - 12:11:59.999), last sampled window: (index: 9740404, 12:09:00 - 12:11:59.999), target window after that: (index: 9740405, 12:12:00 - 12:14:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:12:04,096] INFO Saving metric sample completeness to cache for generation 8 and from/to indices 9740393-9740404 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:12:04,103] INFO Saving metric sample completeness to cache for generation 8 and from/to indices 9740393-9740404 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:12:04,105] INFO Saving metric sample completeness to cache for generation 8 and from/to indices 9740393-9740404 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:12:04,108] INFO Saving metric sample completeness to cache for generation 8 and from/to indices 9740393-9740404 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:12:21,257] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:12:21,257] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:12:21,258] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:12:40,428] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:12:40,432] INFO Generated cluster model in 37 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:12:40,433] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:12:40,433] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:12:51,752] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:12:51,752] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:12:51,753] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:12:57,794] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.43 ms each. The slowest event was writeNoOpRecord(588275269), which took 156.78 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:12:57,823] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:13:22,662] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:13:22,662] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:13:22,665] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:13:40,380] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:13:40,393] INFO Generated cluster model in 16 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:13:40,393] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:13:40,393] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:13:52,753] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:13:52,753] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:13:52,756] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:13:57,797] INFO [ControllerServer id=1] In the last 60000 ms period, 336 controller events were completed, which took an average of 10.75 ms each. The slowest event was writeNoOpRecord(2097660168), which took 40.09 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:13:57,824] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:14:23,760] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:14:23,760] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:14:23,763] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:14:40,373] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:14:40,382] INFO Generated cluster model in 13 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:14:40,383] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:14:40,383] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:14:55,801] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:14:55,801] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:14:55,804] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:14:57,800] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.30 ms each. The slowest event was writeNoOpRecord(1465781428), which took 44.13 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:14:57,826] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:15:00,010] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753272720000, endMs=1753272900000, endMsInclusive=1753272899999, index=9740405, baseTimestamp=0}(12:12:00 - 12:14:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1282 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1281 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,027] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:15:00,040] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:12:00,12:14:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:15:00,041] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:12:58.627 to 12:14:58.738 (1753272778627 to 1753272898738). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:15:00,042] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:15:00,042] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:15:00,042] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 8->9,current window range [1753270740000, 1753272900000, 11:39:00 to 12:15:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:15:00,042] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 8->9,current window range [1753270740000, 1753272900000, 11:39:00 to 12:15:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:15:00,042] INFO Successfully finished metric sampling for time period 12:12:00 to 12:14:59.999 (1753272720000 to 1753272899999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:15:00,042] INFO Sleeping the SamplingScheduler until 12:17:59.999 (for 179957ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740405, 12:12:00 - 12:14:59.999), currentWindow: (index: 9740406, 12:15:00 - 12:17:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:15:04,098] INFO Saving metric sample completeness to cache for generation 9 and from/to indices 9740394-9740405 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:15:04,100] INFO Saving metric sample completeness to cache for generation 9 and from/to indices 9740394-9740405 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:15:04,101] INFO Saving metric sample completeness to cache for generation 9 and from/to indices 9740394-9740405 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:15:04,102] INFO Saving metric sample completeness to cache for generation 9 and from/to indices 9740394-9740405 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:15:25,615] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:15:25,615] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:15:25,616] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:15:40,373] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:15:40,381] INFO Generated cluster model in 12 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:15:40,382] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:15:40,382] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:15:54,120] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:15:54,120] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:15:54,121] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:15:57,722] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 414 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 12:15:57,802] INFO [ControllerServer id=1] In the last 60000 ms period, 336 controller events were completed, which took an average of 10.86 ms each. The slowest event was writeNoOpRecord(887350921), which took 36.55 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:15:57,828] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:16:25,576] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:16:25,576] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:16:25,580] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:16:28,106] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:16:28,106] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:16:28,107] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:16:28,107] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:16:40,373] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:16:40,380] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:16:40,381] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:16:40,381] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:16:57,597] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:16:57,597] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:16:57,598] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:16:57,804] INFO [ControllerServer id=1] In the last 60000 ms period, 329 controller events were completed, which took an average of 11.50 ms each. The slowest event was writeNoOpRecord(80805179), which took 54.69 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:16:57,829] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:17:28,897] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:17:28,897] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:17:28,902] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:17:40,376] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:17:40,382] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:17:40,383] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:17:40,383] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:17:57,805] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.06 ms each. The slowest event was writeNoOpRecord(1076633190), which took 45.33 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:17:57,830] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:17:59,999] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753272900000, endMs=1753273080000, endMsInclusive=1753273079999, index=9740406, baseTimestamp=0}(12:15:00 - 12:17:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:18:00,083] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1465 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1479 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:18:00,102] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:15:00,12:17:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_IN=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_BYTES_IN=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:18:00,103] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:15:58.645 to 12:17:58.769 (1753272958645 to 1753273078769). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:18:00,104] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:18:00,104] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:18:00,104] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 9->10,current window range [1753270920000, 1753273080000, 11:42:00 to 12:18:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:18:00,104] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 9->10,current window range [1753270920000, 1753273080000, 11:42:00 to 12:18:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:18:00,104] INFO Successfully finished metric sampling for time period 12:15:00 to 12:17:59.999 (1753272900000 to 1753273079999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:18:00,105] INFO Sleeping the SamplingScheduler until 12:20:59.999 (for 179895ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740406, 12:15:00 - 12:17:59.999), currentWindow: (index: 9740407, 12:18:00 - 12:20:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:18:00,923] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:18:00,923] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:18:00,924] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:18:04,090] INFO Saving metric sample completeness to cache for generation 10 and from/to indices 9740395-9740406 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:18:04,092] INFO Saving metric sample completeness to cache for generation 10 and from/to indices 9740395-9740406 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:18:04,094] INFO Saving metric sample completeness to cache for generation 10 and from/to indices 9740395-9740406 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:18:04,097] INFO Saving metric sample completeness to cache for generation 10 and from/to indices 9740395-9740406 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:18:32,949] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:18:32,949] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:18:32,954] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:18:40,381] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:18:40,385] INFO Generated cluster model in 7 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:18:40,386] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:18:40,386] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:18:57,809] INFO [ControllerServer id=1] In the last 60000 ms period, 338 controller events were completed, which took an average of 11.33 ms each. The slowest event was writeNoOpRecord(1878925016), which took 55.05 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:18:57,830] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:18:59,557] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:18:59,557] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:18:59,558] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:19:25,415] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:19:25,415] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:19:25,419] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:19:25,425] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 12:19:25,425] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 12:19:40,382] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:19:40,400] INFO Generated cluster model in 29 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:19:40,401] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:19:40,401] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:19:57,446] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:19:57,446] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:19:57,447] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:19:57,812] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 10.86 ms each. The slowest event was writeNoOpRecord(159225968), which took 45.07 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:19:57,830] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:20:29,454] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:20:29,454] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:20:29,456] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:20:40,378] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:20:40,385] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:20:40,386] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:20:40,386] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:20:55,688] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:20:55,688] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:20:55,689] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:20:57,722] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 227 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 12:20:57,818] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 11.11 ms each. The slowest event was writeNoOpRecord(434791911), which took 47.00 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:20:57,833] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:20:59,999] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753273080000, endMs=1753273260000, endMsInclusive=1753273259999, index=9740407, baseTimestamp=0}(12:18:00 - 12:20:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:21:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1665 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,036] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1660 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:21:00,059] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:18:00,12:20:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, BROKER_CPU_UTIL=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:21:00,063] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:18:58.626 to 12:20:58.715 (1753273138626 to 1753273258715). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:21:00,075] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:21:00,075] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:21:00,075] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 10->11,current window range [1753271100000, 1753273260000, 11:45:00 to 12:21:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:21:00,075] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 10->11,current window range [1753271100000, 1753273260000, 11:45:00 to 12:21:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:21:00,075] INFO Successfully finished metric sampling for time period 12:18:00 to 12:20:59.999 (1753273080000 to 1753273259999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:21:00,075] INFO Sleeping the SamplingScheduler until 12:23:59.999 (for 179924ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740407, 12:18:00 - 12:20:59.999), currentWindow: (index: 9740408, 12:21:00 - 12:23:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:21:04,085] INFO Saving metric sample completeness to cache for generation 11 and from/to indices 9740396-9740407 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:21:04,086] INFO Saving metric sample completeness to cache for generation 11 and from/to indices 9740396-9740407 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:21:04,086] INFO Saving metric sample completeness to cache for generation 11 and from/to indices 9740396-9740407 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:21:04,088] INFO Saving metric sample completeness to cache for generation 11 and from/to indices 9740396-9740407 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:21:27,699] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:21:27,699] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:21:27,701] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:21:28,103] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:21:28,103] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:21:28,104] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:21:28,104] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:21:40,371] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:21:40,377] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:21:40,378] INFO Skipping goal violation detection due to previous new broker change - will resume at 12:22:04.172 (1753273324172) (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:21:40,378] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:21:55,718] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:21:55,718] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:21:55,719] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:21:57,834] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:21:57,837] INFO [ControllerServer id=1] In the last 60000 ms period, 334 controller events were completed, which took an average of 11.13 ms each. The slowest event was writeNoOpRecord(465807602), which took 47.14 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:22:04,179] INFO Broker change event(s) detected: [] (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 12:22:04,183] INFO Alive brokers: [1], failed brokers: [] (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 12:22:04,183] INFO Updated list of failed broker: {} (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 12:22:27,747] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:22:27,747] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:22:27,750] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:22:40,373] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:22:40,388] INFO Generated cluster model in 19 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:22:40,470] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:22:40,502] INFO Max replica load per broker for resource disk in MiB is: [1=0.04892253875732422] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:22:40,530] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.0065453751012682915] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:22:40,536] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006389735732227564] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:22:40,537] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:22:40,538] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.0065453751012682915] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:22:40,539] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:22:40,554] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.18, lower limit: 0.14, upper limit: 0.22), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.18, lower limit: 0.14, upper limit: 0.22}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:22:40,557] INFO Max replica load per broker for resource disk in MiB is: [1=0.04892253875732422] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:22:40,559] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:22:40,568] INFO Loaded an even cluster load state record EvenClusterLoadStateRecord{ currentState=BALANCED, currentStateCreatedAt=1753273360559, currentStateLastUpdatedAt=1753273360559, currentStateException=null, previousState=null, previousStateCreatedAt=0, previousStateLastUpdatedAt=0, previousStateException=null} (io.confluent.databalancer.persistence.ApiStatePersistenceStore)
[2025-07-23 12:22:40,568] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:22:57,834] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:22:57,837] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 11.01 ms each. The slowest event was writeNoOpRecord(976543108), which took 57.74 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:22:59,761] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:22:59,761] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:22:59,761] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:23:29,667] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:23:29,667] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:23:29,669] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:23:40,356] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:23:40,362] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:23:40,365] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:23:40,369] INFO Max replica load per broker for resource disk in MiB is: [1=0.04892253875732422] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:23:40,371] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.0065453751012682915] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:23:40,372] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006389735732227564] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:23:40,373] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:23:40,374] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.0065453751012682915] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:23:40,375] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:23:40,377] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.18, lower limit: 0.14, upper limit: 0.22), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.18, lower limit: 0.14, upper limit: 0.22}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:23:40,377] INFO Max replica load per broker for resource disk in MiB is: [1=0.04892253875732422] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:23:40,377] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:23:40,378] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:23:57,600] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:23:57,600] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:23:57,600] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:23:57,834] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:23:57,839] INFO [ControllerServer id=1] In the last 60000 ms period, 336 controller events were completed, which took an average of 11.13 ms each. The slowest event was writeNoOpRecord(1115596866), which took 45.26 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:23:59,998] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753273260000, endMs=1753273440000, endMsInclusive=1753273439999, index=9740408, baseTimestamp=0}(12:21:00 - 12:23:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:24:00,017] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,017] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,017] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1838 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 1868 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:24:00,034] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:21:00,12:23:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, BROKER_CPU_UTIL=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_CONSUME_CAPACITY=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:24:00,036] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:21:58.628 to 12:23:58.712 (1753273318628 to 1753273438712). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:24:00,037] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:24:00,037] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:24:00,038] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 11->12,current window range [1753271280000, 1753273440000, 11:48:00 to 12:24:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:24:00,038] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 11->12,current window range [1753271280000, 1753273440000, 11:48:00 to 12:24:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:24:00,038] INFO Successfully finished metric sampling for time period 12:21:00 to 12:23:59.999 (1753273260000 to 1753273439999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:24:00,038] INFO Sleeping the SamplingScheduler until 12:26:59.999 (for 179961ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740408, 12:21:00 - 12:23:59.999), currentWindow: (index: 9740409, 12:24:00 - 12:26:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:24:04,084] INFO Saving metric sample completeness to cache for generation 12 and from/to indices 9740397-9740408 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:24:04,086] INFO Saving metric sample completeness to cache for generation 12 and from/to indices 9740397-9740408 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:24:04,087] INFO Saving metric sample completeness to cache for generation 12 and from/to indices 9740397-9740408 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:24:04,090] INFO Saving metric sample completeness to cache for generation 12 and from/to indices 9740397-9740408 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:24:29,641] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:24:29,641] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:24:29,644] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:24:40,378] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:24:40,385] INFO Generated cluster model in 12 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:24:40,392] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:24:40,397] INFO Max replica load per broker for resource disk in MiB is: [1=0.05343879386782646] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:24:40,398] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.006425566505640745] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:24:40,401] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006310372147709131] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:24:40,402] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:24:40,402] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.006425566505640745] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:24:40,403] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:24:40,405] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.20, lower limit: 0.16, upper limit: 0.24), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.20, lower limit: 0.16, upper limit: 0.24}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:24:40,405] INFO Max replica load per broker for resource disk in MiB is: [1=0.05343879386782646] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:24:40,405] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:24:40,405] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:24:55,824] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:24:55,824] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:24:55,825] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:24:57,836] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:24:57,841] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.39 ms each. The slowest event was writeNoOpRecord(2142142141), which took 51.97 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:25:27,846] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:25:27,846] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:25:27,847] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:25:40,370] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:25:40,374] INFO Generated cluster model in 8 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:25:40,377] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:25:40,379] INFO Max replica load per broker for resource disk in MiB is: [1=0.05343879386782646] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:25:40,380] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.006425566505640745] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:25:40,381] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006310372147709131] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:25:40,381] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:25:40,382] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.006425566505640745] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:25:40,383] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:25:40,383] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.20, lower limit: 0.16, upper limit: 0.24), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.20, lower limit: 0.16, upper limit: 0.24}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:25:40,384] INFO Max replica load per broker for resource disk in MiB is: [1=0.05343879386782646] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:25:40,384] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:25:40,384] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:25:57,722] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 309 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 12:25:57,837] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:25:57,841] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.82 ms each. The slowest event was writeNoOpRecord(1187271447), which took 54.94 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:25:59,873] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:25:59,873] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:25:59,874] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:26:28,105] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:26:28,105] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:26:28,106] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:26:28,106] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:26:28,193] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:26:28,193] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:26:28,194] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:26:40,380] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:26:40,390] INFO Generated cluster model in 15 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:26:40,398] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:26:40,404] INFO Max replica load per broker for resource disk in MiB is: [1=0.05343879386782646] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:26:40,406] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.006425566505640745] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:26:40,410] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006310372147709131] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:26:40,411] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:26:40,412] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.006425566505640745] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:26:40,412] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:26:40,414] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.20, lower limit: 0.16, upper limit: 0.24), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.20, lower limit: 0.16, upper limit: 0.24}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:26:40,414] INFO Max replica load per broker for resource disk in MiB is: [1=0.05343879386782646] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:26:40,415] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:26:40,415] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:26:57,839] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:26:57,845] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.51 ms each. The slowest event was writeNoOpRecord(1408245995), which took 45.30 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:26:58,543] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:26:58,543] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:26:58,544] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:27:00,002] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753273440000, endMs=1753273620000, endMsInclusive=1753273619999, index=9740409, baseTimestamp=0}(12:24:00 - 12:26:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2031 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2056 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:27:00,057] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:24:00,12:26:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, BROKER_CPU_UTIL=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:27:00,059] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:24:58.626 to 12:26:58.694 (1753273498626 to 1753273618694). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:27:00,059] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:27:00,059] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:27:00,060] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 12->13,current window range [1753271460000, 1753273620000, 11:51:00 to 12:27:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:27:00,060] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 12->13,current window range [1753271460000, 1753273620000, 11:51:00 to 12:27:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:27:00,060] INFO Successfully finished metric sampling for time period 12:24:00 to 12:26:59.999 (1753273440000 to 1753273619999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:27:00,060] INFO Sleeping the SamplingScheduler until 12:29:59.999 (for 179939ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740409, 12:24:00 - 12:26:59.999), currentWindow: (index: 9740410, 12:27:00 - 12:29:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:27:04,088] INFO Saving metric sample completeness to cache for generation 13 and from/to indices 9740398-9740409 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:27:04,091] INFO Saving metric sample completeness to cache for generation 13 and from/to indices 9740398-9740409 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:27:04,093] INFO Saving metric sample completeness to cache for generation 13 and from/to indices 9740398-9740409 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:27:04,097] INFO Saving metric sample completeness to cache for generation 13 and from/to indices 9740398-9740409 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:27:30,556] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:27:30,556] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:27:30,558] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:27:40,380] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:27:40,387] INFO Generated cluster model in 11 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:27:40,393] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:27:40,399] INFO Max replica load per broker for resource disk in MiB is: [1=0.05797799304127693] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:27:40,400] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.006322868168354034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:27:40,401] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006217006593942642] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:27:40,402] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:27:40,403] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.006322868168354034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:27:40,404] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:27:40,405] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.22, lower limit: 0.17, upper limit: 0.26), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.22, lower limit: 0.17, upper limit: 0.26}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:27:40,405] INFO Max replica load per broker for resource disk in MiB is: [1=0.05797799304127693] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:27:40,406] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:27:40,406] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:27:57,838] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:27:57,846] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 12.01 ms each. The slowest event was writeNoOpRecord(2089095981), which took 45.71 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:28:02,585] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:28:02,585] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:28:02,588] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:28:34,627] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:28:34,627] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:28:34,630] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:28:40,386] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:28:40,391] INFO Generated cluster model in 8 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:28:40,396] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:28:40,400] INFO Max replica load per broker for resource disk in MiB is: [1=0.05797799304127693] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:28:40,402] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.006322868168354034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:28:40,403] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006217006593942642] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:28:40,404] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:28:40,404] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.006322868168354034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:28:40,405] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:28:40,407] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.22, lower limit: 0.17, upper limit: 0.26), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.22, lower limit: 0.17, upper limit: 0.26}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:28:40,407] INFO Max replica load per broker for resource disk in MiB is: [1=0.05797799304127693] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:28:40,407] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:28:40,408] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:28:57,840] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:28:57,851] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 11.74 ms each. The slowest event was writeNoOpRecord(1629407158), which took 68.72 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:29:06,636] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:29:06,636] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:29:06,637] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:29:38,633] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:29:38,633] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:29:38,634] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:29:40,354] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:29:40,360] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:29:40,361] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:29:40,365] INFO Max replica load per broker for resource disk in MiB is: [1=0.05797799304127693] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:29:40,366] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.006322868168354034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:29:40,367] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006217006593942642] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:29:40,367] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:29:40,368] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.006322868168354034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:29:40,369] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:29:40,369] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.22, lower limit: 0.17, upper limit: 0.26), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.22, lower limit: 0.17, upper limit: 0.26}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:29:40,370] INFO Max replica load per broker for resource disk in MiB is: [1=0.05797799304127693] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:29:40,370] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:29:40,370] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:29:57,821] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:29:57,837] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 12.27 ms each. The slowest event was writeNoOpRecord(1695978379), which took 64.16 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:29:59,981] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753273620000, endMs=1753273800000, endMsInclusive=1753273799999, index=9740410, baseTimestamp=0}(12:27:00 - 12:29:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2230 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2238 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,018] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:30:00,029] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:27:00,12:29:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:30:00,030] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:27:58.62 to 12:29:58.665 (1753273678620 to 1753273798665). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:30:00,030] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:30:00,030] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:30:00,030] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 13->14,current window range [1753271640000, 1753273800000, 11:54:00 to 12:30:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:30:00,030] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 13->14,current window range [1753271640000, 1753273800000, 11:54:00 to 12:30:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:30:00,031] INFO Successfully finished metric sampling for time period 12:27:00 to 12:29:59.999 (1753273620000 to 1753273799999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:30:00,031] INFO Sleeping the SamplingScheduler until 12:32:59.999 (for 179968ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740410, 12:27:00 - 12:29:59.999), currentWindow: (index: 9740411, 12:30:00 - 12:32:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:30:04,069] INFO Saving metric sample completeness to cache for generation 14 and from/to indices 9740399-9740410 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:30:04,071] INFO Saving metric sample completeness to cache for generation 14 and from/to indices 9740399-9740410 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:30:04,072] INFO Saving metric sample completeness to cache for generation 14 and from/to indices 9740399-9740410 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:30:04,074] INFO Saving metric sample completeness to cache for generation 14 and from/to indices 9740399-9740410 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:30:09,344] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:30:09,344] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:30:09,345] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:30:40,359] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:30:40,365] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:30:40,370] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:30:40,372] INFO Max replica load per broker for resource disk in MiB is: [1=0.06731732934713364] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:30:40,373] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005479181185364723] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:30:40,374] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00542655261233449] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:30:40,375] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:30:40,375] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005479181185364723] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:30:40,376] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:30:40,422] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.24, lower limit: 0.19, upper limit: 0.29), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.24, lower limit: 0.19, upper limit: 0.29}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:30:40,423] INFO Max replica load per broker for resource disk in MiB is: [1=0.06731732934713364] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:30:40,423] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:30:40,424] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:30:40,622] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:30:40,622] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:30:40,623] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:30:57,701] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 289 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 12:30:57,817] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:30:57,835] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 11.47 ms each. The slowest event was writeNoOpRecord(1066085790), which took 47.56 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:31:12,638] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:31:12,638] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:31:12,638] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:31:28,080] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:31:28,080] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:31:28,080] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:31:28,080] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:31:40,361] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:31:40,368] INFO Generated cluster model in 11 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:31:40,372] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:31:40,377] INFO Max replica load per broker for resource disk in MiB is: [1=0.06731732934713364] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:31:40,378] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005479181185364723] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:31:40,380] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00542655261233449] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:31:40,380] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:31:40,381] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005479181185364723] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:31:40,382] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:31:40,384] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.24, lower limit: 0.19, upper limit: 0.29), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.24, lower limit: 0.19, upper limit: 0.29}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:31:40,384] INFO Max replica load per broker for resource disk in MiB is: [1=0.06731732934713364] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:31:40,384] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:31:40,384] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:31:40,447] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:31:40,447] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:31:40,447] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:31:57,818] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:31:57,842] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.61 ms each. The slowest event was writeNoOpRecord(883885458), which took 49.05 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:32:12,456] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:32:12,456] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:32:12,457] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:32:40,405] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:32:40,410] INFO Generated cluster model in 8 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:32:40,415] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:32:40,418] INFO Max replica load per broker for resource disk in MiB is: [1=0.06731732934713364] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:32:40,419] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005479181185364723] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:32:40,420] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00542655261233449] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:32:40,420] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:32:40,421] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005479181185364723] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:32:40,421] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:32:40,423] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.24, lower limit: 0.19, upper limit: 0.29), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.24, lower limit: 0.19, upper limit: 0.29}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:32:40,423] INFO Max replica load per broker for resource disk in MiB is: [1=0.06731732934713364] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:32:40,423] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:32:40,423] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:32:42,708] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:32:42,708] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:32:42,711] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:32:57,820] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:32:57,848] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.46 ms each. The slowest event was writeNoOpRecord(711819212), which took 43.22 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:32:59,996] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753273800000, endMs=1753273980000, endMsInclusive=1753273979999, index=9740411, baseTimestamp=0}(12:30:00 - 12:32:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2414 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2435 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:33:00,053] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:30:00,12:32:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_CONSUME_CAPACITY=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:33:00,054] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:30:58.603 to 12:32:58.716 (1753273858603 to 1753273978716). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:33:00,054] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:33:00,054] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:33:00,055] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 14->15,current window range [1753271820000, 1753273980000, 11:57:00 to 12:33:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:33:00,056] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 14->15,current window range [1753271820000, 1753273980000, 11:57:00 to 12:33:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:33:00,056] INFO Successfully finished metric sampling for time period 12:30:00 to 12:32:59.999 (1753273800000 to 1753273979999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:33:00,056] INFO Sleeping the SamplingScheduler until 12:35:59.999 (for 179943ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740411, 12:30:00 - 12:32:59.999), currentWindow: (index: 9740412, 12:33:00 - 12:35:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:33:04,065] INFO Saving metric sample completeness to cache for generation 15 and from/to indices 9740400-9740411 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:33:04,068] INFO Saving metric sample completeness to cache for generation 15 and from/to indices 9740400-9740411 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:33:04,070] INFO Saving metric sample completeness to cache for generation 15 and from/to indices 9740400-9740411 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:33:04,073] INFO Saving metric sample completeness to cache for generation 15 and from/to indices 9740400-9740411 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:33:14,367] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:33:14,367] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:33:14,368] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:33:40,081] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:33:40,081] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:33:40,082] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:33:40,355] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:33:40,362] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:33:40,364] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:33:40,367] INFO Max replica load per broker for resource disk in MiB is: [1=0.07647919654846191] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:33:40,368] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005335550289601088] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:33:40,369] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00537128234282136] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:33:40,370] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:33:40,370] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005335550289601088] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:33:40,371] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:33:40,372] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.25, lower limit: 0.20, upper limit: 0.31), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.25, lower limit: 0.20, upper limit: 0.31}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:33:40,372] INFO Max replica load per broker for resource disk in MiB is: [1=0.07647919654846191] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:33:40,373] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:33:40,373] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:33:57,821] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:33:57,859] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 11.20 ms each. The slowest event was writeNoOpRecord(1710958372), which took 45.97 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:34:09,595] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:34:09,595] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:34:09,596] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:34:40,358] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:34:40,368] INFO Generated cluster model in 17 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:34:40,381] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:34:40,385] INFO Max replica load per broker for resource disk in MiB is: [1=0.07647919654846191] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:34:40,386] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005335550289601088] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:34:40,387] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00537128234282136] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:34:40,388] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:34:40,389] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005335550289601088] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:34:40,389] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:34:40,391] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.25, lower limit: 0.20, upper limit: 0.31), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.25, lower limit: 0.20, upper limit: 0.31}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:34:40,392] INFO Max replica load per broker for resource disk in MiB is: [1=0.07647919654846191] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:34:40,392] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:34:40,392] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:34:41,630] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:34:41,630] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:34:41,633] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:34:41,643] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 12:34:41,643] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 12:34:57,822] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:34:57,863] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 12.48 ms each. The slowest event was writeNoOpRecord(1154703086), which took 167.46 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:35:12,908] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:35:12,908] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:35:12,909] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:35:40,359] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:35:40,369] INFO Generated cluster model in 18 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:35:40,372] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:35:40,375] INFO Max replica load per broker for resource disk in MiB is: [1=0.07647919654846191] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:35:40,375] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005335550289601088] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:35:40,376] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00537128234282136] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:35:40,377] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:35:40,377] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005335550289601088] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:35:40,378] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:35:40,380] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.25, lower limit: 0.20, upper limit: 0.31), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.25, lower limit: 0.20, upper limit: 0.31}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:35:40,380] INFO Max replica load per broker for resource disk in MiB is: [1=0.07647919654846191] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:35:40,380] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:35:40,380] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:35:44,925] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:35:44,925] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:35:44,927] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:35:57,700] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 79 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 12:35:57,821] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:35:57,863] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 10.99 ms each. The slowest event was writeNoOpRecord(1508691695), which took 46.98 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:35:59,997] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753273980000, endMs=1753274160000, endMsInclusive=1753274159999, index=9740412, baseTimestamp=0}(12:33:00 - 12:35:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:36:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2604 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2626 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:36:00,179] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:33:00,12:35:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, ALL_MIRROR_TOPIC_BYTES_IN=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:36:00,185] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:33:58.609 to 12:35:58.655 (1753274038609 to 1753274158655). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:36:00,186] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:36:00,186] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:36:00,186] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 15->16,current window range [1753272000000, 1753274160000, 12:00:00 to 12:36:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:36:00,186] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 15->16,current window range [1753272000000, 1753274160000, 12:00:00 to 12:36:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:36:00,186] INFO Successfully finished metric sampling for time period 12:33:00 to 12:35:59.999 (1753273980000 to 1753274159999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:36:00,187] INFO Sleeping the SamplingScheduler until 12:38:59.999 (for 179812ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740412, 12:33:00 - 12:35:59.999), currentWindow: (index: 9740413, 12:36:00 - 12:38:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:36:04,062] INFO Saving metric sample completeness to cache for generation 16 and from/to indices 9740401-9740412 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:36:04,068] INFO Saving metric sample completeness to cache for generation 16 and from/to indices 9740401-9740412 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:36:04,071] INFO Saving metric sample completeness to cache for generation 16 and from/to indices 9740401-9740412 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:36:04,072] INFO Saving metric sample completeness to cache for generation 16 and from/to indices 9740401-9740412 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:36:16,962] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:36:16,962] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:36:16,963] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:36:28,080] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:36:28,080] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:36:28,082] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:36:28,082] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:36:40,348] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:36:40,357] INFO Generated cluster model in 14 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:36:40,362] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:36:40,366] INFO Max replica load per broker for resource disk in MiB is: [1=0.08548808097839355] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:36:40,367] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005246673244982958] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:36:40,368] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.005292592104524374] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:36:40,369] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:36:40,370] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005246673244982958] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:36:40,371] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:36:40,373] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.27, lower limit: 0.21, upper limit: 0.33), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.27, lower limit: 0.21, upper limit: 0.33}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:36:40,373] INFO Max replica load per broker for resource disk in MiB is: [1=0.08548808097839355] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:36:40,373] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:36:40,373] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:36:47,212] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:36:47,212] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:36:47,215] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:36:57,830] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:36:57,868] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 11.60 ms each. The slowest event was writeNoOpRecord(887664865), which took 55.15 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:52:48,967] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 12:52:48,968] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 12:52:48,969] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 12:52:49,384] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 12:52:49,689] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 12:52:49,726] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:52:49,726] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:52:49,729] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:53:02,967] ERROR [ControllerServer id=1] Exceptionally slow controller event writeNoOpRecord(64876684) took 3698 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:53:02,968] ERROR [ControllerServer id=1] Exceptionally slow controller event writeNoOpRecord(1538800700) took 3837 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:53:02,969] ERROR [ControllerServer id=1] Exceptionally slow controller event maybeFenceStaleBroker(1327484630) took 3792 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:53:02,969] ERROR [ControllerServer id=1] Exceptionally slow controller event writeNoOpRecord(1635061623) took 3140 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:53:11,990] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:53:11,994] INFO Generated cluster model in 8 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:53:11,999] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:53:12,001] INFO Max replica load per broker for resource disk in MiB is: [1=0.08548808097839355] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:53:12,002] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005246673244982958] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:53:12,003] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.005292592104524374] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:53:12,003] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:53:12,006] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005246673244982958] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:53:12,008] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:53:12,009] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.27, lower limit: 0.21, upper limit: 0.33), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.27, lower limit: 0.21, upper limit: 0.33}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:53:12,009] INFO Max replica load per broker for resource disk in MiB is: [1=0.08548808097839355] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:53:12,010] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:53:12,010] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:53:21,708] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:53:21,708] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:53:21,799] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:53:30,361] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:53:30,427] INFO [ControllerServer id=1] In the last 60000 ms period, 271 controller events were completed, which took an average of 210.96 ms each. The slowest event was writeNoOpRecord(1538800700), which took 3837.05 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:53:53,930] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:53:53,930] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:53:53,932] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:54:12,772] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:54:12,788] INFO Generated cluster model in 24 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:54:12,799] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:54:12,808] INFO Max replica load per broker for resource disk in MiB is: [1=0.08548808097839355] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:54:12,811] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005246673244982958] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:54:12,813] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.005292592104524374] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:54:12,817] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:54:12,821] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005246673244982958] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:54:12,826] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:54:12,835] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.27, lower limit: 0.21, upper limit: 0.33), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.27, lower limit: 0.21, upper limit: 0.33}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:54:12,836] INFO Max replica load per broker for resource disk in MiB is: [1=0.08548808097839355] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:54:12,837] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:54:12,837] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:54:21,664] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:54:21,664] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:54:21,666] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:54:30,302] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:54:30,364] INFO [ControllerServer id=1] In the last 60000 ms period, 329 controller events were completed, which took an average of 15.08 ms each. The slowest event was writeNoOpRecord(726193127), which took 298.06 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:54:32,470] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753274160000, endMs=1753274340000, endMsInclusive=1753274339999, index=9740413, baseTimestamp=0}(12:36:00 - 12:38:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:54:32,492] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2784 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2827 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:32,540] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:36:00,12:38:59.999], with 102 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=1, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=1, PARTITION_SIZE=66, ALL_TOPIC_FETCH_REQUEST_RATE=1, TOPIC_BYTES_IN=4, TOPIC_FETCH_REQUEST_RATE=4, TOPIC_BYTES_OUT=4, ALL_TOPIC_BYTES_OUT=1, ALL_TOPIC_REPLICATION_BYTES_IN=1, BROKER_CPU_UTIL=1, TOPIC_MESSAGES_IN_PER_SEC=4, ALL_TOPIC_BYTES_IN=1, ALL_TOPIC_REPLICATION_BYTES_OUT=1, BROKER_CONSUME_CAPACITY=1, BROKER_DISK_CAPACITY=1, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=1, ALL_MIRROR_TOPIC_BYTES_IN=1, BROKER_PRODUCE_MIRROR_CAPACITY=1, TOPIC_PRODUCE_REQUEST_RATE=4, ALL_TOPIC_PRODUCE_REQUEST_RATE=1, BROKER_PRODUCE_REQUEST_RATE=1, BROKER_CONSUMER_FETCH_REQUEST_RATE=1},  204 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:54:32,546] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:36:58.606 to 12:36:58.688 (1753274218606 to 1753274218688). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:54:32,547] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:54:32,547] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:54:32,547] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 16->17,current window range [1753272180000, 1753274340000, 12:03:00 to 12:39:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:54:32,547] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 16->17,current window range [1753272180000, 1753274340000, 12:03:00 to 12:39:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:54:32,547] INFO Successfully finished metric sampling for time period 12:36:00 to 12:38:59.999 (1753274160000 to 1753274339999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:54:32,547] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753275060000, endMs=1753275240000, endMsInclusive=1753275239999, index=9740418, baseTimestamp=0}(12:51:00 - 12:53:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2850 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2888 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,014] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:54:33,023] INFO Finished sampling for 12 partitions - processed 204 metrics over 1 polls for the time range [12:51:00,12:53:59.999], with 102 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=1, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=1, PARTITION_SIZE=66, ALL_TOPIC_FETCH_REQUEST_RATE=1, TOPIC_BYTES_IN=4, TOPIC_FETCH_REQUEST_RATE=4, TOPIC_BYTES_OUT=4, ALL_TOPIC_BYTES_OUT=1, BROKER_CPU_UTIL=1, ALL_TOPIC_REPLICATION_BYTES_IN=1, TOPIC_MESSAGES_IN_PER_SEC=4, ALL_TOPIC_BYTES_IN=1, ALL_TOPIC_REPLICATION_BYTES_OUT=1, BROKER_DISK_CAPACITY=1, BROKER_CONSUME_CAPACITY=1, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=1, ALL_MIRROR_TOPIC_BYTES_IN=1, BROKER_PRODUCE_MIRROR_CAPACITY=1, TOPIC_PRODUCE_REQUEST_RATE=4, ALL_TOPIC_PRODUCE_REQUEST_RATE=1, BROKER_PRODUCE_REQUEST_RATE=1, BROKER_CONSUMER_FETCH_REQUEST_RATE=1},  102 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:54:33,023] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:53:31.221 to 12:53:31.881 (1753275211221 to 1753275211881). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:54:33,024] INFO REPLICA Aggregator rolled out 4 new windows, reset 4 windows and bumped generation from 17->18,current window range [1753272900000, 1753275060000, 12:15:00 to 12:51:00],abandon 260 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:54:33,024] INFO PARTITION Aggregator rolled out 4 new windows, reset 4 windows and bumped generation from 17->18,current window range [1753272900000, 1753275060000, 12:15:00 to 12:51:00],abandon 260 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:54:33,024] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:54:33,024] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:54:33,024] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 18->19,current window range [1753273080000, 1753275240000, 12:18:00 to 12:54:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:54:33,024] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 18->19,current window range [1753273080000, 1753275240000, 12:18:00 to 12:54:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:54:33,024] INFO Successfully finished metric sampling for time period 12:51:00 to 12:53:59.999 (1753275060000 to 1753275239999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:54:33,025] INFO Sleeping the SamplingScheduler until 12:56:59.999 (for 146975ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740418, 12:51:00 - 12:53:59.999), currentWindow: (index: 9740419, 12:54:00 - 12:56:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:54:36,535] INFO Saving metric sample completeness to cache for generation 19 and from/to indices 9740407-9740418 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:54:36,538] INFO Saving metric sample completeness to cache for generation 19 and from/to indices 9740407-9740418 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:54:36,539] INFO Saving metric sample completeness to cache for generation 19 and from/to indices 9740407-9740418 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:54:36,543] INFO Saving metric sample completeness to cache for generation 19 and from/to indices 9740407-9740418 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:54:51,706] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:54:51,706] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:54:51,706] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:55:13,604] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:55:13,616] INFO Generated cluster model in 19 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:55:13,622] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:55:13,630] INFO Max replica load per broker for resource disk in MiB is: [1=0.11920928955078125] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:55:13,635] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005095210392028093] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:55:13,636] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.005605269689112902] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:55:13,637] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:55:13,637] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005095210392028093] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:55:13,639] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:55:13,643] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.28, lower limit: 0.22, upper limit: 0.34), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.28, lower limit: 0.22, upper limit: 0.34}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:55:13,643] INFO Max replica load per broker for resource disk in MiB is: [1=0.11920928955078125] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:55:13,643] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:55:13,643] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:55:23,724] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:55:23,724] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:55:23,727] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:55:31,095] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:55:31,178] INFO [ControllerServer id=1] In the last 60000 ms period, 329 controller events were completed, which took an average of 11.56 ms each. The slowest event was writeNoOpRecord(3354616), which took 81.40 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:55:53,016] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:55:53,016] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:55:53,017] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:56:14,271] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:56:14,277] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:56:14,281] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:56:14,286] INFO Max replica load per broker for resource disk in MiB is: [1=0.11920928955078125] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:56:14,287] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005095210392028093] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:56:14,288] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.005605269689112902] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:56:14,289] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:56:14,291] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005095210392028093] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:56:14,292] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:56:14,293] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.28, lower limit: 0.22, upper limit: 0.34), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.28, lower limit: 0.22, upper limit: 0.34}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:56:14,293] INFO Max replica load per broker for resource disk in MiB is: [1=0.11920928955078125] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:56:14,294] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:56:14,294] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:56:25,090] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:56:25,090] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:56:25,091] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:56:31,610] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 84 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 12:56:31,744] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:56:31,836] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 11.18 ms each. The slowest event was writeNoOpRecord(725386708), which took 38.57 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:56:57,965] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:56:57,965] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:56:57,966] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:57:02,311] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753275240000, endMs=1753275420000, endMsInclusive=1753275419999, index=9740419, baseTimestamp=0}(12:54:00 - 12:56:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:57:02,338] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,338] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,338] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,338] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2924 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,338] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,338] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,338] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,340] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,340] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,340] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 2941 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,340] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,340] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 12:57:02,385] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:54:00,12:56:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, BROKER_CPU_UTIL=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 12:57:02,387] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:54:31.072 to 12:56:32.617 (1753275271072 to 1753275392617). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 12:57:02,388] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:57:02,388] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 12:57:02,388] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 19->20,current window range [1753273260000, 1753275420000, 12:21:00 to 12:57:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:57:02,388] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 19->20,current window range [1753273260000, 1753275420000, 12:21:00 to 12:57:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 12:57:02,388] INFO Successfully finished metric sampling for time period 12:54:00 to 12:56:59.999 (1753275240000 to 1753275419999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:57:02,388] INFO Sleeping the SamplingScheduler until 12:59:59.999 (for 177611ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740419, 12:54:00 - 12:56:59.999), currentWindow: (index: 9740420, 12:57:00 - 12:59:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 12:57:02,852] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:57:02,852] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 12:57:02,852] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:57:02,852] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 12:57:08,833] INFO Saving metric sample completeness to cache for generation 20 and from/to indices 9740408-9740419 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:57:08,854] INFO Saving metric sample completeness to cache for generation 20 and from/to indices 9740408-9740419 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:57:08,854] INFO Saving metric sample completeness to cache for generation 20 and from/to indices 9740408-9740419 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:57:08,855] INFO Saving metric sample completeness to cache for generation 20 and from/to indices 9740408-9740419 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 12:57:15,120] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:57:15,123] INFO Generated cluster model in 5 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:57:15,126] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:57:15,128] INFO Max replica load per broker for resource disk in MiB is: [1=0.12655317783355713] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:57:15,128] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.0051050311885774136] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:57:15,129] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006023466121405363] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:57:15,130] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:57:15,131] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.0051050311885774136] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:57:15,131] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:57:15,132] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.30, lower limit: 0.24, upper limit: 0.36), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.30, lower limit: 0.24, upper limit: 0.36}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:57:15,133] INFO Max replica load per broker for resource disk in MiB is: [1=0.12655317783355713] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:57:15,133] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:57:15,133] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:57:24,886] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:57:24,886] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:57:24,888] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:57:32,671] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:57:32,769] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.43 ms each. The slowest event was writeNoOpRecord(581362668), which took 45.90 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:57:55,481] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:57:55,481] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:57:55,485] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:58:16,153] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:58:16,261] INFO Generated cluster model in 127 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:58:16,450] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:58:16,463] INFO Max replica load per broker for resource disk in MiB is: [1=0.12655317783355713] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:58:16,469] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.0051050311885774136] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:58:16,471] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006023466121405363] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:58:16,473] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:58:16,475] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.0051050311885774136] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:58:16,495] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:58:16,510] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.30, lower limit: 0.24, upper limit: 0.36), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.30, lower limit: 0.24, upper limit: 0.36}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:58:16,510] INFO Max replica load per broker for resource disk in MiB is: [1=0.12655317783355713] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:58:16,511] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:58:16,511] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:58:23,931] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:58:23,931] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:58:23,932] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:58:33,189] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:58:33,289] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 10.83 ms each. The slowest event was writeNoOpRecord(100188508), which took 54.43 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:58:56,671] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:58:56,671] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:58:56,672] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:59:16,397] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:59:16,401] INFO Generated cluster model in 5 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 12:59:16,402] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 12:59:16,404] INFO Max replica load per broker for resource disk in MiB is: [1=0.12655317783355713] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:59:16,405] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.0051050311885774136] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:59:16,405] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006023466121405363] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:59:16,405] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:59:16,406] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.0051050311885774136] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:59:16,406] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 12:59:16,407] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.30, lower limit: 0.24, upper limit: 0.36), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.30, lower limit: 0.24, upper limit: 0.36}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 12:59:16,407] INFO Max replica load per broker for resource disk in MiB is: [1=0.12655317783355713] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 12:59:16,407] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:59:16,407] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 12:59:28,711] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:59:28,711] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:59:28,713] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 12:59:33,921] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 12:59:34,031] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 11.12 ms each. The slowest event was writeNoOpRecord(433955311), which took 44.24 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 12:59:58,926] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:59:58,926] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 12:59:58,926] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 13:00:02,123] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753275420000, endMs=1753275600000, endMsInclusive=1753275599999, index=9740420, baseTimestamp=0}(12:57:00 - 12:59:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 13:00:02,195] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3121 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3125 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,196] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:00:02,212] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [12:57:00,12:59:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, BROKER_CPU_UTIL=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 13:00:02,213] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 12:57:33.429 to 12:59:34.752 (1753275453429 to 1753275574752). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 13:00:02,214] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 13:00:02,214] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 13:00:02,214] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 20->21,current window range [1753273440000, 1753275600000, 12:24:00 to 13:00:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 13:00:02,214] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 20->21,current window range [1753273440000, 1753275600000, 12:24:00 to 13:00:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 13:00:02,214] INFO Successfully finished metric sampling for time period 12:57:00 to 12:59:59.999 (1753275420000 to 1753275599999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 13:00:02,214] INFO Sleeping the SamplingScheduler until 13:02:59.999 (for 177785ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740420, 12:57:00 - 12:59:59.999), currentWindow: (index: 9740421, 13:00:00 - 13:02:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 13:00:10,966] INFO Saving metric sample completeness to cache for generation 21 and from/to indices 9740409-9740420 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 13:00:10,969] INFO Saving metric sample completeness to cache for generation 21 and from/to indices 9740409-9740420 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 13:00:10,973] INFO Saving metric sample completeness to cache for generation 21 and from/to indices 9740409-9740420 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 13:00:10,977] INFO Saving metric sample completeness to cache for generation 21 and from/to indices 9740409-9740420 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 13:00:17,238] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 13:00:17,246] INFO Generated cluster model in 11 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 13:00:17,250] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 13:00:17,254] INFO Max replica load per broker for resource disk in MiB is: [1=0.13390886783599854] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:00:17,255] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005102140828967094] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:00:17,256] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006502487231045961] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:00:17,256] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:00:17,257] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005102140828967094] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:00:17,258] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 13:00:17,261] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.32, lower limit: 0.25, upper limit: 0.39), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.32, lower limit: 0.25, upper limit: 0.39}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 13:00:17,261] INFO Max replica load per broker for resource disk in MiB is: [1=0.13390886783599854] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:00:17,261] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 13:00:17,262] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 13:00:31,742] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:00:31,742] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:00:31,745] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 13:00:35,529] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 13:00:35,638] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 10.81 ms each. The slowest event was writeNoOpRecord(151872956), which took 43.63 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 13:01:03,761] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:01:03,761] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:01:03,762] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 13:01:18,040] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 13:01:18,064] INFO Generated cluster model in 33 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 13:01:18,069] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 13:01:18,111] INFO Max replica load per broker for resource disk in MiB is: [1=0.13390886783599854] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:01:18,113] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005102140828967094] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:01:18,114] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006502487231045961] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:01:18,115] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:01:18,116] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005102140828967094] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:01:18,118] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 13:01:18,120] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.32, lower limit: 0.25, upper limit: 0.39), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.32, lower limit: 0.25, upper limit: 0.39}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 13:01:18,120] INFO Max replica load per broker for resource disk in MiB is: [1=0.13390886783599854] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:01:18,120] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 13:01:18,120] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 13:01:36,907] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 146 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 13:01:37,052] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 13:01:37,162] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.63 ms each. The slowest event was writeNoOpRecord(1308310356), which took 39.94 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 13:01:37,307] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:01:37,307] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:01:37,310] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 13:02:06,995] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:02:06,995] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:02:06,995] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 13:02:07,275] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 13:02:07,275] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 13:02:07,275] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 13:02:07,275] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 13:02:19,541] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 13:02:19,546] INFO Generated cluster model in 7 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 13:02:19,551] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 13:02:19,553] INFO Max replica load per broker for resource disk in MiB is: [1=0.13390886783599854] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:02:19,554] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005102140828967094] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:02:19,555] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006502487231045961] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:02:19,555] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:02:19,555] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005102140828967094] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:02:19,556] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 13:02:19,557] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.32, lower limit: 0.25, upper limit: 0.39), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.32, lower limit: 0.25, upper limit: 0.39}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 13:02:19,557] INFO Max replica load per broker for resource disk in MiB is: [1=0.13390886783599854] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:02:19,557] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 13:02:19,557] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 13:02:35,136] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:02:35,136] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:02:35,139] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 13:02:37,939] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 13:02:38,044] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.75 ms each. The slowest event was writeNoOpRecord(712465811), which took 58.09 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 13:34:23,468] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 13:34:23,468] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 13:34:23,469] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 13:34:23,772] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 13:34:29,034] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753275600000, endMs=1753275780000, endMsInclusive=1753275779999, index=9740421, baseTimestamp=0}(13:00:00 - 13:02:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 13:34:29,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3316 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,059] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,059] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,059] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,059] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3311 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,059] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,059] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,077] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [13:00:00,13:02:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 13:34:29,078] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 13:00:36.276 to 13:02:38.805 (1753275636276 to 1753275758805). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 13:34:29,079] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 13:34:29,079] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 13:34:29,080] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 21->22,current window range [1753273620000, 1753275780000, 12:27:00 to 13:03:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 13:34:29,080] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 21->22,current window range [1753273620000, 1753275780000, 12:27:00 to 13:03:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 13:34:29,080] INFO Successfully finished metric sampling for time period 13:00:00 to 13:02:59.999 (1753275600000 to 1753275779999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 13:34:29,080] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753277400000, endMs=1753277580000, endMsInclusive=1753277579999, index=9740431, baseTimestamp=0}(13:30:00 - 13:32:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3502 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3506 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:29,586] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 13:34:33,003] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:34:33,003] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 13:34:33,003] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 13:34:34,592] INFO Finished sampling for 12 partitions - processed 0 metrics over 1 polls for the time range [13:30:00,13:32:59.999], with 0 of them added to the metrics processor, having the following distribution {},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 13:34:34,593] WARN Zero replica samples were added! Collected 0 (0 discarded, 0 added) replica metric samples for 0 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 13:34:34,593] WARN Zero partition samples were added! Collected 0 (0 discarded, 0 added) partition metric samples for 0 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 13:34:34,593] INFO Successfully finished metric sampling for time period 13:30:00 to 13:32:59.999 (1753277400000 to 1753277579999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 13:34:34,593] INFO Sleeping the SamplingScheduler until 13:35:59.999 (for 85406ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740431, 13:30:00 - 13:32:59.999), currentWindow: (index: 9740432, 13:33:00 - 13:35:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 13:34:39,993] INFO Saving metric sample completeness to cache for generation 22 and from/to indices 9740410-9740421 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 13:34:39,996] INFO Saving metric sample completeness to cache for generation 22 and from/to indices 9740410-9740421 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 13:34:39,997] INFO Saving metric sample completeness to cache for generation 22 and from/to indices 9740410-9740421 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 13:34:40,000] INFO Saving metric sample completeness to cache for generation 22 and from/to indices 9740410-9740421 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 13:34:46,629] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 13:34:46,681] INFO Generated cluster model in 62 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 13:34:46,769] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 13:34:46,847] INFO Max replica load per broker for resource disk in MiB is: [1=0.14143657684326172] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:34:46,953] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005101862829178572] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:34:46,955] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.0068427384831011295] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:34:46,970] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:34:47,020] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005101862829178572] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:34:47,055] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 13:34:47,073] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.34, lower limit: 0.27, upper limit: 0.41), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.34, lower limit: 0.27, upper limit: 0.41}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 13:34:47,074] INFO Max replica load per broker for resource disk in MiB is: [1=0.14143657684326172] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 13:34:47,074] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 13:34:47,074] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 14:38:02,259] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 14:38:02,260] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 14:38:02,261] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 14:38:02,479] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 14:38:08,148] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 14:38:08,148] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 14:38:08,157] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 14:38:12,574] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 14:38:12,680] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 14.16 ms each. The slowest event was writeNoOpRecord(2030229028), which took 250.50 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 14:38:40,189] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 14:38:40,189] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 14:38:40,190] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 14:38:55,097] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 14:38:55,105] INFO Generated cluster model in 13 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 14:38:55,109] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 14:38:55,114] INFO Max replica load per broker for resource disk in MiB is: [1=0.14143657684326172] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 14:38:55,116] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005101862829178572] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 14:38:55,117] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.0068427384831011295] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 14:38:55,117] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 14:38:55,118] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005101862829178572] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 14:38:55,118] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 14:38:55,120] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.34, lower limit: 0.27, upper limit: 0.41), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.34, lower limit: 0.27, upper limit: 0.41}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 14:38:55,120] INFO Max replica load per broker for resource disk in MiB is: [1=0.14143657684326172] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 14:38:55,120] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 14:38:55,121] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 15:28:58,303] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 15:28:58,304] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 15:28:58,304] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 15:28:58,511] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 15:29:04,788] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753277580000, endMs=1753277760000, endMsInclusive=1753277759999, index=9740432, baseTimestamp=0}(13:33:00 - 13:35:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3502 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3506 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,821] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:04,861] INFO Finished sampling for 12 partitions - processed 102 metrics over 1 polls for the time range [13:33:00,13:35:59.999], with 0 of them added to the metrics processor, having the following distribution {},  102 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 15:29:04,861] WARN Zero replica samples were added! Collected 0 (0 discarded, 0 added) replica metric samples for 0 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 15:29:04,861] WARN Zero partition samples were added! Collected 0 (0 discarded, 0 added) partition metric samples for 0 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 15:29:04,862] INFO Successfully finished metric sampling for time period 13:33:00 to 13:35:59.999 (1753277580000 to 1753277759999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:29:04,862] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753284240000, endMs=1753284420000, endMsInclusive=1753284419999, index=9740469, baseTimestamp=0}(15:24:00 - 15:26:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:29:05,334] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,334] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,334] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,334] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3552 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,335] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,335] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,335] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,335] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,335] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,335] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3583 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,335] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:05,335] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:29:08,215] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 15:29:08,215] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 15:29:08,217] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 15:29:08,580] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 15:29:08,683] INFO [ControllerServer id=1] In the last 60000 ms period, 334 controller events were completed, which took an average of 10.94 ms each. The slowest event was writeNoOpRecord(367185594), which took 129.66 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 15:29:09,435] INFO Finished sampling for 12 partitions - processed 87 metrics over 1 polls for the time range [15:24:00,15:26:59.999], with 0 of them added to the metrics processor, having the following distribution {},  87 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 15:29:09,435] WARN Zero replica samples were added! Collected 0 (0 discarded, 0 added) replica metric samples for 0 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 15:29:09,435] WARN Zero partition samples were added! Collected 0 (0 discarded, 0 added) partition metric samples for 0 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 15:29:09,435] INFO Successfully finished metric sampling for time period 15:24:00 to 15:26:59.999 (1753284240000 to 1753284419999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:29:09,435] INFO Sleeping the SamplingScheduler until 15:29:59.999 (for 50564ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740469, 15:24:00 - 15:26:59.999), currentWindow: (index: 9740470, 15:27:00 - 15:29:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:29:33,859] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 15:29:33,859] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 15:29:33,861] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 15:29:51,096] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 15:29:51,099] INFO Generated cluster model in 48 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 15:29:51,102] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 15:29:51,109] INFO Max replica load per broker for resource disk in MiB is: [1=0.14143657684326172] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 15:29:51,110] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005101862829178572] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 15:29:51,110] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.0068427384831011295] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 15:29:51,111] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 15:29:51,111] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005101862829178572] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 15:29:51,112] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 15:29:51,113] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.34, lower limit: 0.27, upper limit: 0.41), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.34, lower limit: 0.27, upper limit: 0.41}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 15:29:51,113] INFO Max replica load per broker for resource disk in MiB is: [1=0.14143657684326172] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 15:29:51,113] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 15:29:51,113] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 15:39:12,200] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 15:39:12,200] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 15:39:12,201] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 15:39:12,405] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 15:39:13,861] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753284420000, endMs=1753284600000, endMsInclusive=1753284599999, index=9740470, baseTimestamp=0}(15:27:00 - 15:29:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:39:13,905] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,905] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,905] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,905] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3552 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,905] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,905] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,905] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,905] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,905] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,906] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3583 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,906] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,906] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:13,918] INFO Finished sampling for 12 partitions - processed 102 metrics over 1 polls for the time range [15:27:00,15:29:59.999], with 102 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=1, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=1, PARTITION_SIZE=66, TOPIC_BYTES_IN=4, TOPIC_FETCH_REQUEST_RATE=4, TOPIC_BYTES_OUT=4, ALL_TOPIC_FETCH_REQUEST_RATE=1, ALL_TOPIC_BYTES_OUT=1, ALL_TOPIC_REPLICATION_BYTES_IN=1, BROKER_CPU_UTIL=1, TOPIC_MESSAGES_IN_PER_SEC=4, ALL_TOPIC_REPLICATION_BYTES_OUT=1, BROKER_DISK_CAPACITY=1, BROKER_CONSUME_CAPACITY=1, ALL_TOPIC_BYTES_IN=1, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=1, ALL_MIRROR_TOPIC_BYTES_IN=1, BROKER_PRODUCE_MIRROR_CAPACITY=1, TOPIC_PRODUCE_REQUEST_RATE=4, BROKER_PRODUCE_REQUEST_RATE=1, ALL_TOPIC_PRODUCE_REQUEST_RATE=1, BROKER_CONSUMER_FETCH_REQUEST_RATE=1},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 15:39:13,920] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 15:29:09.313 to 15:29:09.434 (1753284549313 to 1753284549434). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 15:39:13,920] INFO REPLICA Aggregator rolled out 48 new windows, reset 13 windows and bumped generation from 22->23,current window range [1753282260000, 1753284420000, 14:51:00 to 15:27:00],abandon 520 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 15:39:13,921] INFO PARTITION Aggregator rolled out 48 new windows, reset 13 windows and bumped generation from 22->23,current window range [1753282260000, 1753284420000, 14:51:00 to 15:27:00],abandon 520 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 15:39:13,923] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 15:39:13,923] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 15:39:13,923] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 23->24,current window range [1753282440000, 1753284600000, 14:54:00 to 15:30:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 15:39:13,923] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 23->24,current window range [1753282440000, 1753284600000, 14:54:00 to 15:30:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 15:39:13,923] INFO Successfully finished metric sampling for time period 15:27:00 to 15:29:59.999 (1753284420000 to 1753284599999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:39:13,923] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753284960000, endMs=1753285140000, endMsInclusive=1753285139999, index=9740473, baseTimestamp=0}(15:36:00 - 15:38:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:39:14,044] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 15:39:14,044] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 15:39:14,045] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 15:39:14,047] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 15:39:14,047] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 15:39:14,424] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3615 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3647 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:14,425] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 15:39:19,429] INFO Finished sampling for 12 partitions - processed 0 metrics over 1 polls for the time range [15:36:00,15:38:59.999], with 0 of them added to the metrics processor, having the following distribution {},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 15:39:19,429] WARN Zero replica samples were added! Collected 0 (0 discarded, 0 added) replica metric samples for 0 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 15:39:19,429] WARN Zero partition samples were added! Collected 0 (0 discarded, 0 added) partition metric samples for 0 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 15:39:19,429] INFO Successfully finished metric sampling for time period 15:36:00 to 15:38:59.999 (1753284960000 to 1753285139999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:39:19,429] INFO Sleeping the SamplingScheduler until 15:41:59.999 (for 160570ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740473, 15:36:00 - 15:38:59.999), currentWindow: (index: 9740474, 15:39:00 - 15:41:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 15:39:22,441] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 15:39:22,552] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 11.08 ms each. The slowest event was writeNoOpRecord(342572695), which took 61.90 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 15:39:28,632] INFO Saving metric sample completeness to cache for generation 24 and from/to indices 9740459-9740470 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 15:39:28,635] INFO Saving metric sample completeness to cache for generation 24 and from/to indices 9740459-9740470 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 15:39:28,637] INFO Saving metric sample completeness to cache for generation 24 and from/to indices 9740459-9740470 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 15:39:28,643] INFO Saving metric sample completeness to cache for generation 24 and from/to indices 9740459-9740470 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 15:39:39,805] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 15:39:39,805] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 15:39:39,806] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 16:12:08,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 16:12:08,493] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 16:12:08,494] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 16:12:08,696] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 16:12:31,181] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 16:12:31,189] INFO Generated cluster model in 13 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 16:12:31,194] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 16:12:31,197] INFO Max replica load per broker for resource disk in MiB is: [1=0.1739206314086914] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:12:31,198] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005123159848153591] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:12:31,199] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.013843502849340439] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:12:31,200] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:12:31,201] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005123159848153591] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:12:31,202] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 16:12:31,203] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.35, lower limit: 0.28, upper limit: 0.42), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.35, lower limit: 0.28, upper limit: 0.42}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 16:12:31,204] INFO Max replica load per broker for resource disk in MiB is: [1=0.1739206314086914] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:12:31,204] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 16:12:31,204] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 16:40:09,039] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 16:40:09,039] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 16:40:09,044] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 16:40:09,100] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 16:40:09,100] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 16:40:09,101] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 16:40:09,353] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 16:40:09,362] INFO [AdminClient clientId=cluster-link--local-admin-1] Metadata update failed (org.apache.kafka.clients.admin.internals.AdminMetadataManager)
org.apache.kafka.common.errors.TimeoutException: Timed out waiting to send the call. Call: fetchMetadata
[2025-07-23 16:40:18,785] INFO [ControllerServer id=1] Periodic task expireDelegationTokens generated 0 records in 1447 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 16:40:18,828] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 153 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 16:40:18,993] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 16:40:19,020] INFO [SnapshotGenerator id=1] Creating new KRaft snapshot file snapshot 00000000000000007238-0000000001 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2025-07-23 16:40:19,143] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 15.86 ms each. The slowest event was writeNoOpRecord(1758630785), which took 310.95 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 16:40:19,663] INFO [SnapshotEmitter id=1] Successfully wrote snapshot 00000000000000007238-0000000001 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2025-07-23 16:40:20,248] INFO [ProducerStateManager partition=_confluent-telemetry-metrics-6] Wrote producer snapshot at offset 3688 with 0 producer ids in 24 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-07-23 16:40:20,259] INFO [MergedLog partition=_confluent-telemetry-metrics-6, dir=/var/lib/kafka/data] Rolled new log segment at offset 3688 in 83 ms. (kafka.log.MergedLog)
[2025-07-23 16:40:20,259] INFO [MergedLog partition=_confluent-telemetry-metrics-6, dir=/var/lib/kafka/data] Rolled new log segment at offset 3688 in 83 ms. (kafka.log.MergedLog)
[2025-07-23 16:40:20,281] INFO [ProducerStateManager partition=_confluent-telemetry-metrics-0] Wrote producer snapshot at offset 3701 with 0 producer ids in 0 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-07-23 16:40:20,281] INFO [MergedLog partition=_confluent-telemetry-metrics-0, dir=/var/lib/kafka/data] Rolled new log segment at offset 3701 in 5 ms. (kafka.log.MergedLog)
[2025-07-23 16:40:20,281] INFO [MergedLog partition=_confluent-telemetry-metrics-0, dir=/var/lib/kafka/data] Rolled new log segment at offset 3701 in 5 ms. (kafka.log.MergedLog)
[2025-07-23 16:56:37,970] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 16:56:37,971] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 16:56:37,971] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 16:56:38,181] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 16:56:39,804] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 16:56:39,804] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 16:56:39,805] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 16:56:48,090] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 16:56:48,090] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 16:56:48,091] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 16:56:48,091] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 16:57:00,356] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 16:57:00,367] INFO Generated cluster model in 14 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 16:57:00,373] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 16:57:00,378] INFO Max replica load per broker for resource disk in MiB is: [1=0.1739206314086914] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:57:00,380] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005123159848153591] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:57:00,381] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.013843502849340439] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:57:00,382] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:57:00,383] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005123159848153591] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:57:00,384] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 16:57:00,385] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.35, lower limit: 0.28, upper limit: 0.42), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.35, lower limit: 0.28, upper limit: 0.42}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 16:57:00,386] INFO Max replica load per broker for resource disk in MiB is: [1=0.1739206314086914] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 16:57:00,386] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 16:57:00,386] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 17:13:47,631] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 17:13:47,631] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 17:13:47,632] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 17:13:47,837] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 17:13:51,527] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 17:13:51,527] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 17:13:51,527] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 17:13:57,609] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 17:13:57,757] INFO [ControllerServer id=1] In the last 60000 ms period, 328 controller events were completed, which took an average of 13.07 ms each. The slowest event was writeNoOpRecord(84793464), which took 232.52 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 17:14:03,863] INFO Broker change event(s) detected: [] (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 17:14:03,866] INFO Alive brokers: [1], failed brokers: [] (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 17:14:03,866] INFO Updated list of failed broker: {} (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 17:41:12,952] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 17:41:12,952] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 17:41:12,952] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 17:41:13,156] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 17:41:18,906] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 17:41:18,906] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 17:41:18,908] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 17:41:30,499] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753285140000, endMs=1753285320000, endMsInclusive=1753285319999, index=9740474, baseTimestamp=0}(15:39:00 - 15:41:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 17:41:30,533] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,533] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,533] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,533] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3615 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,533] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,533] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,533] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,534] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,534] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,534] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3647 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,534] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,534] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:30,624] INFO Finished sampling for 12 partitions - processed 306 metrics over 2 polls for the time range [15:39:00,15:41:59.999], with 102 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=1, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=1, PARTITION_SIZE=66, ALL_TOPIC_FETCH_REQUEST_RATE=1, TOPIC_BYTES_IN=4, TOPIC_FETCH_REQUEST_RATE=4, TOPIC_BYTES_OUT=4, ALL_TOPIC_BYTES_OUT=1, BROKER_CPU_UTIL=1, ALL_TOPIC_REPLICATION_BYTES_IN=1, TOPIC_MESSAGES_IN_PER_SEC=4, ALL_TOPIC_BYTES_IN=1, ALL_TOPIC_REPLICATION_BYTES_OUT=1, BROKER_CONSUME_CAPACITY=1, BROKER_DISK_CAPACITY=1, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=1, ALL_MIRROR_TOPIC_BYTES_IN=1, BROKER_PRODUCE_MIRROR_CAPACITY=1, TOPIC_PRODUCE_REQUEST_RATE=4, ALL_TOPIC_PRODUCE_REQUEST_RATE=1, BROKER_PRODUCE_REQUEST_RATE=1, BROKER_CONSUMER_FETCH_REQUEST_RATE=1},  204 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 17:41:30,627] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 15:39:23.166 to 15:39:23.26 (1753285163166 to 1753285163260). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 17:41:30,627] INFO REPLICA Aggregator rolled out 3 new windows, reset 3 windows and bumped generation from 24->25,current window range [1753282980000, 1753285140000, 15:03:00 to 15:39:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 17:41:30,628] INFO PARTITION Aggregator rolled out 3 new windows, reset 3 windows and bumped generation from 24->25,current window range [1753282980000, 1753285140000, 15:03:00 to 15:39:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 17:41:30,628] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 17:41:30,628] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 17:41:30,629] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 25->26,current window range [1753283160000, 1753285320000, 15:06:00 to 15:42:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 17:41:30,629] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 25->26,current window range [1753283160000, 1753285320000, 15:06:00 to 15:42:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 17:41:30,629] INFO Successfully finished metric sampling for time period 15:39:00 to 15:41:59.999 (1753285140000 to 1753285319999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 17:41:30,629] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753292160000, endMs=1753292340000, endMsInclusive=1753292339999, index=9740513, baseTimestamp=0}(17:36:00 - 17:38:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 17:41:31,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3813 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,085] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3830 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,085] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:31,085] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 17:41:35,416] INFO Saving metric sample completeness to cache for generation 26 and from/to indices 9740463-9740474 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 17:41:35,419] INFO Saving metric sample completeness to cache for generation 26 and from/to indices 9740463-9740474 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 17:41:35,420] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 17:41:35,424] INFO Generated cluster model in 12 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 17:41:35,426] INFO Saving metric sample completeness to cache for generation 26 and from/to indices 9740463-9740474 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 17:41:35,427] INFO Saving metric sample completeness to cache for generation 26 and from/to indices 9740463-9740474 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 17:41:35,428] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 17:41:35,431] INFO Max replica load per broker for resource disk in MiB is: [1=0.17532920837402344] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 17:41:35,432] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005113370716571808] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 17:41:35,433] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.01478083711117506] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 17:41:35,433] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 17:41:35,434] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005113370716571808] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 17:41:35,435] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 17:41:35,436] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.36, lower limit: 0.28, upper limit: 0.43), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.36, lower limit: 0.28, upper limit: 0.43}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 17:41:35,436] INFO Max replica load per broker for resource disk in MiB is: [1=0.17532920837402344] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 17:41:35,436] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 17:41:35,436] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 17:41:36,102] INFO Finished sampling for 12 partitions - processed 0 metrics over 1 polls for the time range [17:36:00,17:38:59.999], with 0 of them added to the metrics processor, having the following distribution {},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 17:41:36,102] WARN Zero replica samples were added! Collected 0 (0 discarded, 0 added) replica metric samples for 0 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 17:41:36,102] WARN Zero partition samples were added! Collected 0 (0 discarded, 0 added) partition metric samples for 0 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 17:41:36,102] INFO Successfully finished metric sampling for time period 17:36:00 to 17:38:59.999 (1753292160000 to 1753292339999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 17:41:36,102] INFO Sleeping the SamplingScheduler until 17:41:59.999 (for 23897ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740513, 17:36:00 - 17:38:59.999), currentWindow: (index: 9740514, 17:39:00 - 17:41:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:05:33,519] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 18:05:33,520] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Requesting disconnect from last known coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 18:05:33,520] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
[2025-07-23 18:05:33,730] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Discovered group coordinator kafka:9092 (id: 2147483646 rack: null isFenced: false) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
[2025-07-23 18:05:41,413] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:05:41,413] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:05:41,414] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:05:43,441] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:05:43,585] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 12.21 ms each. The slowest event was writeNoOpRecord(816511283), which took 120.88 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:05:50,475] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753292340000, endMs=1753292520000, endMsInclusive=1753292519999, index=9740514, baseTimestamp=0}(17:39:00 - 17:41:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3813 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3830 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,513] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:50,570] INFO Finished sampling for 12 partitions - processed 102 metrics over 1 polls for the time range [17:39:00,17:41:59.999], with 0 of them added to the metrics processor, having the following distribution {},  102 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:05:50,570] WARN Zero replica samples were added! Collected 0 (0 discarded, 0 added) replica metric samples for 0 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:05:50,570] WARN Zero partition samples were added! Collected 0 (0 discarded, 0 added) partition metric samples for 0 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:05:50,570] INFO Successfully finished metric sampling for time period 17:39:00 to 17:41:59.999 (1753292340000 to 1753292519999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:05:50,571] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753293600000, endMs=1753293780000, endMsInclusive=1753293779999, index=9740521, baseTimestamp=0}(18:00:00 - 18:02:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3813 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3830 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,084] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:05:51,090] INFO Finished sampling for 12 partitions - processed 102 metrics over 1 polls for the time range [18:00:00,18:02:59.999], with 0 of them added to the metrics processor, having the following distribution {},  102 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:05:51,090] WARN Zero replica samples were added! Collected 0 (0 discarded, 0 added) replica metric samples for 0 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:05:51,091] WARN Zero partition samples were added! Collected 0 (0 discarded, 0 added) partition metric samples for 0 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:05:51,091] INFO Successfully finished metric sampling for time period 18:00:00 to 18:02:59.999 (1753293600000 to 1753293779999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:05:51,091] INFO Sleeping the SamplingScheduler until 18:05:59.999 (for 8908ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740521, 18:00:00 - 18:02:59.999), currentWindow: (index: 9740522, 18:03:00 - 18:05:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:06:00,000] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753293780000, endMs=1753293960000, endMsInclusive=1753293959999, index=9740522, baseTimestamp=0}(18:03:00 - 18:05:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3813 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3830 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:06:00,041] INFO Finished sampling for 12 partitions - processed 102 metrics over 1 polls for the time range [18:03:00,18:05:59.999], with 102 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=1, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=1, PARTITION_SIZE=66, ALL_TOPIC_FETCH_REQUEST_RATE=1, TOPIC_BYTES_IN=4, TOPIC_FETCH_REQUEST_RATE=4, TOPIC_BYTES_OUT=4, ALL_TOPIC_BYTES_OUT=1, BROKER_CPU_UTIL=1, ALL_TOPIC_REPLICATION_BYTES_IN=1, TOPIC_MESSAGES_IN_PER_SEC=4, ALL_TOPIC_BYTES_IN=1, BROKER_CONSUME_CAPACITY=1, ALL_TOPIC_REPLICATION_BYTES_OUT=1, BROKER_DISK_CAPACITY=1, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=1, ALL_MIRROR_TOPIC_BYTES_IN=1, BROKER_PRODUCE_MIRROR_CAPACITY=1, TOPIC_PRODUCE_REQUEST_RATE=4, BROKER_PRODUCE_REQUEST_RATE=1, ALL_TOPIC_PRODUCE_REQUEST_RATE=1, BROKER_CONSUMER_FETCH_REQUEST_RATE=1},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:06:00,042] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:05:44.139 to 18:05:44.347 (1753293944139 to 1753293944347). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:06:00,043] INFO REPLICA Aggregator rolled out 47 new windows, reset 13 windows and bumped generation from 26->27,current window range [1753291620000, 1753293780000, 17:27:00 to 18:03:00],abandon 130 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:06:00,043] INFO PARTITION Aggregator rolled out 47 new windows, reset 13 windows and bumped generation from 26->27,current window range [1753291620000, 1753293780000, 17:27:00 to 18:03:00],abandon 130 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:06:00,043] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:06:00,043] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:06:00,043] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 27->28,current window range [1753291800000, 1753293960000, 17:30:00 to 18:06:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:06:00,043] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 27->28,current window range [1753291800000, 1753293960000, 17:30:00 to 18:06:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:06:00,044] INFO Successfully finished metric sampling for time period 18:03:00 to 18:05:59.999 (1753293780000 to 1753293959999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:06:00,044] INFO Sleeping the SamplingScheduler until 18:08:59.999 (for 179955ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740522, 18:03:00 - 18:05:59.999), currentWindow: (index: 9740523, 18:06:00 - 18:08:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:06:13,436] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:06:13,436] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:06:13,438] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:06:19,596] INFO Saving metric sample completeness to cache for generation 28 and from/to indices 9740511-9740522 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:06:19,598] INFO Saving metric sample completeness to cache for generation 28 and from/to indices 9740511-9740522 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:06:19,599] INFO Saving metric sample completeness to cache for generation 28 and from/to indices 9740511-9740522 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:06:19,601] INFO Saving metric sample completeness to cache for generation 28 and from/to indices 9740511-9740522 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:06:25,870] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:06:25,892] INFO Generated cluster model in 25 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:06:25,898] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:06:25,901] INFO Max replica load per broker for resource disk in MiB is: [1=0.18582630157470703] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:06:25,903] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005098532419651747] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:06:25,903] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.018173975870013237] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:06:25,904] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:06:25,905] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005098532419651747] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:06:25,906] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:06:25,907] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.37, lower limit: 0.29, upper limit: 0.45), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.37, lower limit: 0.29, upper limit: 0.45}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:06:25,907] INFO Max replica load per broker for resource disk in MiB is: [1=0.18582630157470703] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:06:25,908] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:06:25,908] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:06:39,844] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:06:39,844] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:06:39,844] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:06:43,448] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:06:43,586] INFO [ControllerServer id=1] In the last 60000 ms period, 339 controller events were completed, which took an average of 11.14 ms each. The slowest event was writeNoOpRecord(651107351), which took 58.84 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:07:11,887] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:07:11,887] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:07:11,888] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:07:25,878] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:07:25,881] INFO Generated cluster model in 4 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:07:25,882] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:07:25,884] INFO Max replica load per broker for resource disk in MiB is: [1=0.18582630157470703] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:07:25,884] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005098532419651747] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:07:25,885] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.018173975870013237] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:07:25,885] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:07:25,885] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005098532419651747] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:07:25,886] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:07:25,886] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.37, lower limit: 0.29, upper limit: 0.45), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.37, lower limit: 0.29, upper limit: 0.45}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:07:25,887] INFO Max replica load per broker for resource disk in MiB is: [1=0.18582630157470703] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:07:25,887] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:07:25,887] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:07:41,157] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:07:41,157] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:07:41,158] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:07:43,450] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:07:43,588] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 10.84 ms each. The slowest event was writeNoOpRecord(453937024), which took 58.46 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:08:13,219] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:08:13,219] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:08:13,221] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:08:25,914] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:08:25,925] INFO Generated cluster model in 12 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:08:25,937] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:08:25,940] INFO Max replica load per broker for resource disk in MiB is: [1=0.18582630157470703] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:08:25,941] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005098532419651747] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:08:25,942] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.018173975870013237] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:08:25,943] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:08:25,944] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005098532419651747] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:08:25,946] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:08:25,948] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.37, lower limit: 0.29, upper limit: 0.45), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.37, lower limit: 0.29, upper limit: 0.45}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:08:25,949] INFO Max replica load per broker for resource disk in MiB is: [1=0.18582630157470703] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:08:25,949] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:08:25,950] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:08:43,268] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 209 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 18:08:43,453] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:08:43,592] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.17 ms each. The slowest event was writeNoOpRecord(657827050), which took 47.09 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:08:45,243] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:08:45,243] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:08:45,245] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:09:00,015] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753293960000, endMs=1753294140000, endMsInclusive=1753294139999, index=9740523, baseTimestamp=0}(18:06:00 - 18:08:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3878 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 3892 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,037] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:09:00,057] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:06:00,18:08:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, TOPIC_BYTES_IN=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_BYTES_IN=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:09:00,058] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:06:44.132 to 18:08:44.249 (1753294004132 to 1753294124249). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:09:00,059] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:09:00,059] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:09:00,059] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 28->29,current window range [1753291980000, 1753294140000, 17:33:00 to 18:09:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:09:00,059] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 28->29,current window range [1753291980000, 1753294140000, 17:33:00 to 18:09:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:09:00,059] INFO Successfully finished metric sampling for time period 18:06:00 to 18:08:59.999 (1753293960000 to 1753294139999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:09:00,059] INFO Sleeping the SamplingScheduler until 18:11:59.999 (for 179940ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740523, 18:06:00 - 18:08:59.999), currentWindow: (index: 9740524, 18:09:00 - 18:11:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:09:13,605] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:09:13,605] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:09:13,605] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:09:13,605] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:09:17,251] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:09:17,251] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:09:17,252] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:09:19,591] INFO Saving metric sample completeness to cache for generation 29 and from/to indices 9740512-9740523 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:09:19,593] INFO Saving metric sample completeness to cache for generation 29 and from/to indices 9740512-9740523 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:09:19,594] INFO Saving metric sample completeness to cache for generation 29 and from/to indices 9740512-9740523 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:09:19,597] INFO Saving metric sample completeness to cache for generation 29 and from/to indices 9740512-9740523 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:09:25,883] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:09:25,888] INFO Generated cluster model in 7 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:09:25,892] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:09:25,894] INFO Max replica load per broker for resource disk in MiB is: [1=0.18988561630249023] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:09:25,897] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005048580002039671] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:09:25,898] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.013463123701512814] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:09:25,899] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:09:25,899] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005048580002039671] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:09:25,900] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:09:25,901] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.39, lower limit: 0.31, upper limit: 0.47), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.39, lower limit: 0.31, upper limit: 0.47}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:09:25,901] INFO Max replica load per broker for resource disk in MiB is: [1=0.18988561630249023] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:09:25,901] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:09:25,901] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:09:43,452] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:09:43,593] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.38 ms each. The slowest event was writeNoOpRecord(334684483), which took 42.52 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:09:49,270] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:09:49,270] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:09:49,271] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:10:18,632] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:10:18,632] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:10:18,634] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:10:25,887] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:10:25,892] INFO Generated cluster model in 7 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:10:25,895] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:10:25,899] INFO Max replica load per broker for resource disk in MiB is: [1=0.18988561630249023] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:10:25,900] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005048580002039671] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:10:25,901] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.013463123701512814] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:10:25,901] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:10:25,901] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005048580002039671] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:10:25,902] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:10:25,903] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.39, lower limit: 0.31, upper limit: 0.47), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.39, lower limit: 0.31, upper limit: 0.47}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:10:25,903] INFO Max replica load per broker for resource disk in MiB is: [1=0.18988561630249023] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:10:25,904] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:10:25,904] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:10:43,457] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:10:43,597] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 11.14 ms each. The slowest event was writeNoOpRecord(1874788221), which took 92.33 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:10:49,286] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:10:49,286] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:10:49,289] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:11:21,306] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:11:21,306] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:11:21,308] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:11:25,874] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:11:25,878] INFO Generated cluster model in 6 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:11:25,883] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:11:25,888] INFO Max replica load per broker for resource disk in MiB is: [1=0.18988561630249023] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:11:25,890] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005048580002039671] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:11:25,891] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.013463123701512814] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:11:25,893] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:11:25,893] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005048580002039671] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:11:25,894] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:11:25,896] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.39, lower limit: 0.31, upper limit: 0.47), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.39, lower limit: 0.31, upper limit: 0.47}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:11:25,896] INFO Max replica load per broker for resource disk in MiB is: [1=0.18988561630249023] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:11:25,897] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:11:25,897] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:11:43,457] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:11:43,599] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.96 ms each. The slowest event was writeNoOpRecord(1687401984), which took 47.70 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:11:53,336] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:11:53,336] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:11:53,338] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:12:00,000] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753294140000, endMs=1753294320000, endMsInclusive=1753294319999, index=9740524, baseTimestamp=0}(18:09:00 - 18:11:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:12:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4066 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4085 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:12:00,046] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:09:00,18:11:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:12:00,047] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:09:44.132 to 18:11:44.211 (1753294184132 to 1753294304211). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:12:00,047] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:12:00,047] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:12:00,048] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 29->30,current window range [1753292160000, 1753294320000, 17:36:00 to 18:12:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:12:00,048] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 29->30,current window range [1753292160000, 1753294320000, 17:36:00 to 18:12:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:12:00,048] INFO Successfully finished metric sampling for time period 18:09:00 to 18:11:59.999 (1753294140000 to 1753294319999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:12:00,048] INFO Sleeping the SamplingScheduler until 18:14:59.999 (for 179951ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740524, 18:09:00 - 18:11:59.999), currentWindow: (index: 9740525, 18:12:00 - 18:14:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:12:19,623] INFO Saving metric sample completeness to cache for generation 30 and from/to indices 9740513-9740524 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:12:19,635] INFO Saving metric sample completeness to cache for generation 30 and from/to indices 9740513-9740524 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:12:19,639] INFO Saving metric sample completeness to cache for generation 30 and from/to indices 9740513-9740524 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:12:19,640] INFO Saving metric sample completeness to cache for generation 30 and from/to indices 9740513-9740524 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:12:25,363] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:12:25,363] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:12:25,365] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:12:25,871] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:12:25,879] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:12:25,897] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:12:25,902] INFO Max replica load per broker for resource disk in MiB is: [1=0.19357013702392578] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:12:25,903] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004830982070416212] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:12:25,904] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.011036314070224762] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:12:25,904] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:12:25,905] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004830982070416212] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:12:25,906] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:12:25,907] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.41, lower limit: 0.32, upper limit: 0.49), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.41, lower limit: 0.32, upper limit: 0.49}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:12:25,907] INFO Max replica load per broker for resource disk in MiB is: [1=0.19357013702392578] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:12:25,907] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:12:25,907] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:12:43,459] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:12:43,599] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 10.76 ms each. The slowest event was writeNoOpRecord(1985411098), which took 44.58 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:12:52,821] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:12:52,821] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:12:52,821] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:13:24,861] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:13:24,861] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:13:24,864] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:13:25,888] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:13:25,894] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:13:25,899] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:13:25,902] INFO Max replica load per broker for resource disk in MiB is: [1=0.19357013702392578] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:13:25,903] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004830982070416212] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:13:25,904] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.011036314070224762] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:13:25,904] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:13:25,907] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004830982070416212] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:13:25,908] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:13:25,912] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.41, lower limit: 0.32, upper limit: 0.49), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.41, lower limit: 0.32, upper limit: 0.49}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:13:25,912] INFO Max replica load per broker for resource disk in MiB is: [1=0.19357013702392578] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:13:25,912] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:13:25,913] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:13:43,270] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 215 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 18:13:43,462] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:13:43,603] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 10.77 ms each. The slowest event was writeNoOpRecord(714688209), which took 42.28 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:13:56,877] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:13:56,877] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:13:56,878] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:14:13,615] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:14:13,615] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:14:13,617] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:14:13,617] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:14:25,891] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:14:25,895] INFO Generated cluster model in 6 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:14:25,990] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:14:26,001] INFO Max replica load per broker for resource disk in MiB is: [1=0.19357013702392578] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:14:26,007] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004830982070416212] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:14:26,009] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.011036314070224762] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:14:26,012] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:14:26,014] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004830982070416212] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:14:26,017] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:14:26,024] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.41, lower limit: 0.32, upper limit: 0.49), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.41, lower limit: 0.32, upper limit: 0.49}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:14:26,025] INFO Max replica load per broker for resource disk in MiB is: [1=0.19357013702392578] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:14:26,026] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:14:26,027] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:14:28,897] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:14:28,897] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:14:28,898] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:14:43,465] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:14:43,609] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.71 ms each. The slowest event was writeNoOpRecord(967074625), which took 39.55 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:14:58,947] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:14:58,947] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:14:58,948] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:15:00,017] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753294320000, endMs=1753294500000, endMsInclusive=1753294499999, index=9740525, baseTimestamp=0}(18:12:00 - 18:14:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4248 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4284 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,058] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:15:00,087] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:12:00,18:14:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_OUT=12, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:15:00,088] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:12:44.133 to 18:14:44.213 (1753294364133 to 1753294484213). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:15:00,089] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:15:00,089] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:15:00,089] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 30->31,current window range [1753292340000, 1753294500000, 17:39:00 to 18:15:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:15:00,089] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 30->31,current window range [1753292340000, 1753294500000, 17:39:00 to 18:15:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:15:00,089] INFO Successfully finished metric sampling for time period 18:12:00 to 18:14:59.999 (1753294320000 to 1753294499999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:15:00,089] INFO Sleeping the SamplingScheduler until 18:17:59.999 (for 179910ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740525, 18:12:00 - 18:14:59.999), currentWindow: (index: 9740526, 18:15:00 - 18:17:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:15:19,589] INFO Saving metric sample completeness to cache for generation 31 and from/to indices 9740514-9740525 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:15:19,590] INFO Saving metric sample completeness to cache for generation 31 and from/to indices 9740514-9740525 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:15:19,591] INFO Saving metric sample completeness to cache for generation 31 and from/to indices 9740514-9740525 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:15:19,592] INFO Saving metric sample completeness to cache for generation 31 and from/to indices 9740514-9740525 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:15:25,882] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:15:25,891] INFO Generated cluster model in 13 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:15:25,898] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:15:25,904] INFO Max replica load per broker for resource disk in MiB is: [1=0.19769954681396484] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:15:25,905] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004756549838930368] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:15:25,906] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.009644204750657082] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:15:25,907] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:15:25,907] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004756549838930368] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:15:25,908] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:15:25,911] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.42, lower limit: 0.33, upper limit: 0.51), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.42, lower limit: 0.33, upper limit: 0.51}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:15:25,911] INFO Max replica load per broker for resource disk in MiB is: [1=0.19769954681396484] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:15:25,912] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:15:25,912] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:15:29,657] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:15:29,657] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:15:29,658] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:15:43,468] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:15:43,609] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.61 ms each. The slowest event was writeNoOpRecord(1843681441), which took 44.21 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:15:56,899] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:15:56,899] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:15:56,904] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:16:25,893] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:16:25,899] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:16:25,905] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:16:25,909] INFO Max replica load per broker for resource disk in MiB is: [1=0.19769954681396484] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:16:25,910] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004756549838930368] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:16:25,910] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.009644204750657082] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:16:25,911] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:16:25,911] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004756549838930368] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:16:25,912] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:16:25,914] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.42, lower limit: 0.33, upper limit: 0.51), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.42, lower limit: 0.33, upper limit: 0.51}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:16:25,914] INFO Max replica load per broker for resource disk in MiB is: [1=0.19769954681396484] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:16:25,915] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:16:25,915] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:16:26,591] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:16:26,591] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:16:26,596] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:16:43,467] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:16:43,611] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 10.89 ms each. The slowest event was writeNoOpRecord(1528074006), which took 61.30 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:16:58,615] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:16:58,615] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:16:58,617] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:17:25,881] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:17:25,888] INFO Generated cluster model in 14 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:17:25,894] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:17:25,899] INFO Max replica load per broker for resource disk in MiB is: [1=0.19769954681396484] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:17:25,900] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004756549838930368] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:17:25,901] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.009644204750657082] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:17:25,902] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:17:25,904] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004756549838930368] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:17:25,905] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:17:25,907] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.42, lower limit: 0.33, upper limit: 0.51), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.42, lower limit: 0.33, upper limit: 0.51}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:17:25,907] INFO Max replica load per broker for resource disk in MiB is: [1=0.19769954681396484] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:17:25,907] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:17:25,907] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:17:26,378] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:17:26,378] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:17:26,379] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:17:43,470] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:17:43,612] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 10.59 ms each. The slowest event was writeNoOpRecord(2131201072), which took 45.57 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:17:58,404] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:17:58,404] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:17:58,406] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:17:58,412] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 18:17:58,412] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 18:17:59,998] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753294500000, endMs=1753294680000, endMsInclusive=1753294679999, index=9740526, baseTimestamp=0}(18:15:00 - 18:17:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4426 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4487 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:18:00,079] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:15:00,18:17:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_BYTES_IN=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:18:00,080] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:15:44.136 to 18:17:44.232 (1753294544136 to 1753294664232). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:18:00,080] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:18:00,080] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:18:00,080] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 31->32,current window range [1753292520000, 1753294680000, 17:42:00 to 18:18:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:18:00,080] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 31->32,current window range [1753292520000, 1753294680000, 17:42:00 to 18:18:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:18:00,081] INFO Successfully finished metric sampling for time period 18:15:00 to 18:17:59.999 (1753294500000 to 1753294679999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:18:00,081] INFO Sleeping the SamplingScheduler until 18:20:59.999 (for 179918ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740526, 18:15:00 - 18:17:59.999), currentWindow: (index: 9740527, 18:18:00 - 18:20:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:18:19,591] INFO Saving metric sample completeness to cache for generation 32 and from/to indices 9740515-9740526 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:18:19,594] INFO Saving metric sample completeness to cache for generation 32 and from/to indices 9740515-9740526 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:18:19,595] INFO Saving metric sample completeness to cache for generation 32 and from/to indices 9740515-9740526 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:18:19,597] INFO Saving metric sample completeness to cache for generation 32 and from/to indices 9740515-9740526 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:18:25,903] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:18:25,909] INFO Generated cluster model in 8 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:18:25,913] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:18:25,931] INFO Max replica load per broker for resource disk in MiB is: [1=0.20191478729248047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:18:25,934] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004791212268173695] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:18:25,935] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008983410894870758] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:18:25,936] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:18:26,011] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004791212268173695] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:18:26,012] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:18:26,013] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.44, lower limit: 0.35, upper limit: 0.53), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.44, lower limit: 0.35, upper limit: 0.53}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:18:26,013] INFO Max replica load per broker for resource disk in MiB is: [1=0.20191478729248047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:18:26,013] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:18:26,014] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:18:30,429] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:18:30,429] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:18:30,436] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:18:43,272] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 306 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 18:18:43,473] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:18:43,614] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 10.79 ms each. The slowest event was writeNoOpRecord(382404201), which took 53.83 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:19:00,249] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:19:00,249] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:19:00,249] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:19:13,606] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:19:13,606] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:19:13,607] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:19:13,607] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:19:25,890] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:19:25,896] INFO Generated cluster model in 11 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:19:25,904] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:19:25,908] INFO Max replica load per broker for resource disk in MiB is: [1=0.20191478729248047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:19:25,912] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004791212268173695] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:19:25,913] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008983410894870758] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:19:25,913] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:19:25,914] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004791212268173695] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:19:25,915] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:19:25,917] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.44, lower limit: 0.35, upper limit: 0.53), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.44, lower limit: 0.35, upper limit: 0.53}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:19:25,917] INFO Max replica load per broker for resource disk in MiB is: [1=0.20191478729248047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:19:25,918] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:19:25,918] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:19:29,965] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:19:29,965] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:19:29,971] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:19:43,479] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:19:43,622] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 10.74 ms each. The slowest event was writeNoOpRecord(1537892382), which took 40.12 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:19:59,767] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:19:59,767] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:19:59,767] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:20:25,925] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:20:25,947] INFO Generated cluster model in 29 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:20:25,956] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:20:26,072] INFO Max replica load per broker for resource disk in MiB is: [1=0.20191478729248047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:20:26,074] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004791212268173695] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:20:26,074] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008983410894870758] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:20:26,075] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:20:26,076] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004791212268173695] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:20:26,077] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:20:26,079] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.44, lower limit: 0.35, upper limit: 0.53), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.44, lower limit: 0.35, upper limit: 0.53}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:20:26,079] INFO Max replica load per broker for resource disk in MiB is: [1=0.20191478729248047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:20:26,079] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:20:26,079] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:20:31,780] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:20:31,780] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:20:31,783] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:20:43,476] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:20:43,620] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 10.71 ms each. The slowest event was writeNoOpRecord(1045948558), which took 36.73 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:21:00,001] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753294680000, endMs=1753294860000, endMsInclusive=1753294859999, index=9740527, baseTimestamp=0}(18:18:00 - 18:20:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4616 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4678 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,052] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:21:00,072] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:18:00,18:20:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_OUT=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_IN=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, ALL_MIRROR_TOPIC_BYTES_IN=3, TOPIC_PRODUCE_REQUEST_RATE=12, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:21:00,074] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:18:44.134 to 18:20:44.222 (1753294724134 to 1753294844222). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:21:00,075] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:21:00,075] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:21:00,076] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 32->33,current window range [1753292700000, 1753294860000, 17:45:00 to 18:21:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:21:00,076] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 32->33,current window range [1753292700000, 1753294860000, 17:45:00 to 18:21:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:21:00,076] INFO Successfully finished metric sampling for time period 18:18:00 to 18:20:59.999 (1753294680000 to 1753294859999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:21:00,076] INFO Sleeping the SamplingScheduler until 18:23:59.999 (for 179923ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740527, 18:18:00 - 18:20:59.999), currentWindow: (index: 9740528, 18:21:00 - 18:23:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:21:01,706] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:21:01,706] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:21:01,708] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:21:19,591] INFO Saving metric sample completeness to cache for generation 33 and from/to indices 9740516-9740527 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:21:19,592] INFO Saving metric sample completeness to cache for generation 33 and from/to indices 9740516-9740527 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:21:19,593] INFO Saving metric sample completeness to cache for generation 33 and from/to indices 9740516-9740527 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:21:19,594] INFO Saving metric sample completeness to cache for generation 33 and from/to indices 9740516-9740527 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:21:25,868] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:21:25,872] INFO Generated cluster model in 6 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:21:25,876] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:21:25,882] INFO Max replica load per broker for resource disk in MiB is: [1=0.20610475540161133] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:21:25,884] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004864469636231661] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:21:25,885] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008549840189516544] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:21:25,886] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:21:25,888] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004864469636231661] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:21:25,891] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:21:25,894] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.46, lower limit: 0.36, upper limit: 0.55), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.46, lower limit: 0.36, upper limit: 0.55}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:21:25,894] INFO Max replica load per broker for resource disk in MiB is: [1=0.20610475540161133] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:21:25,894] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:21:25,894] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:21:33,737] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:21:33,737] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:21:33,740] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:21:43,477] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:21:43,622] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 10.81 ms each. The slowest event was writeNoOpRecord(55381563), which took 40.42 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:22:05,766] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:22:05,766] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:22:05,769] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:22:25,863] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:22:25,869] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:22:25,886] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:22:25,894] INFO Max replica load per broker for resource disk in MiB is: [1=0.20610475540161133] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:22:25,895] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004864469636231661] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:22:25,896] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008549840189516544] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:22:25,897] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:22:25,898] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004864469636231661] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:22:25,898] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:22:25,900] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.46, lower limit: 0.36, upper limit: 0.55), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.46, lower limit: 0.36, upper limit: 0.55}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:22:25,900] INFO Max replica load per broker for resource disk in MiB is: [1=0.20610475540161133] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:22:25,900] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:22:25,900] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:22:35,252] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:22:35,252] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:22:35,258] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:22:43,478] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:22:43,623] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.77 ms each. The slowest event was writeNoOpRecord(1671669945), which took 51.61 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:23:07,285] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:23:07,285] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:23:07,287] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:23:25,903] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:23:25,911] INFO Generated cluster model in 13 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:23:25,919] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:23:25,922] INFO Max replica load per broker for resource disk in MiB is: [1=0.20610475540161133] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:23:25,923] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.004864469636231661] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:23:25,923] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008549840189516544] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:23:25,924] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:23:25,924] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.004864469636231661] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:23:25,925] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:23:25,926] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.46, lower limit: 0.36, upper limit: 0.55), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.46, lower limit: 0.36, upper limit: 0.55}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:23:25,926] INFO Max replica load per broker for resource disk in MiB is: [1=0.20610475540161133] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:23:25,927] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:23:25,927] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:23:39,282] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:23:39,282] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:23:39,282] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:23:43,276] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 93 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 18:23:43,478] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:23:43,631] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 10.96 ms each. The slowest event was writeNoOpRecord(1558211511), which took 46.52 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:24:00,008] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753294860000, endMs=1753295040000, endMsInclusive=1753295039999, index=9740528, baseTimestamp=0}(18:21:00 - 18:23:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:24:00,028] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4834 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 4841 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,029] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:24:00,062] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:21:00,18:23:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, BROKER_CPU_UTIL=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, ALL_MIRROR_TOPIC_BYTES_IN=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:24:00,064] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:21:44.133 to 18:23:44.207 (1753294904133 to 1753295024207). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:24:00,064] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:24:00,064] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:24:00,064] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 33->34,current window range [1753292880000, 1753295040000, 17:48:00 to 18:24:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:24:00,064] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 33->34,current window range [1753292880000, 1753295040000, 17:48:00 to 18:24:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:24:00,065] INFO Successfully finished metric sampling for time period 18:21:00 to 18:23:59.999 (1753294860000 to 1753295039999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:24:00,065] INFO Sleeping the SamplingScheduler until 18:26:59.999 (for 179934ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740528, 18:21:00 - 18:23:59.999), currentWindow: (index: 9740529, 18:24:00 - 18:26:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:24:07,503] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:24:07,503] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:24:07,504] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:24:13,611] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:24:13,611] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:24:13,617] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:24:13,617] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:24:19,598] INFO Saving metric sample completeness to cache for generation 34 and from/to indices 9740517-9740528 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:24:19,599] INFO Saving metric sample completeness to cache for generation 34 and from/to indices 9740517-9740528 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:24:19,600] INFO Saving metric sample completeness to cache for generation 34 and from/to indices 9740517-9740528 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:24:19,602] INFO Saving metric sample completeness to cache for generation 34 and from/to indices 9740517-9740528 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:24:25,855] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:24:25,858] INFO Generated cluster model in 8 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:24:25,861] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:24:25,862] INFO Max replica load per broker for resource disk in MiB is: [1=0.21056310832500458] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:24:25,863] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005002887453883886] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:24:25,864] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008345280773937702] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:24:25,866] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:24:25,867] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005002887453883886] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:24:25,868] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:24:25,868] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.48, lower limit: 0.38, upper limit: 0.58), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.48, lower limit: 0.38, upper limit: 0.58}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:24:25,868] INFO Max replica load per broker for resource disk in MiB is: [1=0.21056310832500458] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:24:25,869] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:24:25,869] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:24:35,750] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:24:35,750] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:24:35,760] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:24:43,475] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:24:43,630] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 10.40 ms each. The slowest event was writeNoOpRecord(42438707), which took 41.58 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:25:07,434] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:25:07,434] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:25:07,437] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:25:25,912] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:25:25,918] INFO Generated cluster model in 44 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:25:25,922] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:25:25,927] INFO Max replica load per broker for resource disk in MiB is: [1=0.21056310832500458] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:25:25,929] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005002887453883886] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:25:25,929] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008345280773937702] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:25:25,930] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:25:25,930] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005002887453883886] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:25:25,931] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:25:25,932] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.48, lower limit: 0.38, upper limit: 0.58), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.48, lower limit: 0.38, upper limit: 0.58}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:25:25,932] INFO Max replica load per broker for resource disk in MiB is: [1=0.21056310832500458] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:25:25,932] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:25:25,932] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:25:39,457] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:25:39,457] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:25:39,458] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:25:43,474] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:25:43,630] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.04 ms each. The slowest event was writeNoOpRecord(926457087), which took 41.78 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:26:11,479] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:26:11,479] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:26:11,480] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:26:25,850] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:26:25,857] INFO Generated cluster model in 8 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:26:25,871] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:26:25,884] INFO Max replica load per broker for resource disk in MiB is: [1=0.21056310832500458] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:26:25,885] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005002887453883886] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:26:25,886] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008345280773937702] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:26:25,887] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:26:25,887] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005002887453883886] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:26:25,888] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:26:25,889] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.48, lower limit: 0.38, upper limit: 0.58), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.48, lower limit: 0.38, upper limit: 0.58}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:26:25,889] INFO Max replica load per broker for resource disk in MiB is: [1=0.21056310832500458] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:26:25,890] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:26:25,890] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:26:39,858] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:26:39,858] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:26:39,861] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:26:43,477] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:26:43,631] INFO [ControllerServer id=1] In the last 60000 ms period, 336 controller events were completed, which took an average of 10.83 ms each. The slowest event was writeNoOpRecord(462127280), which took 45.77 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:26:59,995] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753295040000, endMs=1753295220000, endMsInclusive=1753295219999, index=9740529, baseTimestamp=0}(18:24:00 - 18:26:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:27:00,041] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5005 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5051 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,043] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:27:00,066] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:24:00,18:26:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_OUT=12, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:27:00,067] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:24:44.131 to 18:26:44.256 (1753295084131 to 1753295204256). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:27:00,067] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:27:00,067] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:27:00,067] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 34->35,current window range [1753293060000, 1753295220000, 17:51:00 to 18:27:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:27:00,067] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 34->35,current window range [1753293060000, 1753295220000, 17:51:00 to 18:27:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:27:00,067] INFO Successfully finished metric sampling for time period 18:24:00 to 18:26:59.999 (1753295040000 to 1753295219999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:27:00,067] INFO Sleeping the SamplingScheduler until 18:29:59.999 (for 179932ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740529, 18:24:00 - 18:26:59.999), currentWindow: (index: 9740530, 18:27:00 - 18:29:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:27:11,878] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:27:11,878] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:27:11,879] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:27:19,592] INFO Saving metric sample completeness to cache for generation 35 and from/to indices 9740518-9740529 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:27:19,594] INFO Saving metric sample completeness to cache for generation 35 and from/to indices 9740518-9740529 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:27:19,595] INFO Saving metric sample completeness to cache for generation 35 and from/to indices 9740518-9740529 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:27:19,597] INFO Saving metric sample completeness to cache for generation 35 and from/to indices 9740518-9740529 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:27:25,867] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:27:25,873] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:27:25,878] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:27:25,881] INFO Max replica load per broker for resource disk in MiB is: [1=0.2150641679763794] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:27:25,882] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005043725483119488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:27:25,883] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008215815760195255] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:27:25,883] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:27:25,884] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005043725483119488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:27:25,884] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:27:25,885] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.50, lower limit: 0.39, upper limit: 0.60), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.50, lower limit: 0.39, upper limit: 0.60}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:27:25,886] INFO Max replica load per broker for resource disk in MiB is: [1=0.2150641679763794] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:27:25,886] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:27:25,886] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:27:43,479] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:27:43,633] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 10.79 ms each. The slowest event was writeNoOpRecord(1141701089), which took 40.20 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:27:43,918] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:27:43,918] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:27:43,920] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:28:12,235] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:28:12,235] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:28:12,236] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:28:25,864] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:28:25,868] INFO Generated cluster model in 7 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:28:25,871] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:28:25,873] INFO Max replica load per broker for resource disk in MiB is: [1=0.2150641679763794] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:28:25,874] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005043725483119488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:28:25,874] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008215815760195255] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:28:25,875] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:28:25,875] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005043725483119488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:28:25,875] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:28:25,876] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.50, lower limit: 0.39, upper limit: 0.60), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.50, lower limit: 0.39, upper limit: 0.60}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:28:25,876] INFO Max replica load per broker for resource disk in MiB is: [1=0.2150641679763794] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:28:25,877] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:28:25,877] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:28:43,056] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:28:43,056] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:28:43,058] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:28:43,270] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 84 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 18:28:43,483] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:28:43,636] INFO [ControllerServer id=1] In the last 60000 ms period, 334 controller events were completed, which took an average of 10.77 ms each. The slowest event was writeNoOpRecord(1471293129), which took 53.70 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:29:13,601] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:29:13,601] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:29:13,601] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:29:13,601] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:29:15,076] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:29:15,076] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:29:15,077] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:29:25,859] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:29:25,866] INFO Generated cluster model in 11 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:29:25,869] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:29:25,873] INFO Max replica load per broker for resource disk in MiB is: [1=0.2150641679763794] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:29:25,874] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005043725483119488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:29:25,875] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.008215815760195255] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:29:25,875] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:29:25,876] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005043725483119488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:29:25,876] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:29:25,877] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.50, lower limit: 0.39, upper limit: 0.60), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.50, lower limit: 0.39, upper limit: 0.60}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:29:25,877] INFO Max replica load per broker for resource disk in MiB is: [1=0.2150641679763794] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:29:25,878] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:29:25,878] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:29:43,484] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:29:43,636] INFO [ControllerServer id=1] In the last 60000 ms period, 329 controller events were completed, which took an average of 10.90 ms each. The slowest event was writeNoOpRecord(1726418956), which took 41.90 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:29:47,096] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:29:47,096] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:29:47,097] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:30:00,014] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753295220000, endMs=1753295400000, endMsInclusive=1753295399999, index=9740530, baseTimestamp=0}(18:27:00 - 18:29:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5193 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5244 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,038] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:30:00,061] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:27:00,18:29:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, ALL_MIRROR_TOPIC_BYTES_IN=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:30:00,062] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:27:44.123 to 18:29:44.177 (1753295264123 to 1753295384177). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:30:00,064] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:30:00,064] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:30:00,065] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 35->36,current window range [1753293240000, 1753295400000, 17:54:00 to 18:30:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:30:00,065] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 35->36,current window range [1753293240000, 1753295400000, 17:54:00 to 18:30:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:30:00,065] INFO Successfully finished metric sampling for time period 18:27:00 to 18:29:59.999 (1753295220000 to 1753295399999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:30:00,065] INFO Sleeping the SamplingScheduler until 18:32:59.999 (for 179934ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740530, 18:27:00 - 18:29:59.999), currentWindow: (index: 9740531, 18:30:00 - 18:32:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:30:19,123] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:30:19,123] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:30:19,126] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:30:19,582] INFO Saving metric sample completeness to cache for generation 36 and from/to indices 9740519-9740530 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:30:19,583] INFO Saving metric sample completeness to cache for generation 36 and from/to indices 9740519-9740530 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:30:19,584] INFO Saving metric sample completeness to cache for generation 36 and from/to indices 9740519-9740530 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:30:19,585] INFO Saving metric sample completeness to cache for generation 36 and from/to indices 9740519-9740530 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:30:25,876] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:30:25,881] INFO Generated cluster model in 7 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:30:25,885] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:30:25,888] INFO Max replica load per broker for resource disk in MiB is: [1=0.21955394744873047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:30:25,889] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.00506127392873168] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:30:25,889] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00804881565272808] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:30:25,890] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:30:25,890] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.00506127392873168] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:30:25,891] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:30:25,892] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.51, lower limit: 0.41, upper limit: 0.62), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.51, lower limit: 0.41, upper limit: 0.62}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:30:25,892] INFO Max replica load per broker for resource disk in MiB is: [1=0.21955394744873047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:30:25,892] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:30:25,892] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:30:43,488] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:30:43,637] INFO [ControllerServer id=1] In the last 60000 ms period, 336 controller events were completed, which took an average of 10.76 ms each. The slowest event was writeNoOpRecord(1871147519), which took 49.65 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:30:50,366] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:30:50,366] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:30:50,368] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:31:22,391] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:31:22,391] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:31:22,394] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:31:25,879] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:31:25,891] INFO Generated cluster model in 16 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:31:25,897] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:31:25,901] INFO Max replica load per broker for resource disk in MiB is: [1=0.21955394744873047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:31:25,902] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.00506127392873168] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:31:25,903] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00804881565272808] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:31:25,903] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:31:25,904] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.00506127392873168] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:31:25,904] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:31:25,906] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.51, lower limit: 0.41, upper limit: 0.62), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.51, lower limit: 0.41, upper limit: 0.62}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:31:25,906] INFO Max replica load per broker for resource disk in MiB is: [1=0.21955394744873047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:31:25,906] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:31:25,906] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:31:43,491] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:31:43,639] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 10.42 ms each. The slowest event was writeNoOpRecord(1278831230), which took 40.45 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:31:54,418] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:31:54,418] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:31:54,420] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:32:25,874] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:32:25,881] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:32:25,884] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:32:25,887] INFO Max replica load per broker for resource disk in MiB is: [1=0.21955394744873047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:32:25,889] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.00506127392873168] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:32:25,889] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00804881565272808] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:32:25,890] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:32:25,891] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.00506127392873168] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:32:25,891] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:32:25,893] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.51, lower limit: 0.41, upper limit: 0.62), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.51, lower limit: 0.41, upper limit: 0.62}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:32:25,893] INFO Max replica load per broker for resource disk in MiB is: [1=0.21955394744873047] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:32:25,893] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:32:25,893] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:32:26,428] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:32:26,428] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:32:26,428] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:32:43,503] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:32:43,641] INFO [ControllerServer id=1] In the last 60000 ms period, 329 controller events were completed, which took an average of 10.72 ms each. The slowest event was writeNoOpRecord(1169250748), which took 40.34 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:32:52,741] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:32:52,741] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:32:52,743] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:32:59,999] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753295400000, endMs=1753295580000, endMsInclusive=1753295579999, index=9740531, baseTimestamp=0}(18:30:00 - 18:32:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5372 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,016] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5446 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,017] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,017] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:33:00,039] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:30:00,18:32:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:33:00,040] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:30:44.121 to 18:32:44.231 (1753295444121 to 1753295564231). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:33:00,040] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:33:00,040] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:33:00,040] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 36->37,current window range [1753293420000, 1753295580000, 17:57:00 to 18:33:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:33:00,040] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 36->37,current window range [1753293420000, 1753295580000, 17:57:00 to 18:33:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:33:00,041] INFO Successfully finished metric sampling for time period 18:30:00 to 18:32:59.999 (1753295400000 to 1753295579999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:33:00,041] INFO Sleeping the SamplingScheduler until 18:35:59.999 (for 179958ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740531, 18:30:00 - 18:32:59.999), currentWindow: (index: 9740532, 18:33:00 - 18:35:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:33:19,587] INFO Saving metric sample completeness to cache for generation 37 and from/to indices 9740520-9740531 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:33:19,590] INFO Saving metric sample completeness to cache for generation 37 and from/to indices 9740520-9740531 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:33:19,590] INFO Saving metric sample completeness to cache for generation 37 and from/to indices 9740520-9740531 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:33:19,593] INFO Saving metric sample completeness to cache for generation 37 and from/to indices 9740520-9740531 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:33:24,770] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:33:24,770] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:33:24,771] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:33:24,773] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 18:33:24,773] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 18:33:25,872] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:33:25,880] INFO Generated cluster model in 13 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:33:25,885] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:33:25,890] INFO Max replica load per broker for resource disk in MiB is: [1=0.22406892478466034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:33:25,891] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005071909166872501] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:33:25,892] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.007910167798399925] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:33:25,893] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:33:25,893] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005071909166872501] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:33:25,894] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:33:25,896] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.53, lower limit: 0.42, upper limit: 0.64), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.53, lower limit: 0.42, upper limit: 0.64}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:33:25,896] INFO Max replica load per broker for resource disk in MiB is: [1=0.22406892478466034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:33:25,896] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:33:25,897] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:33:43,269] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 182 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 18:33:43,504] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:33:43,644] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.73 ms each. The slowest event was writeNoOpRecord(206299476), which took 44.81 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:33:55,245] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:33:55,245] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:33:55,248] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:34:13,600] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:34:13,600] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:34:13,600] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:34:13,600] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:34:25,872] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:34:25,877] INFO Generated cluster model in 12 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:34:25,880] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:34:25,883] INFO Max replica load per broker for resource disk in MiB is: [1=0.22406892478466034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:34:25,884] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005071909166872501] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:34:25,885] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.007910167798399925] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:34:25,886] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:34:25,886] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005071909166872501] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:34:25,887] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:34:25,888] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.53, lower limit: 0.42, upper limit: 0.64), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.53, lower limit: 0.42, upper limit: 0.64}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:34:25,889] INFO Max replica load per broker for resource disk in MiB is: [1=0.22406892478466034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:34:25,889] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:34:25,889] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:34:27,258] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:34:27,258] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:34:27,259] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:34:43,509] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:34:43,647] INFO [ControllerServer id=1] In the last 60000 ms period, 331 controller events were completed, which took an average of 10.83 ms each. The slowest event was writeNoOpRecord(1129569596), which took 45.43 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:34:49,686] INFO Broker change event(s) detected: [] (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 18:34:49,687] INFO Alive brokers: [1], failed brokers: [] (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 18:34:49,688] INFO Updated list of failed broker: {} (com.linkedin.kafka.cruisecontrol.detector.BrokerFailureDetector)
[2025-07-23 18:34:53,737] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:34:53,737] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:34:53,739] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:35:25,762] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:35:25,762] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:35:25,764] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:35:25,864] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:35:25,870] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:35:25,873] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:35:25,876] INFO Max replica load per broker for resource disk in MiB is: [1=0.22406892478466034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:35:25,876] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005071909166872501] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:35:25,877] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.007910167798399925] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:35:25,878] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:35:25,879] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005071909166872501] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:35:25,879] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:35:25,880] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.53, lower limit: 0.42, upper limit: 0.64), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.53, lower limit: 0.42, upper limit: 0.64}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:35:25,881] INFO Max replica load per broker for resource disk in MiB is: [1=0.22406892478466034] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:35:25,881] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:35:25,881] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:35:43,512] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:35:43,649] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 10.88 ms each. The slowest event was writeNoOpRecord(741527406), which took 44.01 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:35:51,564] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:35:51,564] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:35:51,565] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:36:00,000] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753295580000, endMs=1753295760000, endMsInclusive=1753295759999, index=9740532, baseTimestamp=0}(18:33:00 - 18:35:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:36:00,054] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5561 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5638 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,055] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:36:00,070] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:33:00,18:35:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_FETCH_REQUEST_RATE=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:36:00,074] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:33:44.125 to 18:35:44.204 (1753295624125 to 1753295744204). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:36:00,075] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:36:00,075] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:36:00,075] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 37->38,current window range [1753293600000, 1753295760000, 18:00:00 to 18:36:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:36:00,075] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 37->38,current window range [1753293600000, 1753295760000, 18:00:00 to 18:36:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:36:00,076] INFO Successfully finished metric sampling for time period 18:33:00 to 18:35:59.999 (1753295580000 to 1753295759999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:36:00,076] INFO Sleeping the SamplingScheduler until 18:38:59.999 (for 179923ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740532, 18:33:00 - 18:35:59.999), currentWindow: (index: 9740533, 18:36:00 - 18:38:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:36:19,585] INFO Saving metric sample completeness to cache for generation 38 and from/to indices 9740521-9740532 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:36:19,588] INFO Saving metric sample completeness to cache for generation 38 and from/to indices 9740521-9740532 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:36:19,589] INFO Saving metric sample completeness to cache for generation 38 and from/to indices 9740521-9740532 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:36:19,619] INFO Saving metric sample completeness to cache for generation 38 and from/to indices 9740521-9740532 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:36:23,578] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:36:23,578] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:36:23,579] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:36:25,866] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:36:25,872] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:36:25,876] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:36:25,879] INFO Max replica load per broker for resource disk in MiB is: [1=0.2285153716802597] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:36:25,880] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005080875474959612] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:36:25,881] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.007794705219566822] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:36:25,882] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:36:25,882] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005080875474959612] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:36:25,883] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:36:25,884] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.55, lower limit: 0.43, upper limit: 0.67), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.55, lower limit: 0.43, upper limit: 0.67}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:36:25,884] INFO Max replica load per broker for resource disk in MiB is: [1=0.2285153716802597] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:36:25,885] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:36:25,885] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:36:43,512] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:36:43,653] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 10.58 ms each. The slowest event was writeNoOpRecord(1809685653), which took 40.72 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:36:53,363] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:36:53,363] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:36:53,365] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:37:19,365] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:37:19,365] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:37:19,367] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:37:25,877] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:37:25,885] INFO Generated cluster model in 12 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:37:25,898] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:37:25,901] INFO Max replica load per broker for resource disk in MiB is: [1=0.2285153716802597] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:37:25,903] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005080875474959612] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:37:25,904] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.007794705219566822] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:37:25,904] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:37:25,905] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005080875474959612] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:37:25,906] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:37:25,909] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.55, lower limit: 0.43, upper limit: 0.67), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.55, lower limit: 0.43, upper limit: 0.67}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:37:25,909] INFO Max replica load per broker for resource disk in MiB is: [1=0.2285153716802597] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:37:25,910] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:37:25,910] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:37:43,516] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:37:43,659] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.36 ms each. The slowest event was writeNoOpRecord(212181820), which took 53.41 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:37:50,825] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:37:50,825] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:37:50,826] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:38:22,852] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:38:22,852] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:38:22,855] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:38:25,867] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:38:25,873] INFO Generated cluster model in 9 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:38:25,876] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:38:25,878] INFO Max replica load per broker for resource disk in MiB is: [1=0.2285153716802597] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:38:25,879] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005080875474959612] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:38:25,880] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.007794705219566822] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:38:25,880] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:38:25,881] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005080875474959612] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:38:25,881] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:38:25,883] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.55, lower limit: 0.43, upper limit: 0.67), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.55, lower limit: 0.43, upper limit: 0.67}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:38:25,883] INFO Max replica load per broker for resource disk in MiB is: [1=0.2285153716802597] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:38:25,884] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:38:25,884] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:38:43,270] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 449 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 18:38:43,519] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:38:43,665] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.62 ms each. The slowest event was writeNoOpRecord(727474911), which took 53.24 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:38:51,492] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:38:51,492] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:38:51,495] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:39:00,021] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753295760000, endMs=1753295940000, endMsInclusive=1753295939999, index=9740533, baseTimestamp=0}(18:36:00 - 18:38:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5774 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5806 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,062] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:39:00,129] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:36:00,18:38:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:39:00,129] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:36:44.116 to 18:38:44.191 (1753295804116 to 1753295924191). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:39:00,130] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:39:00,130] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:39:00,130] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 38->39,current window range [1753293780000, 1753295940000, 18:03:00 to 18:39:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:39:00,130] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 38->39,current window range [1753293780000, 1753295940000, 18:03:00 to 18:39:00],abandon 0 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:39:00,130] INFO Successfully finished metric sampling for time period 18:36:00 to 18:38:59.999 (1753295760000 to 1753295939999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:39:00,130] INFO Sleeping the SamplingScheduler until 18:41:59.999 (for 179869ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740533, 18:36:00 - 18:38:59.999), currentWindow: (index: 9740534, 18:39:00 - 18:41:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:39:13,600] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:39:13,600] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:39:13,600] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:39:13,600] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:39:19,583] INFO Saving metric sample completeness to cache for generation 39 and from/to indices 9740522-9740533 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:39:19,584] INFO Saving metric sample completeness to cache for generation 39 and from/to indices 9740522-9740533 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:39:19,584] INFO Saving metric sample completeness to cache for generation 39 and from/to indices 9740522-9740533 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:39:19,589] INFO Saving metric sample completeness to cache for generation 39 and from/to indices 9740522-9740533 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:39:20,109] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:39:20,109] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:39:20,110] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:39:25,875] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:39:25,883] INFO Generated cluster model in 12 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:39:25,893] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:39:25,897] INFO Max replica load per broker for resource disk in MiB is: [1=0.23299908638000488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:39:25,899] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005082204006612301] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:39:25,899] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.007694097235798836] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:39:25,900] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:39:25,900] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005082204006612301] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:39:25,901] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:39:25,903] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.57, lower limit: 0.45, upper limit: 0.69), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.57, lower limit: 0.45, upper limit: 0.69}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:39:25,903] INFO Max replica load per broker for resource disk in MiB is: [1=0.23299908638000488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:39:25,903] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:39:25,904] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:39:43,519] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:39:43,666] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 10.87 ms each. The slowest event was writeNoOpRecord(1267040582), which took 46.93 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:39:50,831] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:39:50,831] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:39:50,833] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:40:22,863] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:40:22,863] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:40:22,866] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:40:25,888] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:40:25,918] INFO Generated cluster model in 36 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:40:25,921] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:40:25,923] INFO Max replica load per broker for resource disk in MiB is: [1=0.23299908638000488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:40:25,924] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005082204006612301] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:40:25,924] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.007694097235798836] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:40:25,925] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:40:25,925] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005082204006612301] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:40:25,925] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:40:25,926] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.57, lower limit: 0.45, upper limit: 0.69), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.57, lower limit: 0.45, upper limit: 0.69}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:40:25,926] INFO Max replica load per broker for resource disk in MiB is: [1=0.23299908638000488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:40:25,926] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:40:25,926] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:40:43,522] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:40:43,672] INFO [ControllerServer id=1] In the last 60000 ms period, 329 controller events were completed, which took an average of 11.44 ms each. The slowest event was writeNoOpRecord(1155560549), which took 42.46 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:40:54,923] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:40:54,923] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:40:54,925] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:41:25,885] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:41:25,892] INFO Generated cluster model in 13 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:41:25,900] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:41:25,904] INFO Max replica load per broker for resource disk in MiB is: [1=0.23299908638000488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:41:25,906] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005082204006612301] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:41:25,906] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.007694097235798836] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:41:25,907] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:41:25,908] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005082204006612301] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:41:25,909] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:41:25,911] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.57, lower limit: 0.45, upper limit: 0.69), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.57, lower limit: 0.45, upper limit: 0.69}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:41:25,912] INFO Max replica load per broker for resource disk in MiB is: [1=0.23299908638000488] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:41:25,912] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:41:25,912] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:41:26,935] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:41:26,935] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:41:26,935] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:41:43,525] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:41:43,674] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 11.50 ms each. The slowest event was writeNoOpRecord(1153665324), which took 44.36 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:41:53,984] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:41:53,984] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:41:53,989] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:41:59,998] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753295940000, endMs=1753296120000, endMsInclusive=1753296119999, index=9740534, baseTimestamp=0}(18:39:00 - 18:41:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 5959 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 6002 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:42:00,054] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:39:00,18:41:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, BROKER_CPU_UTIL=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, ALL_MIRROR_TOPIC_BYTES_IN=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:42:00,055] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:39:44.12 to 18:41:44.196 (1753295984120 to 1753296104196). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:42:00,056] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:42:00,056] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:42:00,056] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 39->40,current window range [1753293960000, 1753296120000, 18:06:00 to 18:42:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:42:00,056] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 39->40,current window range [1753293960000, 1753296120000, 18:06:00 to 18:42:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:42:00,056] INFO Successfully finished metric sampling for time period 18:39:00 to 18:41:59.999 (1753295940000 to 1753296119999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:42:00,056] INFO Sleeping the SamplingScheduler until 18:44:59.999 (for 179943ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740534, 18:39:00 - 18:41:59.999), currentWindow: (index: 9740535, 18:42:00 - 18:44:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:42:19,591] INFO Saving metric sample completeness to cache for generation 40 and from/to indices 9740523-9740534 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:42:19,595] INFO Saving metric sample completeness to cache for generation 40 and from/to indices 9740523-9740534 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:42:19,597] INFO Saving metric sample completeness to cache for generation 40 and from/to indices 9740523-9740534 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:42:19,601] INFO Saving metric sample completeness to cache for generation 40 and from/to indices 9740523-9740534 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:42:25,865] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:42:25,890] INFO Generated cluster model in 29 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:42:25,895] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:42:25,899] INFO Max replica load per broker for resource disk in MiB is: [1=0.24183590710163116] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:42:25,900] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005073465872555971] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:42:25,900] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006719710770994425] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:42:25,901] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:42:25,902] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005073465872555971] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:42:25,903] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:42:25,904] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.58, lower limit: 0.46, upper limit: 0.71), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.58, lower limit: 0.46, upper limit: 0.71}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:42:25,904] INFO Max replica load per broker for resource disk in MiB is: [1=0.24183590710163116] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:42:25,905] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:42:25,905] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:42:26,002] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:42:26,002] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:42:26,002] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:42:43,526] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:42:43,676] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 11.52 ms each. The slowest event was writeNoOpRecord(657045691), which took 47.41 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:42:54,561] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:42:54,561] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:42:54,562] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:43:25,875] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:43:25,880] INFO Generated cluster model in 8 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:43:25,884] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:43:25,886] INFO Max replica load per broker for resource disk in MiB is: [1=0.24183590710163116] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:43:25,887] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005073465872555971] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:43:25,888] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006719710770994425] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:43:25,888] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:43:25,889] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005073465872555971] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:43:25,889] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:43:25,891] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.58, lower limit: 0.46, upper limit: 0.71), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.58, lower limit: 0.46, upper limit: 0.71}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:43:25,891] INFO Max replica load per broker for resource disk in MiB is: [1=0.24183590710163116] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:43:25,891] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:43:25,891] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:43:26,612] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:43:26,612] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:43:26,615] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:43:43,271] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 580 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 18:43:43,525] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:43:43,677] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 11.53 ms each. The slowest event was writeNoOpRecord(369418738), which took 82.84 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:43:58,641] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:43:58,641] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:43:58,641] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:44:13,603] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:44:13,603] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:44:13,606] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:44:13,606] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:44:25,861] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:44:25,863] INFO Generated cluster model in 4 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:44:25,865] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:44:25,868] INFO Max replica load per broker for resource disk in MiB is: [1=0.24183590710163116] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:44:25,869] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005073465872555971] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:44:25,869] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006719710770994425] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:44:25,870] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:44:25,870] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005073465872555971] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:44:25,870] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:44:25,871] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.58, lower limit: 0.46, upper limit: 0.71), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.58, lower limit: 0.46, upper limit: 0.71}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:44:25,871] INFO Max replica load per broker for resource disk in MiB is: [1=0.24183590710163116] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:44:25,871] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:44:25,871] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:44:30,658] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:44:30,658] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:44:30,659] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:44:43,529] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:44:43,680] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 10.86 ms each. The slowest event was writeNoOpRecord(81100650), which took 38.66 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:45:00,000] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753296120000, endMs=1753296300000, endMsInclusive=1753296299999, index=9740535, baseTimestamp=0}(18:42:00 - 18:44:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 6140 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 6202 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,040] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:45:00,057] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:42:00,18:44:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_BYTES_IN=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_FETCH_REQUEST_RATE=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_BYTES_IN=3, BROKER_DISK_CAPACITY=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:45:00,058] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:42:44.121 to 18:44:44.167 (1753296164121 to 1753296284167). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:45:00,060] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:45:00,060] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:45:00,061] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 40->41,current window range [1753294140000, 1753296300000, 18:09:00 to 18:45:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:45:00,061] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 40->41,current window range [1753294140000, 1753296300000, 18:09:00 to 18:45:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:45:00,061] INFO Successfully finished metric sampling for time period 18:42:00 to 18:44:59.999 (1753296120000 to 1753296299999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:45:00,061] INFO Sleeping the SamplingScheduler until 18:47:59.999 (for 179938ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740535, 18:42:00 - 18:44:59.999), currentWindow: (index: 9740536, 18:45:00 - 18:47:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:45:02,680] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:45:02,680] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:45:02,682] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:45:19,594] INFO Saving metric sample completeness to cache for generation 41 and from/to indices 9740524-9740535 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:45:19,610] INFO Saving metric sample completeness to cache for generation 41 and from/to indices 9740524-9740535 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:45:19,611] INFO Saving metric sample completeness to cache for generation 41 and from/to indices 9740524-9740535 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:45:19,613] INFO Saving metric sample completeness to cache for generation 41 and from/to indices 9740524-9740535 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:45:25,874] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:45:25,882] INFO Generated cluster model in 13 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:45:25,894] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:45:25,897] INFO Max replica load per broker for resource disk in MiB is: [1=0.2506519854068756] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:45:25,897] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005085426848381758] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:45:25,898] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006531672552227974] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:45:25,899] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:45:25,899] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005085426848381758] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:45:25,900] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:45:25,902] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.60, lower limit: 0.48, upper limit: 0.73), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.60, lower limit: 0.48, upper limit: 0.73}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:45:25,902] INFO Max replica load per broker for resource disk in MiB is: [1=0.2506519854068756] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:45:25,902] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:45:25,902] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:45:34,689] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:45:34,689] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:45:34,689] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:45:43,529] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:45:43,681] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.68 ms each. The slowest event was writeNoOpRecord(1260265432), which took 40.50 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:46:06,701] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:46:06,701] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:46:06,702] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:46:25,885] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:46:25,894] INFO Generated cluster model in 14 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:46:25,899] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:46:25,902] INFO Max replica load per broker for resource disk in MiB is: [1=0.2506519854068756] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:46:25,904] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005085426848381758] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:46:25,905] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006531672552227974] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:46:25,906] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:46:25,907] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005085426848381758] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:46:25,908] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:46:25,912] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.60, lower limit: 0.48, upper limit: 0.73), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.60, lower limit: 0.48, upper limit: 0.73}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:46:25,912] INFO Max replica load per broker for resource disk in MiB is: [1=0.2506519854068756] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:46:25,912] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:46:25,912] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:46:38,601] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:46:38,601] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:46:38,604] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:46:43,530] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:46:43,684] INFO [ControllerServer id=1] In the last 60000 ms period, 335 controller events were completed, which took an average of 10.88 ms each. The slowest event was writeNoOpRecord(1599276837), which took 46.40 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:47:07,962] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:47:07,962] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:47:07,964] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:47:25,866] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:47:25,873] INFO Generated cluster model in 11 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:47:25,876] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:47:25,878] INFO Max replica load per broker for resource disk in MiB is: [1=0.2506519854068756] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:47:25,879] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005085426848381758] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:47:25,879] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.006531672552227974] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:47:25,879] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:47:25,880] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005085426848381758] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:47:25,880] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:47:25,882] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.60, lower limit: 0.48, upper limit: 0.73), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.60, lower limit: 0.48, upper limit: 0.73}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:47:25,882] INFO Max replica load per broker for resource disk in MiB is: [1=0.2506519854068756] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:47:25,882] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:47:25,883] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:47:39,998] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:47:39,998] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:47:40,003] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:47:43,534] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:47:43,687] INFO [ControllerServer id=1] In the last 60000 ms period, 330 controller events were completed, which took an average of 11.13 ms each. The slowest event was writeNoOpRecord(1154677474), which took 44.38 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:48:00,002] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753296300000, endMs=1753296480000, endMsInclusive=1753296479999, index=9740536, baseTimestamp=0}(18:45:00 - 18:47:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 6335 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 6388 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,030] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:48:00,078] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:45:00,18:47:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, TOPIC_FETCH_REQUEST_RATE=12, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_IN=12, TOPIC_BYTES_OUT=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, BROKER_DISK_CAPACITY=3, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:48:00,079] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:45:44.122 to 18:47:44.232 (1753296344122 to 1753296464232). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:48:00,080] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:48:00,080] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:48:00,080] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 41->42,current window range [1753294320000, 1753296480000, 18:12:00 to 18:48:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:48:00,080] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 41->42,current window range [1753294320000, 1753296480000, 18:12:00 to 18:48:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:48:00,080] INFO Successfully finished metric sampling for time period 18:45:00 to 18:47:59.999 (1753296300000 to 1753296479999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:48:00,081] INFO Sleeping the SamplingScheduler until 18:50:59.999 (for 179918ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740536, 18:45:00 - 18:47:59.999), currentWindow: (index: 9740537, 18:48:00 - 18:50:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:48:12,034] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:48:12,034] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:48:12,037] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:48:19,596] INFO Saving metric sample completeness to cache for generation 42 and from/to indices 9740525-9740536 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:48:19,607] INFO Saving metric sample completeness to cache for generation 42 and from/to indices 9740525-9740536 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.95, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:48:19,608] INFO Saving metric sample completeness to cache for generation 42 and from/to indices 9740525-9740536 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:48:19,611] INFO Saving metric sample completeness to cache for generation 42 and from/to indices 9740525-9740536 - validEntityRatio: 1.00, validEntityGroupRatio: 1.00 - for options (reason=, minValidEntityRatio=0.00, minValidEntityGroupRatio=0.00, minValidWindows=1, numEntitiesToInclude=65, granularity=ENTITY_GROUP) (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregatorState)
[2025-07-23 18:48:25,873] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:48:25,879] INFO Generated cluster model in 10 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:48:25,885] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:48:25,888] INFO Max replica load per broker for resource disk in MiB is: [1=0.25968560576438904] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:48:25,890] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005151037126779556] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:48:25,891] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00656840018928051] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:48:25,892] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:48:25,893] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005151037126779556] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:48:25,894] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:48:25,895] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.62, lower limit: 0.49, upper limit: 0.75), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.62, lower limit: 0.49, upper limit: 0.75}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:48:25,896] INFO Max replica load per broker for resource disk in MiB is: [1=0.25968560576438904] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:48:25,896] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:48:25,896] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:48:43,279] INFO [ControllerServer id=1] Periodic task electUnclean generated 0 records in 156 microseconds. (org.apache.kafka.controller.PeriodicTaskControlManager)
[2025-07-23 18:48:43,540] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:48:43,690] INFO [ControllerServer id=1] In the last 60000 ms period, 332 controller events were completed, which took an average of 10.72 ms each. The slowest event was writeNoOpRecord(439671422), which took 43.31 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:48:44,063] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:48:44,063] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:48:44,064] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:48:44,069] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 18:48:44,069] ERROR [ClusterLinkMetadataManager-broker-1] Cluster link metadata topic creation failed: org.apache.kafka.common.errors.InvalidReplicationFactorException: Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered. (kafka.server.link.ClusterLinkMetadataManagerWithKRaftSupport)
[2025-07-23 18:49:13,590] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:49:13,590] INFO Beginning log roller... (kafka.log.LogManager)
[2025-07-23 18:49:13,590] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:49:13,590] INFO Log roller completed in 0 seconds (kafka.log.LogManager)
[2025-07-23 18:49:14,508] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:49:14,508] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:49:14,511] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:49:25,847] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:49:25,855] INFO Generated cluster model in 12 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:49:25,859] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:49:25,862] INFO Max replica load per broker for resource disk in MiB is: [1=0.25968560576438904] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:49:25,863] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005151037126779556] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:49:25,865] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00656840018928051] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:49:25,867] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:49:25,868] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005151037126779556] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:49:25,869] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:49:25,871] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.62, lower limit: 0.49, upper limit: 0.75), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.62, lower limit: 0.49, upper limit: 0.75}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:49:25,871] INFO Max replica load per broker for resource disk in MiB is: [1=0.25968560576438904] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:49:25,871] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:49:25,871] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:49:42,510] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:49:42,510] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:49:42,511] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:49:43,536] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:49:43,688] INFO [ControllerServer id=1] In the last 60000 ms period, 333 controller events were completed, which took an average of 10.37 ms each. The slowest event was writeNoOpRecord(976994934), which took 34.46 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:50:11,874] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:50:11,874] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:50:11,876] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:50:25,858] INFO Rack IDs: kafka (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:50:25,867] INFO Generated cluster model in 20 ms with broker strategies: {1=ALIVE}. (com.linkedin.kafka.cruisecontrol.monitor.LoadMonitor)
[2025-07-23 18:50:25,870] INFO Initializing RackAwareGoal with racks [kafka] (by broker {1=kafka}) (com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal)
[2025-07-23 18:50:25,873] INFO Max replica load per broker for resource disk in MiB is: [1=0.25968560576438904] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:50:25,874] INFO Max replica load per broker for resource networkInbound in KiB/s is: [1=0.005151037126779556] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:50:25,875] INFO Max replica load per broker for resource networkOutbound in KiB/s is: [1=0.00656840018928051] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:50:25,876] INFO Max replica load per broker for resource replicationInbound in KiB/s is: [1=0.0] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:50:25,876] INFO Max replica load per broker for resource produceInbound in KiB/s is: [1=0.005151037126779556] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:50:25,877] INFO Initiated ReplicaDistributionGoal with lower limit 51 and upper limit 79 (isTriggeredByGoalViolation true) (com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaDistributionAbstractGoal)
[2025-07-23 18:50:25,878] INFO Initiated DiskUsageDistributionGoal with cluster percentage thresholds (Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%) and cell percentage thresholds [Cell -1(Resource Percentage Thresholds for disk - low utilization 20.00%, mean utilization - 0.00%, lower and upper limits - 0.00% and 0.00%), ] where the brokers spread across cells is [Cell(id=-1, brokers=[1]), ] and absolute thresholds per cell are [Cell -1(Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.62, lower limit: 0.49, upper limit: 0.75), ] as part of evaluating whether to trigger the even-cluster load task (all distribution statistics per cell are [ResourceDistributionStatsSnapshot{minBrokerResourceUnderLowerLimitOpt=null, maxBrokerResourceOverUpperLimitOpt=null, numBrokersUnderLowUtilizationThreshold=1, cellId=-1, resourceValueThresholds=Resource Value Thresholds for disk - low utilization threshold 41990.89, mean utilization threshold 0.62, lower limit: 0.49, upper limit: 0.75}, ]) (com.linkedin.kafka.cruisecontrol.analyzer.goals.util.ResourceDistributionLogger)
[2025-07-23 18:50:25,879] INFO Max replica load per broker for resource disk in MiB is: [1=0.25968560576438904] (com.linkedin.kafka.cruisecontrol.analyzer.goals.GoalUtils)
[2025-07-23 18:50:25,879] INFO Goal violation detector did not detect any violated goals. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:50:25,879] INFO Goal violation detection finished. (com.linkedin.kafka.cruisecontrol.detector.GoalViolationDetector)
[2025-07-23 18:50:43,545] INFO [CelltControllerMetricsPublisher id=1] No cells found. Skipping cell metrics refresh. (org.apache.kafka.controller.metrics.CellControllerMetricsPublisher)
[2025-07-23 18:50:43,694] INFO [ControllerServer id=1] In the last 60000 ms period, 329 controller events were completed, which took an average of 10.78 ms each. The slowest event was writeNoOpRecord(1047263922), which took 53.98 ms. (org.apache.kafka.controller.EventPerformanceMonitor)
[2025-07-23 18:50:43,901] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:50:43,901] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-07-23 18:50:43,902] INFO [ControllerServer id=1] CreateTopics result(s): CreatableTopic(name='_confluent-link-metadata', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='min.insync.replicas', value='2')], linkName=null, mirrorTopic=null, sourceTopicId=AAAAAAAAAAAAAAAAAAAAAA, mirrorStartOffsetSpec=-9223372036854775808, mirrorStartOffsets=[], stoppedSequenceNumber=0): INVALID_REPLICATION_FACTOR (Unable to replicate the partition 3 time(s): The target replication factor of 3 cannot be reached because only 1 broker(s) are registered.) (org.apache.kafka.controller.ReplicationControlManager)
[2025-07-23 18:50:59,998] INFO Beginning to sample MetricsWindow{sizeMs=180000, startMs=1753296480000, endMs=1753296660000, endMsInclusive=1753296659999, index=9740537, baseTimestamp=0}(18:48:00 - 18:50:59.999) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:51:00,041] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,041] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,041] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,041] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 6510 for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 6594 for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,042] INFO [Consumer clientId=kafka-cruise-control, groupId=ConfluentTelemetryReporterSampler--5988689947570755077] Seeking to offset 0 for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-07-23 18:51:00,081] INFO Finished sampling for 12 partitions - processed 306 metrics over 1 polls for the time range [18:48:00,18:50:59.999], with 306 of them added to the metrics processor, having the following distribution {ALL_TOPIC_MESSAGES_IN_PER_SEC=3, ALL_TOPIC_FETCH_FROM_FOLLOWER_BYTES_OUT=3, PARTITION_SIZE=198, ALL_TOPIC_FETCH_REQUEST_RATE=3, TOPIC_BYTES_OUT=12, TOPIC_BYTES_IN=12, TOPIC_FETCH_REQUEST_RATE=12, ALL_TOPIC_BYTES_OUT=3, BROKER_CPU_UTIL=3, ALL_TOPIC_REPLICATION_BYTES_IN=3, TOPIC_MESSAGES_IN_PER_SEC=12, ALL_TOPIC_BYTES_IN=3, ALL_TOPIC_REPLICATION_BYTES_OUT=3, BROKER_DISK_CAPACITY=3, BROKER_CONSUME_CAPACITY=3, ALL_TOPIC_FOLLOWER_FETCH_REQUEST_RATE=3, ALL_MIRROR_TOPIC_BYTES_IN=3, BROKER_PRODUCE_MIRROR_CAPACITY=3, TOPIC_PRODUCE_REQUEST_RATE=12, BROKER_PRODUCE_REQUEST_RATE=3, ALL_TOPIC_PRODUCE_REQUEST_RATE=3, BROKER_CONSUMER_FETCH_REQUEST_RATE=3},  0 of them being later than the desired end time and 0 being earlier than the desired start time. (io.confluent.cruisecontrol.metricsreporter.ConfluentMetricsSamplerBase)
[2025-07-23 18:51:00,092] INFO Generated 65 replica metrics samples, 65 partition metric samples from time 18:48:44.118 to 18:50:44.215 (1753296524118 to 1753296644215). (com.linkedin.kafka.cruisecontrol.monitor.sampling.CruiseControlMetricsProcessor)
[2025-07-23 18:51:00,097] INFO Collected 65 (0 discarded, 65 added) replica metric samples for 65 replicas. Total partition assigned: 65. Total unrecognized replicas: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:51:00,097] INFO Collected 65 (0 discarded, 65 added) partition metric samples for 65 partitions. Total partition assigned: 65. Total unrecognized partitions: 0 (com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricFetcherManager)
[2025-07-23 18:51:00,098] INFO REPLICA Aggregator rolled out a new window, reset 1 windows and bumped generation from 42->43,current window range [1753294500000, 1753296660000, 18:15:00 to 18:51:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:51:00,098] INFO PARTITION Aggregator rolled out a new window, reset 1 windows and bumped generation from 42->43,current window range [1753294500000, 1753296660000, 18:15:00 to 18:51:00],abandon 65 samples. (com.linkedin.cruisecontrol.monitor.sampling.aggregator.MetricSampleAggregator)
[2025-07-23 18:51:00,098] INFO Successfully finished metric sampling for time period 18:48:00 to 18:50:59.999 (1753296480000 to 1753296659999). (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
[2025-07-23 18:51:00,098] INFO Sleeping the SamplingScheduler until 18:53:59.999 (for 179901ms) as instructed due to reason The last eligible window for sampling was already sampled. Sleeping until the end of the current window...  (lastSampledWindow: (index: 9740537, 18:48:00 - 18:50:59.999), currentWindow: (index: 9740538, 18:51:00 - 18:53:59.999)) (com.linkedin.kafka.cruisecontrol.monitor.task.MetricSamplingTask)
^C%