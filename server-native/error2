===> Launching kafka ...
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/share/java/kafka/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/share/java/confluent-metadata-service/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/share/java/ce-kafka-rest-servlet/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/share/java/ce-kafka-rest-extensions/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/share/java/confluent-security/kafka-rest/log4j-slf4j-impl-2.24.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
[2025-06-09 19:34:57,198] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-06-09 19:34:58,056] INFO KafkaConfig values:
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = PLAINTEXT://localhost:29092,PLAINTEXT_HOST://localhost:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
	broker.rack = null
	broker.session.timeout.ms = 9000
	broker.session.uuid = GwXCsAj0RRqEIfy8wh6Zwg
	client.quota.callback.class = null
	client.quota.max.throttle.time.in.response.ms = 60000
	client.quota.max.throttle.time.ms = 5000
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	confluent.accp.enabled = false
	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
	confluent.alter.broker.health.max.demoted.brokers = 2147483647
	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
	confluent.ansible.managed = false
	confluent.api.visibility = DEFAULT
	confluent.append.record.interceptor.classes = []
	confluent.apply.create.topic.policy.to.create.partitions = false
	confluent.authorizer.authority.name =
	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
	confluent.backpressure.disk.enable = false
	confluent.backpressure.disk.free.threshold.bytes = 21474836480
	confluent.backpressure.disk.produce.bytes.per.second = 131072
	confluent.backpressure.disk.threshold.recovery.factor = 1.5
	confluent.backpressure.request.min.broker.limit = 200
	confluent.backpressure.request.queue.size.percentile = p95
	confluent.backpressure.types = null
	confluent.balancer.api.state.topic = _confluent_balancer_api_state
	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
	confluent.balancer.capacity.threshold.upper.limit = 0.95
	confluent.balancer.cell.load.upper.bound = 0.7
	confluent.balancer.cell.overload.detection.interval.ms = 3600000
	confluent.balancer.cell.overload.duration.ms = 86400000
	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.cpu.balance.threshold = 1.1
	confluent.balancer.cpu.goal.act.as.capacity.goal = false
	confluent.balancer.cpu.low.utilization.threshold = 0.2
	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
	confluent.balancer.disk.max.load = 0.85
	confluent.balancer.disk.min.free.space.gb = 0
	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
	confluent.balancer.disk.utilization.detector.duration.ms = 600000
	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
	confluent.balancer.enable = false
	confluent.balancer.enable.network.capacity.metric.ingestion = false
	confluent.balancer.exclude.topic.names = []
	confluent.balancer.exclude.topic.prefixes = []
	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	confluent.balancer.incremental.balancing.enabled = false
	confluent.balancer.incremental.balancing.goals = []
	confluent.balancer.incremental.balancing.lower.bound = 0.02
	confluent.balancer.incremental.balancing.min.valid.windows = 5
	confluent.balancer.incremental.balancing.step.ratio = 0.2
	confluent.balancer.inter.cell.balancing.enabled = false
	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
	confluent.balancer.max.replicas = 2147483647
	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.rebalancing.goals = []
	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.resource.utilization.detector.interval.ms = 60000
	confluent.balancer.sbc.metrics.parser.enabled = false
	confluent.balancer.self.healing.maximum.rounds = 1
	confluent.balancer.task.history.retention.days = 30
	confluent.balancer.tenant.maximum.movements = 0
	confluent.balancer.tenant.suspension.ms = 86400000
	confluent.balancer.throttle.bytes.per.second = 10485760
	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
	confluent.balancer.topic.partition.maximum.movements = 3
	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
	confluent.balancer.topic.partition.movements.history.limit = 900
	confluent.balancer.topic.partition.suspension.ms = 3600000
	confluent.balancer.topic.replication.factor = 1
	confluent.balancer.triggering.goals = []
	confluent.balancer.v2.addition.enabled = false
	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
	confluent.balancer.v2.executor.enabled = false
	confluent.basic.auth.credentials.source = null
	confluent.basic.auth.user.info = null
	confluent.bearer.assertion.claim.aud = null
	confluent.bearer.assertion.claim.exp.minutes = null
	confluent.bearer.assertion.claim.iss = null
	confluent.bearer.assertion.claim.jti.include = null
	confluent.bearer.assertion.claim.nbf.include = null
	confluent.bearer.assertion.claim.sub = null
	confluent.bearer.assertion.file = null
	confluent.bearer.assertion.private.key.file = null
	confluent.bearer.assertion.private.key.passphrase = null
	confluent.bearer.assertion.template.file = null
	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
	confluent.bearer.auth.client.id = null
	confluent.bearer.auth.client.secret = null
	confluent.bearer.auth.credentials.source = null
	confluent.bearer.auth.identity.pool.id = null
	confluent.bearer.auth.issuer.endpoint.url = null
	confluent.bearer.auth.logical.cluster = null
	confluent.bearer.auth.scope = null
	confluent.bearer.auth.scope.claim.name = scope
	confluent.bearer.auth.sub.claim.name = sub
	confluent.bearer.auth.token = null
	confluent.broker.health.manager.enabled = true
	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
	confluent.broker.health.manager.hard.kill.duration.ms = 60000
	confluent.broker.health.manager.mitigation.enabled = false
	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
	confluent.broker.health.manager.sample.duration.ms = 1000
	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
	confluent.broker.load.advertised.limit.load = 0.8
	confluent.broker.load.average.service.request.time.ms = 0.1
	confluent.broker.load.delay.metric.start.ms = 180000
	confluent.broker.load.enabled = false
	confluent.broker.load.num.samples = 60
	confluent.broker.load.tenant.metric.enable = false
	confluent.broker.load.update.metric.tags.interval.ms = 60000
	confluent.broker.load.window.size.ms = 60000
	confluent.broker.load.workload.coefficient = 20.0
	confluent.broker.registration.delay.ms = 0
	confluent.calling.resource.identity.type.map =
	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
	confluent.catalog.collector.enable = false
	confluent.catalog.collector.full.configs.enable = false
	confluent.catalog.collector.max.bytes.per.snapshot = 850000
	confluent.catalog.collector.max.topics.process = 500
	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
	confluent.catalog.collector.multitenant.topics.enable = true
	confluent.catalog.collector.snapshot.init.delay.sec = 60
	confluent.catalog.collector.snapshot.interval.sec = 300
	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
	confluent.cdc.api.keys.topic =
	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
	confluent.cdc.client.quotas.enable = false
	confluent.cdc.client.quotas.topic.name =
	confluent.cdc.lkc.metadata.topic =
	confluent.cdc.user.metadata.enable = false
	confluent.cdc.user.metadata.topic = _confluent-user_metadata
	confluent.cell.metrics.refresh.period.ms = 60000
	confluent.cells.default.size = 15
	confluent.cells.enable = false
	confluent.cells.implicit.creation.enable = false
	confluent.cells.k2.base.broker.index = -1
	confluent.cells.load.refresher.enable = true
	confluent.cells.max.size = 15
	confluent.cells.min.size = 6
	confluent.checksum.enabled.files = [none]
	confluent.client.topic.max.metrics.count = 1000
	confluent.client.topic.metrics.expiry.sec = 3600
	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
	confluent.clm.enabled = false
	confluent.clm.frequency.in.hours = 6
	confluent.clm.list.object.thread_pool.size = 1
	confluent.clm.max.backup.days = 3
	confluent.clm.min.delay.in.minutes = 30
	confluent.clm.thread.pool.size = 2
	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
	confluent.close.connections.on.credential.delete = false
	confluent.cluster.link.admin.max.in.flight.requests = 1000
	confluent.cluster.link.admin.request.batch.size = 1
	confluent.cluster.link.allow.config.providers = true
	confluent.cluster.link.allow.legacy.message.format = false
	confluent.cluster.link.allow.truncation.below.hwm = false
	confluent.cluster.link.availability.check.mode = ALL
	confluent.cluster.link.background.thread.affinity = LINK
	confluent.cluster.link.bootstrap.translation.feature.enable = true
	confluent.cluster.link.clients.max.idle.ms = 3153600000000
	confluent.cluster.link.enable = true
	confluent.cluster.link.enable.local.admin = false
	confluent.cluster.link.enable.metrics.reduction = false
	confluent.cluster.link.enable.metrics.reduction.advanced = false
	confluent.cluster.link.fetch.response.min.bytes = 1
	confluent.cluster.link.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.fetcher.auto.tune.enable = false
	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
	confluent.cluster.link.insync.fetch.response.min.bytes = 1
	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
	confluent.cluster.link.intranet.connectivity.enable = false
	confluent.cluster.link.intranet.connectivity.migration.enable = false
	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
	confluent.cluster.link.local.admin.multitenant.enable = false
	confluent.cluster.link.local.reverse.connection.listener.map = null
	confluent.cluster.link.max.client.connections = 2147483647
	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
	confluent.cluster.link.metadata.topic.enable = false
	confluent.cluster.link.metadata.topic.min.isr = 2
	confluent.cluster.link.metadata.topic.partitions = 50
	confluent.cluster.link.metadata.topic.replication.factor = 1
	confluent.cluster.link.mirror.transition.batch.size = 10
	confluent.cluster.link.num.background.threads = 1
	confluent.cluster.link.periodic.task.batch.size = 2147483647
	confluent.cluster.link.periodic.task.min.interval.ms = 1000
	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
	confluent.cluster.link.replica.fetch.connections.mode = combined
	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
	confluent.cluster.link.replication.quota.mode.per.tenant.overrides =
	confluent.cluster.link.replication.quota.window.num = 11
	confluent.cluster.link.replication.quota.window.size.seconds = 2
	confluent.cluster.link.request.quota.capacity = 400
	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
	confluent.cluster.link.switchover.disabled.principals = []
	confluent.cluster.link.switchover.enable = false
	confluent.cluster.link.switchover.listeners = []
	confluent.cluster.link.switchover.server.states = []
	confluent.cluster.link.tenant.replication.quota.enable = false
	confluent.cluster.link.tenant.request.quota.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
	confluent.cluster.metadata.snapshot.tier.upload.enable = false
	confluent.compacted.topic.prefer.tier.fetch.ms = -1
	confluent.connection.invalid.request.delay.enable = false
	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
	confluent.consumer.fetch.partition.pruning.enable = true
	confluent.consumer.lag.emitter.enabled = false
	confluent.consumer.lag.emitter.interval.ms = 60000
	confluent.dataflow.policy.watch.monitor.ms = 300000
	confluent.default.data.policy.enforcement = true
	confluent.defer.isr.shrink.enable = false
	confluent.describe.topic.partitions.enabled = true
	confluent.disk.io.manager.enable = false
	confluent.disk.throughput.headroom = 10485760
	confluent.disk.throughput.limit = 10485760000
	confluent.disk.throughput.quota.tier.archive = 1048576000
	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
	confluent.durability.audit.batch.flush.frequency.ms = 900000
	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
	confluent.durability.audit.enable = false
	confluent.durability.audit.idempotent.producer = false
	confluent.durability.audit.initial.job.delay.ms = 900000
	confluent.durability.audit.io.bytes.per.sec = 10485760
	confluent.durability.audit.log.ignored.event.types =
	confluent.durability.audit.reporting.batch.ms = 1800000
	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
	confluent.durability.topic.partition.count = 50
	confluent.durability.topic.replication.factor = 1
	confluent.e2e_checksum.protection.enabled = false
	confluent.e2e_checksum.protection.files = [none]
	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
	confluent.elastic.cku.enabled = false
	confluent.elastic.cku.scaletozero.enabled = false
	confluent.eligible.controllers = []
	confluent.enable.broker.reporting.min.usage.mode = true
	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.fail.unsatisfied.placement.constraints = false
	confluent.fetch.from.follower.require.leader.epoch.enable = false
	confluent.fetch.partition.pruning.enable = true
	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
	confluent.flexible.fanout.enabled = false
	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
	confluent.flexible.fanout.mode = TENANT_QUOTA
	confluent.floor.connection.rate.per.ip = -1.0
	confluent.floor.connection.rate.per.tenant = -1.0
	confluent.group.coordinator.dynamic.append.linger.enable = false
	confluent.group.coordinator.offsets.batching.enable = false
	confluent.group.coordinator.offsets.writer.threads = 2
	confluent.group.coordinator.txn.offset.validation.enable = false
	confluent.group.highest.offset.commit.rates.log.count = 10
	confluent.group.highest.offset.commit.rates.log.enable = false
	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
	confluent.group.metadata.load.threads = 32
	confluent.group.subscription.pattern.log.interval.ms = -1
	confluent.heap.tenured.notify.bytes = 0
	confluent.heap.tenured.notify.enabled = false
	confluent.hot.partition.ratio = 0.8
	confluent.http.server.start.timeout.ms = 60000
	confluent.http.server.stop.timeout.ms = 30000
	confluent.internal.metrics.enable = false
	confluent.internal.rest.server.bind.port = null
	confluent.internal.rest.server.ssl.enable = false
	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
	confluent.leader.epoch.checkpoint.checksum.enabled = false
	confluent.listener.protocol = TCP
	confluent.log.cleaner.timestamp.validation.enable = true
	confluent.log.placement.constraints =
	confluent.max.broker.load = 1.0
	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
	confluent.max.connection.rate.per.ip = -1.0
	confluent.max.connection.rate.per.tenant = -1.0
	confluent.max.connection.throttle.ms = null
	confluent.max.segment.ms = 9223372036854775807
	confluent.metadata.active.encryptor = null
	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
	confluent.metadata.encryptor.classes = null
	confluent.metadata.encryptor.required = false
	confluent.metadata.encryptor.secret.file = null
	confluent.metadata.encryptor.secrets = null
	confluent.metadata.jvm.warmup.ms = 60000
	confluent.metadata.leader.balance.slice.delay.ms = 100
	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
	confluent.metadata.max.leader.balance.changes.per.slice = 1000
	confluent.metadata.reject.when.throttled.enable = false
	confluent.metadata.server.cluster.registry.clusters = []
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.min.acks = 0
	confluent.min.connection.throttle.ms = 0
	confluent.min.segment.ms = 1
	confluent.missing.id.cache.ttl.sec = 60
	confluent.missing.id.query.range = 20000
	confluent.missing.schema.cache.ttl.sec = 60
	confluent.mtls.build.client.cert.chain.enable = false
	confluent.mtls.enable = false
	confluent.mtls.listener.name = EXTERNAL
	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
	confluent.mtls.truststore.manager.class.name = null
	confluent.multitenant.authorizer.enable.acl.state = false
	confluent.multitenant.interceptor.balancer.apis.enabled = false
	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
	confluent.multitenant.listener.names = null
	confluent.multitenant.parse.lkc.id.enable = false
	confluent.multitenant.parse.sni.host.name.enable = false
	confluent.network.health.manager.enabled = false
	confluent.network.health.manager.external.listener.name = EXTERNAL
	confluent.network.health.manager.externalconnectivitystartup.enabled = false
	confluent.network.health.manager.min.healthy.network.samples = 3
	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
	confluent.network.health.manager.mitigation.enabled = false
	confluent.network.health.manager.network.sample.window.size = 120
	confluent.network.health.manager.sample.duration.ms = 1000
	confluent.oauth.flat.networking.verification.enable = false
	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
	confluent.offsets.topic.placement.constraints =
	confluent.omit.network.processor.metric.tag = false
	confluent.operator.managed = false
	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings =
	confluent.ppv2.endpoint.scheme.enable = false
	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
	confluent.ppv2.endpoint.scheme.template.variable.cloud =
	confluent.ppv2.endpoint.scheme.template.variable.domain =
	confluent.ppv2.endpoint.scheme.template.variable.region =
	confluent.ppv2.endpoint.scheme.template.variables =
	confluent.ppv2.endpoint.scheme.templates =
	confluent.prefer.tier.fetch.ms = -1
	confluent.produce.throttle.pre.check.enable = false
	confluent.produce.throttle.pre.check.for.new.connection.enable = false
	confluent.producer.id.cache.broker.hard.limit = -1
	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
	confluent.producer.id.cache.extra.eviction.percentage = 0
	confluent.producer.id.cache.limit = 2147483647
	confluent.producer.id.cache.partition.hard.limit = -1
	confluent.producer.id.cache.tenant.hard.limit = -1
	confluent.producer.id.quota.manager.enable = false
	confluent.producer.id.quota.window.num = 11
	confluent.producer.id.quota.window.size.seconds = 1
	confluent.producer.id.throttle.enable = false
	confluent.producer.id.throttle.enable.threshold.percentage = 100
	confluent.proxy.mode.local.default = false
	confluent.proxy.protocol.fallback.enabled = false
	confluent.proxy.protocol.version = NONE
	confluent.quota.computing.usage.adjustment = 0.5
	confluent.quota.dynamic.adjustment.min.usage = 102400
	confluent.quota.dynamic.enable = false
	confluent.quota.dynamic.publishing.interval.ms = 60000
	confluent.quota.dynamic.reporting.interval.ms = 30000
	confluent.quota.tenant.broker.max.consumer.rate = 13107200
	confluent.quota.tenant.broker.max.producer.rate = 13107200
	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
	confluent.quota.tenant.fetch.multiplier = 1.0
	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
	confluent.quota.tenant.internal.throttling.enable = false
	confluent.quota.tenant.produce.multiplier = 1.0
	confluent.quota.tenant.user.quotas.enable = false
	confluent.rack.id.mapping = null
	confluent.regional.metadata.client.class = null
	confluent.regional.resource.manager.client.scheduler.threads = 2
	confluent.regional.resource.manager.endpoint = null
	confluent.regional.resource.manager.watch.endpoint = null
	confluent.replica.fetch.backoff.max.ms = 1000
	confluent.replica.fetch.connections.mode = combined
	confluent.replication.mode = PULL
	confluent.replication.push.feature.enable = false
	confluent.reporters.telemetry.auto.enable = true
	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
	confluent.request.pipelining.enable = true
	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
	confluent.require.calling.resource.identity = false
	confluent.require.compatible.keystore.updates = true
	confluent.require.confluent.issuer = false
	confluent.roll.check.interval.ms = 300000
	confluent.schema.registry.max.cache.size = 10000
	confluent.schema.registry.max.retries = 1
	confluent.schema.registry.retries.wait.ms = 0
	confluent.schema.registry.url = null
	confluent.schema.validation.context.name.enable = false
	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
	confluent.schema.validator.multitenant.enable = false
	confluent.schema.validator.samples.per.min = 0
	confluent.security.bc.approved.mode.enable = false
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.config =
	confluent.security.revoked.certificate.ids =
	confluent.segment.eager.roll.enable = false
	confluent.segment.speculative.prefetch.enable = false
	confluent.share.metadata.load.threads = 32
	confluent.spiffe.id.principal.extraction.rules =
	confluent.ssl.key.password = null
	confluent.ssl.keystore.location = null
	confluent.ssl.keystore.password = null
	confluent.ssl.keystore.type = null
	confluent.ssl.protocol = null
	confluent.ssl.truststore.location = null
	confluent.ssl.truststore.password = null
	confluent.ssl.truststore.type = null
	confluent.step.connection.rate.per.ip = -1.0
	confluent.step.connection.rate.per.tenant = -1.0
	confluent.storage.probe.period.ms = -1
	confluent.storage.probe.slow.write.threshold.ms = 5000
	confluent.stray.log.delete.delay.ms = 604800000
	confluent.stray.log.max.deletions.per.run = 72
	confluent.subdomain.prefix = null
	confluent.subdomain.separator.map = null
	confluent.subdomain.separator.variable = %sep
	confluent.system.time.roll.enable = false
	confluent.telemetry.enabled = false
	confluent.telemetry.external.client.metrics.delta.temporality = true
	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
	confluent.telemetry.external.client.metrics.push.enabled = false
	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
	confluent.telemetry.external.client.metrics.subscription.match.list = null
	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
	confluent.tenant.latency.metric.enabled = false
	confluent.tenantaware.encryption.key.manager.enable = false
	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
	confluent.tier.archiver.num.threads = 2
	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
	confluent.tier.azure.block.blob.container = null
	confluent.tier.azure.block.blob.cred.file.path = null
	confluent.tier.azure.block.blob.endpoint = null
	confluent.tier.azure.block.blob.prefix =
	confluent.tier.backend =
	confluent.tier.bucket.probe.period.ms = -1
	confluent.tier.cleaner.compact.min.efficiency = 0.5
	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
	confluent.tier.cleaner.dedupe.buffer.size = 134217728
	confluent.tier.cleaner.dual.compaction = false
	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
	confluent.tier.cleaner.dual.compaction.validation.percent = 0
	confluent.tier.cleaner.enable = false
	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
	confluent.tier.cleaner.feature.enable = false
	confluent.tier.cleaner.io.buffer.load.factor = 0.9
	confluent.tier.cleaner.io.buffer.size = 10485760
	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	confluent.tier.cleaner.min.cleanable.ratio = 0.75
	confluent.tier.cleaner.num.threads = 2
	confluent.tier.enable = false
	confluent.tier.feature = false
	confluent.tier.fenced.segment.delete.delay.ms = 600000
	confluent.tier.fetcher.async.enable = false
	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
	confluent.tier.fetcher.memorypool.bytes = 0
	confluent.tier.fetcher.num.threads = 4
	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
	confluent.tier.fetcher.offset.cache.period.ms = 60000
	confluent.tier.fetcher.offset.cache.size = 200000
	confluent.tier.gcs.bucket = null
	confluent.tier.gcs.cred.file.path = null
	confluent.tier.gcs.prefix =
	confluent.tier.gcs.region = null
	confluent.tier.gcs.sse.customer.encryption.key = null
	confluent.tier.gcs.write.chunk.size = 0
	confluent.tier.local.hotset.bytes = -1
	confluent.tier.local.hotset.ms = 86400000
	confluent.tier.max.partition.fetch.bytes.override = 0
	confluent.tier.metadata.bootstrap.servers = null
	confluent.tier.metadata.max.poll.ms = 100
	confluent.tier.metadata.namespace = null
	confluent.tier.metadata.num.partitions = 50
	confluent.tier.metadata.replication.factor = 1
	confluent.tier.metadata.request.timeout.ms = 30000
	confluent.tier.metadata.snapshots.enable = false
	confluent.tier.metadata.snapshots.interval.ms = 86400000
	confluent.tier.metadata.snapshots.retention.days = 7
	confluent.tier.metadata.snapshots.threads = 2
	confluent.tier.object.fetcher.num.threads = 1
	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
	confluent.tier.partition.state.cleanup.enable = false
	confluent.tier.partition.state.cleanup.interval.ms = 86400000
	confluent.tier.partition.state.commit.interval.ms = 15000
	confluent.tier.prefetch.cache.enable = false
	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
	confluent.tier.prefetch.cache.range.bytes = 5242880
	confluent.tier.prefetch.cache.total.size.bytes = 209715200
	confluent.tier.s3.assumerole.arn = null
	confluent.tier.s3.auto.abort.threshold.bytes = 500000
	confluent.tier.s3.aws.endpoint.override = null
	confluent.tier.s3.aws.signer.override = null
	confluent.tier.s3.bucket = null
	confluent.tier.s3.cred.file.path = null
	confluent.tier.s3.force.path.style.access = false
	confluent.tier.s3.ipv6.enabled = true
	confluent.tier.s3.prefix =
	confluent.tier.s3.region = null
	confluent.tier.s3.security.providers = null
	confluent.tier.s3.sse.algorithm = AES256
	confluent.tier.s3.sse.customer.encryption.key = null
	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.tier.s3.ssl.key.password = null
	confluent.tier.s3.ssl.keystore.location = null
	confluent.tier.s3.ssl.keystore.password = null
	confluent.tier.s3.ssl.keystore.type = null
	confluent.tier.s3.ssl.protocol = TLSv1.3
	confluent.tier.s3.ssl.provider = null
	confluent.tier.s3.ssl.truststore.location = null
	confluent.tier.s3.ssl.truststore.password = null
	confluent.tier.s3.ssl.truststore.type = null
	confluent.tier.s3.storage.class.override =
	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
	confluent.tier.s3.v2.enabled = false
	confluent.tier.segment.hotset.roll.min.bytes = 104857600
	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
	confluent.tier.topic.data.loss.validation.fencing.enable = false
	confluent.tier.topic.delete.backoff.ms = 21600000
	confluent.tier.topic.delete.check.interval.ms = 300000
	confluent.tier.topic.delete.max.inprogress.partitions = 100
	confluent.tier.topic.head.data.loss.validation.enable = true
	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
	confluent.tier.topic.materialization.from.snapshot.enable = false
	confluent.tier.topic.producer.enable.idempotence = true
	confluent.tier.topic.snapshots.enable = false
	confluent.tier.topic.snapshots.interval.ms = 300000
	confluent.tier.topic.snapshots.max.records = 100000
	confluent.tier.topic.snapshots.retention.hours = 168
	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
	confluent.topic.partition.default.placement = 2
	confluent.topic.policy.use.computed.assignments = false
	confluent.topic.replica.assignor.builder.class =
	confluent.track.api.key.per.ip = false
	confluent.track.per.ip.max.size = 100000
	confluent.track.tenant.id.per.ip = false
	confluent.traffic.cdc.network.id.routes.enable = false
	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
	confluent.traffic.network.id =
	confluent.traffic.network.type =
	confluent.transaction.2pc.timeout.ms = -1
	confluent.transaction.logging.verbosity = 0
	confluent.transaction.state.log.placement.constraints =
	confluent.unique.deprecated.request.metrics.per.tenant = 1000
	confluent.valid.broker.rack.set = null
	confluent.valid.sni.hostnames =
	confluent.valid.sni.hostnames.exclude.suffix =
	confluent.verify.group.subscription.prefix = false
	confluent.virtual.topic.creation.enabled = false
	confluent.zone.tagged.request.metrics.enable = false
	connection.failed.authentication.delay.ms = 100
	connection.min.expire.interval.ms = 250
	connections.max.age.ms = 3153600000000
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:29093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.cluster.link.policy.class.name = null
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	enable.fips = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	floor.max.connection.creation.rate = null
	follower.replication.throttled.rate = 9223372036854775807
	follower.replication.throttled.replicas = none
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	k2.stack.builder.class.name = null
	k2.startup.timeout.ms = 60000
	k2.topic.metadata.refresh.ms = 10000
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.replication.throttled.rate = 9223372036854775807
	leader.replication.throttled.replicas = none
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
	listeners = PLAINTEXT://localhost:29092,CONTROLLER://localhost:29093,PLAINTEXT_HOST://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.hash.algorithm = MD5
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.cleanup.policy.empty.validation = none
	log.deletion.max.segments.per.run = 2147483647
	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 1.7976931348623157E308
	max.connection.creation.rate.per.ip.enable.threshold = 0.0
	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.connections.per.tenant = 0
	max.connections.protected.listeners = []
	max.connections.reap.amount = 0
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	multitenant.authorizer.support.resource.ids = false
	multitenant.metadata.class = null
	multitenant.metadata.dir = null
	multitenant.metadata.reload.delay.ms = 120000
	multitenant.metadata.ssl.certs.path = null
	multitenant.tenant.delete.batch.size = 10
	multitenant.tenant.delete.check.ms = 120000
	multitenant.tenant.delete.delay = 604800000
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	otel.exporter.otlp.custom.endpoint = default
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	quotas.consumption.expiration.time.ms = 600000
	quotas.expiration.interval.ms = 3600000
	quotas.expiration.time.ms = 604800000
	quotas.lazy.evaluation.threshold = 0.5
	quotas.topic.append.timeout.ms = 5000
	quotas.topic.compression.codec = 3
	quotas.topic.load.buffer.size = 5242880
	quotas.topic.num.partitions = 50
	quotas.topic.placement.constraints =
	quotas.topic.replication.factor = 3
	quotas.topic.segment.bytes = 104857600
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.authn.async.enable = false
	sasl.server.authn.async.max.threads = 1
	sasl.server.authn.async.timeout.ms = 30000
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	throughput.quota.window.num = 11
	token.impersonation.validation = true
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.metadata.load.threads = 32
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,095] INFO KafkaConfig values:
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = PLAINTEXT://localhost:29092,PLAINTEXT_HOST://localhost:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
	broker.rack = null
	broker.session.timeout.ms = 9000
	broker.session.uuid = GwXCsAj0RRqEIfy8wh6Zwg
	client.quota.callback.class = null
	client.quota.max.throttle.time.in.response.ms = 60000
	client.quota.max.throttle.time.ms = 5000
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	confluent.accp.enabled = false
	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
	confluent.alter.broker.health.max.demoted.brokers = 2147483647
	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
	confluent.ansible.managed = false
	confluent.api.visibility = DEFAULT
	confluent.append.record.interceptor.classes = []
	confluent.apply.create.topic.policy.to.create.partitions = false
	confluent.authorizer.authority.name =
	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
	confluent.backpressure.disk.enable = false
	confluent.backpressure.disk.free.threshold.bytes = 21474836480
	confluent.backpressure.disk.produce.bytes.per.second = 131072
	confluent.backpressure.disk.threshold.recovery.factor = 1.5
	confluent.backpressure.request.min.broker.limit = 200
	confluent.backpressure.request.queue.size.percentile = p95
	confluent.backpressure.types = null
	confluent.balancer.api.state.topic = _confluent_balancer_api_state
	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
	confluent.balancer.capacity.threshold.upper.limit = 0.95
	confluent.balancer.cell.load.upper.bound = 0.7
	confluent.balancer.cell.overload.detection.interval.ms = 3600000
	confluent.balancer.cell.overload.duration.ms = 86400000
	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.cpu.balance.threshold = 1.1
	confluent.balancer.cpu.goal.act.as.capacity.goal = false
	confluent.balancer.cpu.low.utilization.threshold = 0.2
	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
	confluent.balancer.disk.max.load = 0.85
	confluent.balancer.disk.min.free.space.gb = 0
	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
	confluent.balancer.disk.utilization.detector.duration.ms = 600000
	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
	confluent.balancer.enable = false
	confluent.balancer.enable.network.capacity.metric.ingestion = false
	confluent.balancer.exclude.topic.names = []
	confluent.balancer.exclude.topic.prefixes = []
	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	confluent.balancer.incremental.balancing.enabled = false
	confluent.balancer.incremental.balancing.goals = []
	confluent.balancer.incremental.balancing.lower.bound = 0.02
	confluent.balancer.incremental.balancing.min.valid.windows = 5
	confluent.balancer.incremental.balancing.step.ratio = 0.2
	confluent.balancer.inter.cell.balancing.enabled = false
	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
	confluent.balancer.max.replicas = 2147483647
	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.rebalancing.goals = []
	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.resource.utilization.detector.interval.ms = 60000
	confluent.balancer.sbc.metrics.parser.enabled = false
	confluent.balancer.self.healing.maximum.rounds = 1
	confluent.balancer.task.history.retention.days = 30
	confluent.balancer.tenant.maximum.movements = 0
	confluent.balancer.tenant.suspension.ms = 86400000
	confluent.balancer.throttle.bytes.per.second = 10485760
	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
	confluent.balancer.topic.partition.maximum.movements = 3
	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
	confluent.balancer.topic.partition.movements.history.limit = 900
	confluent.balancer.topic.partition.suspension.ms = 3600000
	confluent.balancer.topic.replication.factor = 1
	confluent.balancer.triggering.goals = []
	confluent.balancer.v2.addition.enabled = false
	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
	confluent.balancer.v2.executor.enabled = false
	confluent.basic.auth.credentials.source = null
	confluent.basic.auth.user.info = null
	confluent.bearer.assertion.claim.aud = null
	confluent.bearer.assertion.claim.exp.minutes = null
	confluent.bearer.assertion.claim.iss = null
	confluent.bearer.assertion.claim.jti.include = null
	confluent.bearer.assertion.claim.nbf.include = null
	confluent.bearer.assertion.claim.sub = null
	confluent.bearer.assertion.file = null
	confluent.bearer.assertion.private.key.file = null
	confluent.bearer.assertion.private.key.passphrase = null
	confluent.bearer.assertion.template.file = null
	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
	confluent.bearer.auth.client.id = null
	confluent.bearer.auth.client.secret = null
	confluent.bearer.auth.credentials.source = null
	confluent.bearer.auth.identity.pool.id = null
	confluent.bearer.auth.issuer.endpoint.url = null
	confluent.bearer.auth.logical.cluster = null
	confluent.bearer.auth.scope = null
	confluent.bearer.auth.scope.claim.name = scope
	confluent.bearer.auth.sub.claim.name = sub
	confluent.bearer.auth.token = null
	confluent.broker.health.manager.enabled = true
	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
	confluent.broker.health.manager.hard.kill.duration.ms = 60000
	confluent.broker.health.manager.mitigation.enabled = false
	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
	confluent.broker.health.manager.sample.duration.ms = 1000
	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
	confluent.broker.load.advertised.limit.load = 0.8
	confluent.broker.load.average.service.request.time.ms = 0.1
	confluent.broker.load.delay.metric.start.ms = 180000
	confluent.broker.load.enabled = false
	confluent.broker.load.num.samples = 60
	confluent.broker.load.tenant.metric.enable = false
	confluent.broker.load.update.metric.tags.interval.ms = 60000
	confluent.broker.load.window.size.ms = 60000
	confluent.broker.load.workload.coefficient = 20.0
	confluent.broker.registration.delay.ms = 0
	confluent.calling.resource.identity.type.map =
	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
	confluent.catalog.collector.enable = false
	confluent.catalog.collector.full.configs.enable = false
	confluent.catalog.collector.max.bytes.per.snapshot = 850000
	confluent.catalog.collector.max.topics.process = 500
	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
	confluent.catalog.collector.multitenant.topics.enable = true
	confluent.catalog.collector.snapshot.init.delay.sec = 60
	confluent.catalog.collector.snapshot.interval.sec = 300
	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
	confluent.cdc.api.keys.topic =
	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
	confluent.cdc.client.quotas.enable = false
	confluent.cdc.client.quotas.topic.name =
	confluent.cdc.lkc.metadata.topic =
	confluent.cdc.user.metadata.enable = false
	confluent.cdc.user.metadata.topic = _confluent-user_metadata
	confluent.cell.metrics.refresh.period.ms = 60000
	confluent.cells.default.size = 15
	confluent.cells.enable = false
	confluent.cells.implicit.creation.enable = false
	confluent.cells.k2.base.broker.index = -1
	confluent.cells.load.refresher.enable = true
	confluent.cells.max.size = 15
	confluent.cells.min.size = 6
	confluent.checksum.enabled.files = [none]
	confluent.client.topic.max.metrics.count = 1000
	confluent.client.topic.metrics.expiry.sec = 3600
	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
	confluent.clm.enabled = false
	confluent.clm.frequency.in.hours = 6
	confluent.clm.list.object.thread_pool.size = 1
	confluent.clm.max.backup.days = 3
	confluent.clm.min.delay.in.minutes = 30
	confluent.clm.thread.pool.size = 2
	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
	confluent.close.connections.on.credential.delete = false
	confluent.cluster.link.admin.max.in.flight.requests = 1000
	confluent.cluster.link.admin.request.batch.size = 1
	confluent.cluster.link.allow.config.providers = true
	confluent.cluster.link.allow.legacy.message.format = false
	confluent.cluster.link.allow.truncation.below.hwm = false
	confluent.cluster.link.availability.check.mode = ALL
	confluent.cluster.link.background.thread.affinity = LINK
	confluent.cluster.link.bootstrap.translation.feature.enable = true
	confluent.cluster.link.clients.max.idle.ms = 3153600000000
	confluent.cluster.link.enable = true
	confluent.cluster.link.enable.local.admin = false
	confluent.cluster.link.enable.metrics.reduction = false
	confluent.cluster.link.enable.metrics.reduction.advanced = false
	confluent.cluster.link.fetch.response.min.bytes = 1
	confluent.cluster.link.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.fetcher.auto.tune.enable = false
	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
	confluent.cluster.link.insync.fetch.response.min.bytes = 1
	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
	confluent.cluster.link.intranet.connectivity.enable = false
	confluent.cluster.link.intranet.connectivity.migration.enable = false
	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
	confluent.cluster.link.local.admin.multitenant.enable = false
	confluent.cluster.link.local.reverse.connection.listener.map = null
	confluent.cluster.link.max.client.connections = 2147483647
	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
	confluent.cluster.link.metadata.topic.enable = false
	confluent.cluster.link.metadata.topic.min.isr = 2
	confluent.cluster.link.metadata.topic.partitions = 50
	confluent.cluster.link.metadata.topic.replication.factor = 1
	confluent.cluster.link.mirror.transition.batch.size = 10
	confluent.cluster.link.num.background.threads = 1
	confluent.cluster.link.periodic.task.batch.size = 2147483647
	confluent.cluster.link.periodic.task.min.interval.ms = 1000
	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
	confluent.cluster.link.replica.fetch.connections.mode = combined
	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
	confluent.cluster.link.replication.quota.mode.per.tenant.overrides =
	confluent.cluster.link.replication.quota.window.num = 11
	confluent.cluster.link.replication.quota.window.size.seconds = 2
	confluent.cluster.link.request.quota.capacity = 400
	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
	confluent.cluster.link.switchover.disabled.principals = []
	confluent.cluster.link.switchover.enable = false
	confluent.cluster.link.switchover.listeners = []
	confluent.cluster.link.switchover.server.states = []
	confluent.cluster.link.tenant.replication.quota.enable = false
	confluent.cluster.link.tenant.request.quota.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
	confluent.cluster.metadata.snapshot.tier.upload.enable = false
	confluent.compacted.topic.prefer.tier.fetch.ms = -1
	confluent.connection.invalid.request.delay.enable = false
	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
	confluent.consumer.fetch.partition.pruning.enable = true
	confluent.consumer.lag.emitter.enabled = false
	confluent.consumer.lag.emitter.interval.ms = 60000
	confluent.dataflow.policy.watch.monitor.ms = 300000
	confluent.default.data.policy.enforcement = true
	confluent.defer.isr.shrink.enable = false
	confluent.describe.topic.partitions.enabled = true
	confluent.disk.io.manager.enable = false
	confluent.disk.throughput.headroom = 10485760
	confluent.disk.throughput.limit = 10485760000
	confluent.disk.throughput.quota.tier.archive = 1048576000
	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
	confluent.durability.audit.batch.flush.frequency.ms = 900000
	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
	confluent.durability.audit.enable = false
	confluent.durability.audit.idempotent.producer = false
	confluent.durability.audit.initial.job.delay.ms = 900000
	confluent.durability.audit.io.bytes.per.sec = 10485760
	confluent.durability.audit.log.ignored.event.types =
	confluent.durability.audit.reporting.batch.ms = 1800000
	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
	confluent.durability.topic.partition.count = 50
	confluent.durability.topic.replication.factor = 1
	confluent.e2e_checksum.protection.enabled = false
	confluent.e2e_checksum.protection.files = [none]
	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
	confluent.elastic.cku.enabled = false
	confluent.elastic.cku.scaletozero.enabled = false
	confluent.eligible.controllers = []
	confluent.enable.broker.reporting.min.usage.mode = true
	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.fail.unsatisfied.placement.constraints = false
	confluent.fetch.from.follower.require.leader.epoch.enable = false
	confluent.fetch.partition.pruning.enable = true
	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
	confluent.flexible.fanout.enabled = false
	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
	confluent.flexible.fanout.mode = TENANT_QUOTA
	confluent.floor.connection.rate.per.ip = -1.0
	confluent.floor.connection.rate.per.tenant = -1.0
	confluent.group.coordinator.dynamic.append.linger.enable = false
	confluent.group.coordinator.offsets.batching.enable = false
	confluent.group.coordinator.offsets.writer.threads = 2
	confluent.group.coordinator.txn.offset.validation.enable = false
	confluent.group.highest.offset.commit.rates.log.count = 10
	confluent.group.highest.offset.commit.rates.log.enable = false
	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
	confluent.group.metadata.load.threads = 32
	confluent.group.subscription.pattern.log.interval.ms = -1
	confluent.heap.tenured.notify.bytes = 0
	confluent.heap.tenured.notify.enabled = false
	confluent.hot.partition.ratio = 0.8
	confluent.http.server.start.timeout.ms = 60000
	confluent.http.server.stop.timeout.ms = 30000
	confluent.internal.metrics.enable = false
	confluent.internal.rest.server.bind.port = null
	confluent.internal.rest.server.ssl.enable = false
	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
	confluent.leader.epoch.checkpoint.checksum.enabled = false
	confluent.listener.protocol = TCP
	confluent.log.cleaner.timestamp.validation.enable = true
	confluent.log.placement.constraints =
	confluent.max.broker.load = 1.0
	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
	confluent.max.connection.rate.per.ip = -1.0
	confluent.max.connection.rate.per.tenant = -1.0
	confluent.max.connection.throttle.ms = null
	confluent.max.segment.ms = 9223372036854775807
	confluent.metadata.active.encryptor = null
	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
	confluent.metadata.encryptor.classes = null
	confluent.metadata.encryptor.required = false
	confluent.metadata.encryptor.secret.file = null
	confluent.metadata.encryptor.secrets = null
	confluent.metadata.jvm.warmup.ms = 60000
	confluent.metadata.leader.balance.slice.delay.ms = 100
	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
	confluent.metadata.max.leader.balance.changes.per.slice = 1000
	confluent.metadata.reject.when.throttled.enable = false
	confluent.metadata.server.cluster.registry.clusters = []
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.min.acks = 0
	confluent.min.connection.throttle.ms = 0
	confluent.min.segment.ms = 1
	confluent.missing.id.cache.ttl.sec = 60
	confluent.missing.id.query.range = 20000
	confluent.missing.schema.cache.ttl.sec = 60
	confluent.mtls.build.client.cert.chain.enable = false
	confluent.mtls.enable = false
	confluent.mtls.listener.name = EXTERNAL
	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
	confluent.mtls.truststore.manager.class.name = null
	confluent.multitenant.authorizer.enable.acl.state = false
	confluent.multitenant.interceptor.balancer.apis.enabled = false
	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
	confluent.multitenant.listener.names = null
	confluent.multitenant.parse.lkc.id.enable = false
	confluent.multitenant.parse.sni.host.name.enable = false
	confluent.network.health.manager.enabled = false
	confluent.network.health.manager.external.listener.name = EXTERNAL
	confluent.network.health.manager.externalconnectivitystartup.enabled = false
	confluent.network.health.manager.min.healthy.network.samples = 3
	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
	confluent.network.health.manager.mitigation.enabled = false
	confluent.network.health.manager.network.sample.window.size = 120
	confluent.network.health.manager.sample.duration.ms = 1000
	confluent.oauth.flat.networking.verification.enable = false
	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
	confluent.offsets.topic.placement.constraints =
	confluent.omit.network.processor.metric.tag = false
	confluent.operator.managed = false
	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings =
	confluent.ppv2.endpoint.scheme.enable = false
	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
	confluent.ppv2.endpoint.scheme.template.variable.cloud =
	confluent.ppv2.endpoint.scheme.template.variable.domain =
	confluent.ppv2.endpoint.scheme.template.variable.region =
	confluent.ppv2.endpoint.scheme.template.variables =
	confluent.ppv2.endpoint.scheme.templates =
	confluent.prefer.tier.fetch.ms = -1
	confluent.produce.throttle.pre.check.enable = false
	confluent.produce.throttle.pre.check.for.new.connection.enable = false
	confluent.producer.id.cache.broker.hard.limit = -1
	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
	confluent.producer.id.cache.extra.eviction.percentage = 0
	confluent.producer.id.cache.limit = 2147483647
	confluent.producer.id.cache.partition.hard.limit = -1
	confluent.producer.id.cache.tenant.hard.limit = -1
	confluent.producer.id.quota.manager.enable = false
	confluent.producer.id.quota.window.num = 11
	confluent.producer.id.quota.window.size.seconds = 1
	confluent.producer.id.throttle.enable = false
	confluent.producer.id.throttle.enable.threshold.percentage = 100
	confluent.proxy.mode.local.default = false
	confluent.proxy.protocol.fallback.enabled = false
	confluent.proxy.protocol.version = NONE
	confluent.quota.computing.usage.adjustment = 0.5
	confluent.quota.dynamic.adjustment.min.usage = 102400
	confluent.quota.dynamic.enable = false
	confluent.quota.dynamic.publishing.interval.ms = 60000
	confluent.quota.dynamic.reporting.interval.ms = 30000
	confluent.quota.tenant.broker.max.consumer.rate = 13107200
	confluent.quota.tenant.broker.max.producer.rate = 13107200
	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
	confluent.quota.tenant.fetch.multiplier = 1.0
	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
	confluent.quota.tenant.internal.throttling.enable = false
	confluent.quota.tenant.produce.multiplier = 1.0
	confluent.quota.tenant.user.quotas.enable = false
	confluent.rack.id.mapping = null
	confluent.regional.metadata.client.class = null
	confluent.regional.resource.manager.client.scheduler.threads = 2
	confluent.regional.resource.manager.endpoint = null
	confluent.regional.resource.manager.watch.endpoint = null
	confluent.replica.fetch.backoff.max.ms = 1000
	confluent.replica.fetch.connections.mode = combined
	confluent.replication.mode = PULL
	confluent.replication.push.feature.enable = false
	confluent.reporters.telemetry.auto.enable = true
	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
	confluent.request.pipelining.enable = true
	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
	confluent.require.calling.resource.identity = false
	confluent.require.compatible.keystore.updates = true
	confluent.require.confluent.issuer = false
	confluent.roll.check.interval.ms = 300000
	confluent.schema.registry.max.cache.size = 10000
	confluent.schema.registry.max.retries = 1
	confluent.schema.registry.retries.wait.ms = 0
	confluent.schema.registry.url = null
	confluent.schema.validation.context.name.enable = false
	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
	confluent.schema.validator.multitenant.enable = false
	confluent.schema.validator.samples.per.min = 0
	confluent.security.bc.approved.mode.enable = false
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.config =
	confluent.security.revoked.certificate.ids =
	confluent.segment.eager.roll.enable = false
	confluent.segment.speculative.prefetch.enable = false
	confluent.share.metadata.load.threads = 32
	confluent.spiffe.id.principal.extraction.rules =
	confluent.ssl.key.password = null
	confluent.ssl.keystore.location = null
	confluent.ssl.keystore.password = null
	confluent.ssl.keystore.type = null
	confluent.ssl.protocol = null
	confluent.ssl.truststore.location = null
	confluent.ssl.truststore.password = null
	confluent.ssl.truststore.type = null
	confluent.step.connection.rate.per.ip = -1.0
	confluent.step.connection.rate.per.tenant = -1.0
	confluent.storage.probe.period.ms = -1
	confluent.storage.probe.slow.write.threshold.ms = 5000
	confluent.stray.log.delete.delay.ms = 604800000
	confluent.stray.log.max.deletions.per.run = 72
	confluent.subdomain.prefix = null
	confluent.subdomain.separator.map = null
	confluent.subdomain.separator.variable = %sep
	confluent.system.time.roll.enable = false
	confluent.telemetry.enabled = false
	confluent.telemetry.external.client.metrics.delta.temporality = true
	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
	confluent.telemetry.external.client.metrics.push.enabled = false
	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
	confluent.telemetry.external.client.metrics.subscription.match.list = null
	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
	confluent.tenant.latency.metric.enabled = false
	confluent.tenantaware.encryption.key.manager.enable = false
	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
	confluent.tier.archiver.num.threads = 2
	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
	confluent.tier.azure.block.blob.container = null
	confluent.tier.azure.block.blob.cred.file.path = null
	confluent.tier.azure.block.blob.endpoint = null
	confluent.tier.azure.block.blob.prefix =
	confluent.tier.backend =
	confluent.tier.bucket.probe.period.ms = -1
	confluent.tier.cleaner.compact.min.efficiency = 0.5
	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
	confluent.tier.cleaner.dedupe.buffer.size = 134217728
	confluent.tier.cleaner.dual.compaction = false
	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
	confluent.tier.cleaner.dual.compaction.validation.percent = 0
	confluent.tier.cleaner.enable = false
	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
	confluent.tier.cleaner.feature.enable = false
	confluent.tier.cleaner.io.buffer.load.factor = 0.9
	confluent.tier.cleaner.io.buffer.size = 10485760
	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	confluent.tier.cleaner.min.cleanable.ratio = 0.75
	confluent.tier.cleaner.num.threads = 2
	confluent.tier.enable = false
	confluent.tier.feature = false
	confluent.tier.fenced.segment.delete.delay.ms = 600000
	confluent.tier.fetcher.async.enable = false
	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
	confluent.tier.fetcher.memorypool.bytes = 0
	confluent.tier.fetcher.num.threads = 4
	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
	confluent.tier.fetcher.offset.cache.period.ms = 60000
	confluent.tier.fetcher.offset.cache.size = 200000
	confluent.tier.gcs.bucket = null
	confluent.tier.gcs.cred.file.path = null
	confluent.tier.gcs.prefix =
	confluent.tier.gcs.region = null
	confluent.tier.gcs.sse.customer.encryption.key = null
	confluent.tier.gcs.write.chunk.size = 0
	confluent.tier.local.hotset.bytes = -1
	confluent.tier.local.hotset.ms = 86400000
	confluent.tier.max.partition.fetch.bytes.override = 0
	confluent.tier.metadata.bootstrap.servers = null
	confluent.tier.metadata.max.poll.ms = 100
	confluent.tier.metadata.namespace = null
	confluent.tier.metadata.num.partitions = 50
	confluent.tier.metadata.replication.factor = 1
	confluent.tier.metadata.request.timeout.ms = 30000
	confluent.tier.metadata.snapshots.enable = false
	confluent.tier.metadata.snapshots.interval.ms = 86400000
	confluent.tier.metadata.snapshots.retention.days = 7
	confluent.tier.metadata.snapshots.threads = 2
	confluent.tier.object.fetcher.num.threads = 1
	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
	confluent.tier.partition.state.cleanup.enable = false
	confluent.tier.partition.state.cleanup.interval.ms = 86400000
	confluent.tier.partition.state.commit.interval.ms = 15000
	confluent.tier.prefetch.cache.enable = false
	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
	confluent.tier.prefetch.cache.range.bytes = 5242880
	confluent.tier.prefetch.cache.total.size.bytes = 209715200
	confluent.tier.s3.assumerole.arn = null
	confluent.tier.s3.auto.abort.threshold.bytes = 500000
	confluent.tier.s3.aws.endpoint.override = null
	confluent.tier.s3.aws.signer.override = null
	confluent.tier.s3.bucket = null
	confluent.tier.s3.cred.file.path = null
	confluent.tier.s3.force.path.style.access = false
	confluent.tier.s3.ipv6.enabled = true
	confluent.tier.s3.prefix =
	confluent.tier.s3.region = null
	confluent.tier.s3.security.providers = null
	confluent.tier.s3.sse.algorithm = AES256
	confluent.tier.s3.sse.customer.encryption.key = null
	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.tier.s3.ssl.key.password = null
	confluent.tier.s3.ssl.keystore.location = null
	confluent.tier.s3.ssl.keystore.password = null
	confluent.tier.s3.ssl.keystore.type = null
	confluent.tier.s3.ssl.protocol = TLSv1.3
	confluent.tier.s3.ssl.provider = null
	confluent.tier.s3.ssl.truststore.location = null
	confluent.tier.s3.ssl.truststore.password = null
	confluent.tier.s3.ssl.truststore.type = null
	confluent.tier.s3.storage.class.override =
	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
	confluent.tier.s3.v2.enabled = false
	confluent.tier.segment.hotset.roll.min.bytes = 104857600
	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
	confluent.tier.topic.data.loss.validation.fencing.enable = false
	confluent.tier.topic.delete.backoff.ms = 21600000
	confluent.tier.topic.delete.check.interval.ms = 300000
	confluent.tier.topic.delete.max.inprogress.partitions = 100
	confluent.tier.topic.head.data.loss.validation.enable = true
	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
	confluent.tier.topic.materialization.from.snapshot.enable = false
	confluent.tier.topic.producer.enable.idempotence = true
	confluent.tier.topic.snapshots.enable = false
	confluent.tier.topic.snapshots.interval.ms = 300000
	confluent.tier.topic.snapshots.max.records = 100000
	confluent.tier.topic.snapshots.retention.hours = 168
	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
	confluent.topic.partition.default.placement = 2
	confluent.topic.policy.use.computed.assignments = false
	confluent.topic.replica.assignor.builder.class =
	confluent.track.api.key.per.ip = false
	confluent.track.per.ip.max.size = 100000
	confluent.track.tenant.id.per.ip = false
	confluent.traffic.cdc.network.id.routes.enable = false
	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
	confluent.traffic.network.id =
	confluent.traffic.network.type =
	confluent.transaction.2pc.timeout.ms = -1
	confluent.transaction.logging.verbosity = 0
	confluent.transaction.state.log.placement.constraints =
	confluent.unique.deprecated.request.metrics.per.tenant = 1000
	confluent.valid.broker.rack.set = null
	confluent.valid.sni.hostnames =
	confluent.valid.sni.hostnames.exclude.suffix =
	confluent.verify.group.subscription.prefix = false
	confluent.virtual.topic.creation.enabled = false
	confluent.zone.tagged.request.metrics.enable = false
	connection.failed.authentication.delay.ms = 100
	connection.min.expire.interval.ms = 250
	connections.max.age.ms = 3153600000000
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:29093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.cluster.link.policy.class.name = null
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	enable.fips = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	floor.max.connection.creation.rate = null
	follower.replication.throttled.rate = 9223372036854775807
	follower.replication.throttled.replicas = none
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	k2.stack.builder.class.name = null
	k2.startup.timeout.ms = 60000
	k2.topic.metadata.refresh.ms = 10000
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.replication.throttled.rate = 9223372036854775807
	leader.replication.throttled.replicas = none
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
	listeners = PLAINTEXT://localhost:29092,CONTROLLER://localhost:29093,PLAINTEXT_HOST://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.hash.algorithm = MD5
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.cleanup.policy.empty.validation = none
	log.deletion.max.segments.per.run = 2147483647
	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 1.7976931348623157E308
	max.connection.creation.rate.per.ip.enable.threshold = 0.0
	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.connections.per.tenant = 0
	max.connections.protected.listeners = []
	max.connections.reap.amount = 0
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	multitenant.authorizer.support.resource.ids = false
	multitenant.metadata.class = null
	multitenant.metadata.dir = null
	multitenant.metadata.reload.delay.ms = 120000
	multitenant.metadata.ssl.certs.path = null
	multitenant.tenant.delete.batch.size = 10
	multitenant.tenant.delete.check.ms = 120000
	multitenant.tenant.delete.delay = 604800000
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	otel.exporter.otlp.custom.endpoint = default
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	quotas.consumption.expiration.time.ms = 600000
	quotas.expiration.interval.ms = 3600000
	quotas.expiration.time.ms = 604800000
	quotas.lazy.evaluation.threshold = 0.5
	quotas.topic.append.timeout.ms = 5000
	quotas.topic.compression.codec = 3
	quotas.topic.load.buffer.size = 5242880
	quotas.topic.num.partitions = 50
	quotas.topic.placement.constraints =
	quotas.topic.replication.factor = 3
	quotas.topic.segment.bytes = 104857600
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.authn.async.enable = false
	sasl.server.authn.async.max.threads = 1
	sasl.server.authn.async.timeout.ms = 30000
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	throughput.quota.window.num = 11
	token.impersonation.validation = true
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.metadata.load.threads = 32
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,165] INFO Instantiating ClusterBalanceManager with an instance of io.confluent.databalancer.SbcDataBalanceManager (ClusterBalanceManager)
[2025-06-09 19:34:58,168] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-06-09 19:34:58,172] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
[2025-06-09 19:34:58,176] INFO [ControllerServer id=1] FIPS mode enabled: false (kafka.server.ControllerServer)
[2025-06-09 19:34:58,188] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,189] INFO CrnAuthorityConfig values:
	confluent.authorizer.authority.cache.entries = 10000
	confluent.authorizer.authority.name =
	confluent.metadata.server.api.flavor = CP
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,191] INFO NamedConfigEnabled: false (io.confluent.security.audit.provider.ConfluentAuditLogProvider)
[2025-06-09 19:34:58,191] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,212] INFO CrnAuthorityConfig values:
	confluent.authorizer.authority.cache.entries = 10000
	confluent.authorizer.authority.name =
	confluent.metadata.server.api.flavor = CP
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,214] INFO MultiTenantAuditLogConfig values:
	confluent.security.event.logger.client.ip.enable = false
	confluent.security.event.logger.multitenant.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,214] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,214] INFO Audit Log rate limiter reconfigured: Authn: -1, Authz: -1, Kafka request: -1 (io.confluent.security.audit.provider.AuditLogRateLimiter)
[2025-06-09 19:34:58,374] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Creating data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
[2025-06-09 19:34:58,386] INFO Quota CONTROLLER-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
[2025-06-09 19:34:58,387] INFO Quota CONTROLLER-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
[2025-06-09 19:34:58,388] INFO Quota CONTROLLER-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
[2025-06-09 19:34:58,390] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
[2025-06-09 19:34:58,428] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,447] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,450] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,452] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) used TCP protocol (kafka.network.SocketServer)
[2025-06-09 19:34:58,460] INFO [SharedServer id=1] Using localhost:29092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
[2025-06-09 19:34:58,477] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
[2025-06-09 19:34:58,647] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:58,648] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:58,648] INFO [MergedLog partition=__cluster_metadata-0, dir=/var/lib/kafka/data] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset $lastOffset (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:58,663] INFO Initialized snapshots with IDs SortedSet() from /var/lib/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2025-06-09 19:34:58,673] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2025-06-09 19:34:58,685] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
[2025-06-09 19:34:58,687] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/127.0.0.1:29093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
[2025-06-09 19:34:58,688] INFO [RaftManager id=1] Starting request manager with static voters: [localhost:29093 (id: 1 rack: null isFenced: false)] (org.apache.kafka.raft.KafkaRaftClient)
[2025-06-09 19:34:58,691] INFO [RaftManager id=1] Attempting durable transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1718, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2025-06-09 19:34:58,705] INFO [RaftManager id=1] Completed transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1718, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2025-06-09 19:34:58,710] INFO [RaftManager id=1] Completed transition to ProspectiveState(epoch=0, leaderId=OptionalInt.empty, retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1087, highWatermark=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1718, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-06-09 19:34:58,711] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=y2hnhBSrRN9M9zSpC-BgBg, epoch=1, retries=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1873) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1087, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-06-09 19:34:58,713] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=y2hnhBSrRN9M9zSpC-BgBg, epoch=1, retries=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1873) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, retries=1, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1087, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
[2025-06-09 19:34:58,716] INFO [RaftManager id=1] Attempting durable transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=y2hnhBSrRN9M9zSpC-BgBg), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/<unresolved>:29093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=y2hnhBSrRN9M9zSpC-BgBg, epoch=1, retries=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1873) (org.apache.kafka.raft.QuorumState)
[2025-06-09 19:34:58,717] INFO [RaftManager id=1] Completed transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=y2hnhBSrRN9M9zSpC-BgBg), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=localhost/<unresolved>:29093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=y2hnhBSrRN9M9zSpC-BgBg, epoch=1, retries=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1873) (org.apache.kafka.raft.QuorumState)
[2025-06-09 19:34:58,736] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
[2025-06-09 19:34:58,736] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
[2025-06-09 19:34:58,751] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,754] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-06-09 19:34:58,754] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
[2025-06-09 19:34:58,759] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
[2025-06-09 19:34:58,770] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@103567171 (org.apache.kafka.raft.KafkaRaftClient)
[2025-06-09 19:34:58,771] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@103567171 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2025-06-09 19:34:58,773] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,798] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@228434154 (org.apache.kafka.raft.KafkaRaftClient)
[2025-06-09 19:34:58,799] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@228434154 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
[2025-06-09 19:34:58,808] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-06-09 19:34:58,808] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-06-09 19:34:58,814] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,814] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-06-09 19:34:58,815] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,816] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-06-09 19:34:58,817] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,820] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
[2025-06-09 19:34:58,825] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-06-09 19:34:58,826] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
[2025-06-09 19:34:58,826] INFO [controller-1-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,831] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,838] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 4 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,845] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,849] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-06-09 19:34:58,853] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,854] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,854] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,855] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,855] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,856] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,856] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,857] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,870] INFO [ControllerServer id=1] Self-Balancing Kafka is enabled and will be installed as a metadata publisher. (kafka.server.ControllerServer)
[2025-06-09 19:34:58,872] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-06-09 19:34:58,872] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
[2025-06-09 19:34:58,873] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-06-09 19:34:58,873] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,873] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,874] INFO [ControllerServer id=1] Loaded new metadata Features(metadataVersion=4.0-IV3A, finalizedFeatures={confluent.metadata.version=127}, finalizedFeaturesEpoch=3). (org.apache.kafka.metadata.publisher.FeaturesPublisher)
[2025-06-09 19:34:58,874] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,874] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,875] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,875] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,876] INFO Awaiting socket connections on localhost:29093. (kafka.network.DataPlaneAcceptor)
[2025-06-09 19:34:58,876] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,878] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,878] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,879] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ConfluentControllerMetricsPublisher with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,879] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing CellControllerMetadataMetricsPublisher with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,880] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SbcDataBalanceManager with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,882] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 3 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:58,883] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:58,883] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-06-09 19:34:58,883] INFO [ControllerRegistrationManager id=1 incarnation=hKA9mJ0qRPuwgwLgmrqhLg] initialized channel manager. (kafka.server.ControllerRegistrationManager)
[2025-06-09 19:34:58,883] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
[2025-06-09 19:34:58,883] INFO [ControllerServer id=1] Waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
[2025-06-09 19:34:58,883] INFO [ControllerServer id=1] Finished waiting for multi-tenant metadata loader to be started (kafka.server.ControllerServer)
[2025-06-09 19:34:58,883] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-06-09 19:34:58,883] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
[2025-06-09 19:34:58,883] INFO [ControllerServer id=1] Waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
[2025-06-09 19:34:58,883] INFO [ControllerServer id=1] Finished waiting for userDeletionHandler futures to be completed (kafka.server.ControllerServer)
[2025-06-09 19:34:58,884] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:29093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:58,885] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2025-06-09 19:34:58,886] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
[2025-06-09 19:34:58,889] INFO [ControllerRegistrationManager id=1 incarnation=hKA9mJ0qRPuwgwLgmrqhLg] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=hKA9mJ0qRPuwgwLgmrqhLg, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='localhost', port=29093, securityProtocol=0)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='confluent.metadata.version', minSupportedVersion=7, maxSupportedVersion=127), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=25)], metadataEncryptors=[]) (kafka.server.ControllerRegistrationManager)
[2025-06-09 19:34:58,896] INFO [BrokerServer id=1] FIPS mode enabled: false (kafka.server.BrokerServer)
[2025-06-09 19:34:58,899] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-06-09 19:34:58,900] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-06-09 19:34:58,900] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,900] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-06-09 19:34:58,900] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,901] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClientRequestQuotaManager)
[2025-06-09 19:34:58,902] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,902] INFO Empty logDirs received! Disk based throttling won't be activated! (org.apache.kafka.server.config.DiskUsageBasedThrottlingConfig)
[2025-06-09 19:34:58,903] INFO Client Quota Max Throttle Time is updated from 5000 to 1000 (kafka.server.ClusterLinkRequestQuotaManager)
[2025-06-09 19:34:58,903] INFO [broker-1-ThrottledChannelReaper-ClusterLinkRequest]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,904] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-06-09 19:34:58,907] INFO FlexFanout is not enabled or there is no ClientQuotaCallback so does not start FlexFanoutQuotaManager. (kafka.server.FlexFanoutQuotaManager)
[2025-06-09 19:34:58,927] INFO Skip DiskIOManager init: confluent.disk.io.manager.enable = false (kafka.server.resource.DiskIOManager)
[2025-06-09 19:34:58,928] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,928] INFO CrnAuthorityConfig values:
	confluent.authorizer.authority.cache.entries = 10000
	confluent.authorizer.authority.name =
	confluent.metadata.server.api.flavor = CP
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,929] INFO NamedConfigEnabled: false (io.confluent.security.audit.provider.ConfluentAuditLogProvider)
[2025-06-09 19:34:58,929] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,929] INFO CrnAuthorityConfig values:
	confluent.authorizer.authority.cache.entries = 10000
	confluent.authorizer.authority.name =
	confluent.metadata.server.api.flavor = CP
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,929] INFO MultiTenantAuditLogConfig values:
	confluent.security.event.logger.client.ip.enable = false
	confluent.security.event.logger.multitenant.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,929] INFO AuditLogConfig values:
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.cloudevent.codec = structured
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.exporter.class = class io.confluent.security.audit.telemetry.exporter.NonBlockingKafkaExporter
	confluent.security.event.logger.exporter.kafka.topic.create = true
	confluent.security.event.logger.exporter.kafka.topic.partitions = 12
	confluent.security.event.logger.exporter.kafka.topic.replicas = 3
	confluent.security.event.logger.exporter.kafka.topic.retention.bytes = -1
	confluent.security.event.logger.exporter.kafka.topic.retention.ms = 2592000000
	confluent.security.event.logger.exporter.kafka.topic.roll.ms = 14400000
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.cache.entries = 10000
	confluent.security.event.router.config =
	confluent.security.event.router.named.config.enabled = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:58,929] INFO Audit Log rate limiter reconfigured: Authn: -1, Authz: -1, Kafka request: -1 (io.confluent.security.audit.provider.AuditLogRateLimiter)
[2025-06-09 19:34:58,932] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-06-09 19:34:58,932] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2025-06-09 19:34:58,934] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:58,934] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:29093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:58,940] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2025-06-09 19:34:58,991] INFO [ControllerRegistrationManager id=1 incarnation=hKA9mJ0qRPuwgwLgmrqhLg] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
[2025-06-09 19:34:58,993] INFO [ControllerRegistrationManager id=1 incarnation=hKA9mJ0qRPuwgwLgmrqhLg] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
[2025-06-09 19:34:58,999] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-06-09 19:34:59,017] INFO [SocketServer listenerType=BROKER, nodeId=1] Creating data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-06-09 19:34:59,018] INFO Quota PLAINTEXT-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
[2025-06-09 19:34:59,018] INFO Quota PLAINTEXT-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
[2025-06-09 19:34:59,018] INFO Quota PLAINTEXT-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
[2025-06-09 19:34:59,018] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
[2025-06-09 19:34:59,019] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,022] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,023] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,024] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) used TCP protocol (kafka.network.SocketServer)
[2025-06-09 19:34:59,025] INFO [SocketServer listenerType=BROKER, nodeId=1] Creating data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_HOST) (kafka.network.SocketServer)
[2025-06-09 19:34:59,025] INFO Quota PLAINTEXT_HOST-per-ip-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerIpAutoTuningQuota)
[2025-06-09 19:34:59,025] INFO Quota PLAINTEXT_HOST-per-tenant-connection-rate configured - (max: -1.0, floor: -1.0, adjustment: -1.0) (kafka.network.ListenerTenantAutoTuningQuota)
[2025-06-09 19:34:59,025] INFO Quota PLAINTEXT_HOST-connection-rate configured - (max: 1.7976931348623157E308, floor: 1.7976931348623157E308, adjustment: 5.0) (kafka.network.ListenerAutoTuningQuota)
[2025-06-09 19:34:59,025] INFO Updated connection-tokens max connection creation rate to 1.7976931348623157E308 (kafka.network.ConnectionQuotas)
[2025-06-09 19:34:59,026] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,028] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,029] INFO Config values:
	confluent.security.event.logger.detailed.audit.logs.disabled.apis =
	confluent.security.event.logger.enable.detailed.audit.logs = false
	confluent.security.event.logger.enable.produce.consume.audit.logs = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,030] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_HOST) used TCP protocol (kafka.network.SocketServer)
[2025-06-09 19:34:59,036] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:59,037] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:29093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:59,044] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:59,044] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:29093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:59,048] INFO [BrokerHealthManager]: Starting (kafka.availability.BrokerHealthManager)
[2025-06-09 19:34:59,061] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-06-09 19:34:59,062] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-06-09 19:34:59,062] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-06-09 19:34:59,063] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-06-09 19:34:59,063] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-06-09 19:34:59,072] INFO ReplicationConfig values:
	confluent.replication.linger.ms = 0
	confluent.replication.max.in.flight.requests = 1
	confluent.replication.max.memory.buffer.bytes = 209715200
	confluent.replication.max.replica.pushers = 4
	confluent.replication.max.wait.ms = 500
	confluent.replication.mode = PULL
	confluent.replication.num.pushers.per.broker = 1
	confluent.replication.push.internal.topics.enable = false
	confluent.replication.request.max.bytes = 52428800
	confluent.replication.request.max.partition.bytes = 52428800
	confluent.replication.request.timeout.ms = 5000
	confluent.replication.retry.timeout.ms = 10000
	confluent.replication.socket.send.buffer.bytes = 1048576
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,085] INFO [BrokerServer id=1] Using no op persister (kafka.server.BrokerServer)
[2025-06-09 19:34:59,087] INFO [group-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
[2025-06-09 19:34:59,108] INFO [group-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-06-09 19:34:59,108] INFO [group-coordinator-event-processor-1]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-06-09 19:34:59,108] INFO [group-coordinator-event-processor-2]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-06-09 19:34:59,108] INFO [group-coordinator-event-processor-3]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
[2025-06-09 19:34:59,131] INFO Unable to read the broker epoch in /var/lib/kafka/data. (kafka.log.LogManager)
[2025-06-09 19:34:59,133] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:59,133] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node localhost:29093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
[2025-06-09 19:34:59,133] INFO [SharedServer id=1] Using localhost:29092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
[2025-06-09 19:34:59,134] INFO [SharedServer id=1] Using localhost:29092 as bootstrap.servers for inter broker client config. (kafka.server.SharedServer)
[2025-06-09 19:34:59,136] INFO [BrokerLifecycleManager id=1] Incarnation EHNLKeWRTNGRMmiR7zzJPQ of broker 1 in cluster MkU3OEVBNTcwNTJENDM2Qk is now STARTING. (kafka.server.BrokerLifecycleManager)
[2025-06-09 19:34:59,162] INFO [ExpirationReaper-0-null]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-06-09 19:34:59,168] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,168] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,168] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,169] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,169] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,169] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,170] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,170] INFO Config values:
	confluent.request.log.api.samples.per.min =
	confluent.request.log.enable.admin.apis = true
	confluent.request.log.enable.per.connection = false
	confluent.request.log.enable.slowlog = false
	confluent.request.log.samples.per.min = 0
	confluent.request.slowlog.threshold.override = -1.0
	confluent.request.slowlog.threshold.p99.min = -1.0
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,171] INFO [BrokerServer id=1] Waiting for broker metadata to catch up (kafka.server.BrokerServer)
[2025-06-09 19:34:59,181] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 5 (kafka.server.BrokerLifecycleManager)
[2025-06-09 19:34:59,186] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-06-09 19:34:59,186] INFO [BrokerServer id=1] Finished waiting for broker metadata to catch up (kafka.server.BrokerServer)
[2025-06-09 19:34:59,198] INFO [BrokerLifecycleManager id=1] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2025-06-09 19:34:59,205] INFO Starting DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
[2025-06-09 19:34:59,206] INFO Attempting to initiate DynamicMetricsReporters. Attempt: 1 (kafka.server.DynamicMetricsReportersScheduler)
[2025-06-09 19:34:59,212] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-06-09 19:34:59,212] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2025-06-09 19:34:59,212] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-06-09 19:34:59,212] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2025-06-09 19:34:59,212] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-06-09 19:34:59,213] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:59,213] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:59,214] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch(offset=5, epoch=1) with metadata.version Optional[4.0-IV3A]. (kafka.server.metadata.BrokerMetadataPublisher)
[2025-06-09 19:34:59,214] INFO Loading logs from log dirs ArrayBuffer(/var/lib/kafka/data) (kafka.log.LogManager)
[2025-06-09 19:34:59,217] INFO EventEmitterConfig values:
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,217] INFO No logs found to be loaded in /var/lib/kafka/data (kafka.log.LogManager)
[2025-06-09 19:34:59,232] INFO Loaded 0 logs in 17ms (kafka.log.LogManager)
[2025-06-09 19:34:59,233] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-06-09 19:34:59,234] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-06-09 19:34:59,234] INFO Starting log roller with a period of 300000 ms. (kafka.log.LogManager)
[2025-06-09 19:34:59,249] INFO Linux CPU collector enabled: true (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-06-09 19:34:59,250] INFO Using cpu metric: io\.confluent\.kafka\.server/server/linux_system_cpu_utilization_1m (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-06-09 19:34:59,256] INFO Applying value of confluent.telemetry.enabled flag for default '_confluent' http exporter as confluent.telemetry.exporter._confluent.enabled isn't passed (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-06-09 19:34:59,260] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
[2025-06-09 19:34:59,260] WARN no telemetry exporters are enabled (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-06-09 19:34:59,306] WARN Ignoring redefinition of existing telemetry label kafka.version (io.confluent.telemetry.ResourceBuilderFacade)
[2025-06-09 19:34:59,324] INFO Applying value of confluent.telemetry.enabled flag for default '_confluent' http exporter as confluent.telemetry.exporter._confluent.enabled isn't passed (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-06-09 19:34:59,325] INFO ConfluentTelemetryConfig values:
	confluent.telemetry.api.key = null
	confluent.telemetry.api.secret = null
	confluent.telemetry.cluster.id = null
	confluent.telemetry.debug.enabled = false
	confluent.telemetry.enabled = false
	confluent.telemetry.events.collector.include = .*transaction.remove.expired.transaction.cleanup.interval.ms.*|.*transaction.state.log.load.buffer.size.*|.*transaction.state.log.min.isr.*|.*transaction.state.log.num.partitions.*|.*transaction.state.log.replication.factor.*|.*transaction.state.log.segment.bytes.*|.*transactional.id.expiration.ms.*|.*controlled.shutdown.enable.*|.*fetch.max.bytes.*|.*fetch.purgatory.purge.interval.requests.*|.*group.initial.rebalance.delay.ms.*|.*group.max.session.timeout.ms.*|.*group.max.size.*|.*group.min.session.timeout.ms.*|.*log.cleaner.backoff.ms.*|.*log.cleaner.dedupe.buffer.size.*|.*log.cleaner.delete.retention.ms.*|.*log.cleaner.enable.*|.*log.cleaner.io.buffer.load.factor.*|.*log.cleaner.io.buffer.size.*|.*log.cleaner.io.max.bytes.per.second.*|.*log.cleaner.max.compaction.lag.ms.*|.*log.cleaner.min.cleanable.ratio.*|.*log.cleaner.min.compaction.lag.ms.*|.*log.cleaner.threads.*|.*log.cleanup.policy.*|.*log.index.interval.bytes.*|.*log.index.size.max.bytes.*|.*log.message.downconversion.enable.*|.*log.message.format.version.*|.*log.message.timestamp.difference.max.ms.*|.*log.message.timestamp.type.*|.*max.connection.creation.rate.*|.*max.connections.*|.*max.connections.per.ip.*|.*max.incremental.fetch.session.cache.slots.*|.*replica.fetch.backoff.ms.*|.*replica.fetch.max.bytes.*|.*replica.fetch.min.bytes.*|.*replica.fetch.response.max.bytes.*|.*replica.fetch.wait.max.ms.*|.*replica.high.watermark.checkpoint.interval.ms.*|.*replica.lag.time.max.ms.*|.*replica.selector.class.*|.*replica.socket.receive.buffer.bytes.*|.*replica.socket.timeout.ms.*|.*alter.config.policy.class.name.*|.*alter.log.dirs.replication.quota.window.num.*|.*alter.log.dirs.replication.quota.window.size.seconds.*|.*metrics.num.samples.*|.*metrics.recording.level.*|.*metrics.sample.window.ms.*|.*quota.window.num.*|.*quota.window.size.seconds.*|.*replication.quota.window.num.*|.*replication.quota.window.size.seconds.*|.*confluent.balancer.enable.*|.*confluent.balancer.throttle.bytes.per.second.*|.*confluent.balancer.heal.uneven.load.trigger.*|.*confluent.balancer.heal.broker.failure.threshold.ms.*|.*confluent.balancer.disk.max.load.*|.*confluent.balancer.exclude.topic.prefixes.*|.*confluent.balancer.exclude.topic.names.*|.*confluent.tier.local.hotset.bytes.*|.*confluent.tier.local.hotset.ms.*|.*confluent.tier.archiver.num.threads.*|.*confluent.tier.backend.*|.*confluent.tier.enable.*|.*confluent.tier.feature.*|.*confluent.tier.fetcher.num.threads.*|.*confluent.tier.max.partition.fetch.bytes.override.*|.*confluent.tier.metadata.replication.factor.*|.*confluent.operator.managed.*|.*confluent.ansible.managed.*|.*confluent.license.*
	confluent.telemetry.events.enable = true
	confluent.telemetry.external.client.metrics.exclude.labels =
	confluent.telemetry.metrics.collector.include = .*io.confluent.telemetry/.*.*|.*io\.confluent\.system/(?:.*/)?(process_cpu_load|max_file_descriptor_count|open_file_descriptor_count|system_cpu_load|system_load_average|free_physical_memory_size|total_physical_memory_size|disk_total_bytes|disk_usable_bytes|jvm/mem|jvm/gc).*|.*io.confluent.kafka.server/.*(confluent_audit/audit_log_fallback_rate_per_minute|confluent_audit/audit_log_rate_per_minute|confluent_authorizer/authorization_request_rate_per_minute|confluent_authorizer/authorization_allowed_rate_per_minute|confluent_authorizer/authorization_denied_rate_per_minute|confluent_auth_store/rbac_role_bindings_count|confluent_auth_store/rbac_access_rules_count|confluent_auth_store/acl_access_rules_count).*|.*io.confluent.kafka.server/.*(acl_authorizer/zookeeper_disconnects/total/delta|acl_authorizer/zookeeper_expires/total/delta|broker_failure/zookeeper_disconnects/total/delta|broker_failure/zookeeper_expires/total/delta|broker_topic/bytes_in/total/delta|broker_topic/bytes_out/total/delta|broker_topic/failed_produce_requests/total/delta|broker_topic/failed_fetch_requests/total/delta|broker_topic/produce_message_conversions/total/delta|broker_topic/fetch_message_conversions/total/delta|client_broker_topic/client_bytes_in/delta|client_broker_topic/client_bytes_out/delta|client_broker_topic/client_records_in/delta|client_broker_topic/client_records_out/delta|cluster_link/active_link_count|cluster_link/consumer_offset_committed_rate|cluster_link/consumer_offset_committed_total|cluster_link/fetch_throttle_time_avg|cluster_link/fetch_throttle_time_max|cluster_link/link_count|cluster_link/linked_leader_epoch_change_rate|cluster_link/linked_leader_epoch_change_total|cluster_link/linked_topic_partition_addition_rate|cluster_link/linked_topic_partition_addition_total|cluster_link/mirror_partition_count|cluster_link/mirror_topic_byte_total|cluster_link/mirror_topic_count|cluster_link/mirror_topic_lag|cluster_link/topic_config_update_rate|cluster_link/topic_config_update_total|cluster_link_fetcher/connection_count|cluster_link_fetcher/failed_reauthentication_rate|cluster_link_fetcher/failed_reauthentication_total|cluster_link_fetcher/incoming_byte_rate|cluster_link_fetcher/incoming_byte_total|cluster_link_fetcher/outgoing_byte_rate|cluster_link_fetcher/outgoing_byte_total|cluster_link_fetcher/reauthentication_latency_avg|cluster_link_fetcher_manager/max_lag|controller/active_controller_count|controller/leader_election_rate_and_time_ms|controller/offline_partitions_count|controller/partition_availability|controller/preferred_replica_imbalance_count|controller/tenant_partition_availability|controller/global_under_min_isr_partition_count|controller/unclean_leader_elections/total|controller_channel/connection_close_rate|controller_channel/connection_close_total|controller_channel/connection_count|controller_channel/connection_creation_rate|controller_channel/connection_creation_total|controller_channel/request_size_avg|controller_channel/request_size_max|controller_channel_manager/queue_size|controller_channel_manager/total_queue_size|controller_event_manager/event_queue_size|delayed_operation_purgatory/purgatory_size|executor/zookeeper_disconnects/total/delta|executor/zookeeper_expires/total/delta|fetch/queue_size|fetcher/bytes_per_sec|fetcher_lag/consumer_lag|group_coordinator/partition_load_time_max|log/log_end_offset|log/log_start_offset|log/total_size|log_cleaner_manager/achieved_cleaning_ratio/time/delta|log_cleaner_manager/achieved_cleaning_ratio/total/delta|log_cleaner_manager/compacted_partition_bytes|log_cleaner_manager/max_dirty_percent|log_cleaner_manager/time_since_last_run_ms|log_cleaner_manager/uncleanable_bytes|log_cleaner_manager/uncleanable_partitions_count|replica_alter_log_dirs_manager/max_lag|replica_fetcher/request_size_avg|replica_fetcher/request_size_max|replica_fetcher_manager/max_lag|replica_manager/blocked_on_mirror_source_partition_count|replica_manager/isr_shrinks|replica_manager/leader_count|replica_manager/partition_count|replica_manager/under_min_isr_mirror_partition_count|replica_manager/under_min_isr_partition_count|replica_manager/under_replicated_mirror_partitions|replica_manager/under_replicated_partitions|request/errors/total/delta|request/local_time_ms/time/delta|request/local_time_ms/total/delta|request/queue_size|request/remote_time_ms/time/delta|request/remote_time_ms/total/delta|request/request_queue_time_ms/time/delta|request/request_queue_time_ms/total/delta|request/requests|request/response_queue_time_ms/time/delta|request/response_queue_time_ms/total/delta|request/response_send_time_ms/time/delta|request/response_send_time_ms/total/delta|request/total_time_ms/time/delta|request/total_time_ms/total/delta|request_channel/request_queue_size|request_channel/response_queue_size|request_handler_pool/request_handler_avg_idle_percent|session_expire_listener/zookeeper_disconnects/total/delta|session_expire_listener/zookeeper_expires/total/delta|socket_server/connections|socket_server/successful_authentication_total/delta|socket_server/failed_authentication_total/delta|socket_server/network_processor_avg_idle_percent|socket_server/request_size_avg|socket_server/request_size_max|tenant/consumer_lag_offsets).*|.*org\.apache\.kafka\.(producer\.connection\.creation\.rate|producer\.node\.request\.latency\.avg|producer\.node\.request\.latency\.max|producer\.produce\.throttle\.time\.avg|producer\.produce\.throttle\.time\.max|producer\.record\.queue\.time\.avg|producer\.record\.queue\.time\.max|producer\.connection\.creation\.total|consumer\.connection\.creation\.rate|consumer\.connection\.creation\.total|consumer\.node\.request\.latency\.avg|consumer\.node\.request\.latency\.max|consumer\.poll\.idle\.ratio\.avg|consumer\.coordinator\.commit\.latency\.avg|consumer\.coordinator\.commit\.latency\.max|consumer\.coordinator\.assigned\.partitions|consumer\.coordinator\.rebalance\.latency\.avg|consumer\.coordinator\.rebalance\.latency\.max|consumer\.coordinator\.rebalance\.latency\.total|consumer\.fetch\.manager\.fetch\.latency\.avg|consumer\.fetch\.manager\.fetch\.latency\.max).*
	confluent.telemetry.metrics.collector.interval.ms = 60000
	confluent.telemetry.metrics.collector.slo.enabled = false
	confluent.telemetry.proxy.password = null
	confluent.telemetry.proxy.url = null
	confluent.telemetry.proxy.username = null
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,327] INFO VolumeMetricsCollectorConfig values:
	confluent.telemetry.metrics.collector.volume.update.ms = 15000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,327] INFO HttpClientConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = httpTelemetryClient
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,327] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client = _confluentClient
	client.attempts.max = null
	client.base.url = null
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = false
	events.enabled = true
	metrics.enabled = true
	metrics.include = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	remote.configurable = true
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,327] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
[2025-06-09 19:34:59,328] INFO HttpExporterConfig values:
	api.key = unused
	api.secret = [hidden]
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = 2000
	buffer.inflight.submissions.max = 10
	buffer.pending.batches.max = 25
	client =
	client.attempts.max = null
	client.base.url = http://localhost:9090/api/v1/otlp
	client.compression = gzip
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = false
	events.enabled = true
	metrics.enabled = true
	metrics.include = (io.confluent.kafka.server.request.(?!.*delta).*|io.confluent.kafka.server.server.broker.state|io.confluent.kafka.server.replica.manager.leader.count|io.confluent.kafka.server.request.queue.size|io.confluent.kafka.server.broker.topic.failed.produce.requests.rate.1_min|io.confluent.kafka.server.tier.archiver.total.lag|io.confluent.kafka.server.request.total.time.ms.p99|io.confluent.kafka.server.broker.topic.failed.fetch.requests.rate.1_min|io.confluent.kafka.server.log.total.size|io.confluent.kafka.server.broker.topic.total.fetch.requests.rate.1_min|io.confluent.kafka.server.partition.caught.up.replicas.count|io.confluent.kafka.server.partition.observer.replicas.count|io.confluent.kafka.server.tier.tasks.num.partitions.in.error|io.confluent.kafka.server.broker.topic.bytes.out.rate.1_min|io.confluent.kafka.server.request.total.time.ms.p95|io.confluent.kafka.server.controller.active.controller.count|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.total|io.confluent.kafka.server.request.total.time.ms.p999|io.confluent.kafka.server.controller.active.broker.count|io.confluent.kafka.server.request.handler.pool.request.handler.avg.idle.percent.rate.1_min|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.rate.1_min|io.confluent.kafka.server.controller.unclean.leader.elections.rate.1_min|io.confluent.kafka.server.replica.manager.partition.count|io.confluent.kafka.server.controller.unclean.leader.elections.total|io.confluent.kafka.server.partition.replicas.count|io.confluent.kafka.server.broker.topic.total.produce.requests.rate.1_min|io.confluent.kafka.server.controller.offline.partitions.count|io.confluent.kafka.server.socket.server.network.processor.avg.idle.percent|io.confluent.kafka.server.partition.under.replicated|io.confluent.kafka.server.log.log.start.offset|io.confluent.kafka.server.log.tier.size|io.confluent.kafka.server.log.size|io.confluent.kafka.server.tier.fetcher.bytes.fetched.total|io.confluent.kafka.server.request.total.time.ms.p50|io.confluent.kafka.server.tenant.consumer.lag.offsets|io.confluent.kafka.server.session.expire.listener.zookeeper.expires.rate.1_min|io.confluent.kafka.server.log.log.end.offset|io.confluent.kafka.server.log.num.log.segments|io.confluent.kafka.server.broker.topic.bytes.in.rate.1_min|io.confluent.kafka.server.partition.under.min.isr|io.confluent.kafka.server.partition.in.sync.replicas.count|io.confluent.telemetry.http.exporter.batches.dropped|io.confluent.telemetry.http.exporter.items.total|io.confluent.telemetry.http.exporter.items.succeeded|io.confluent.telemetry.http.exporter.send.time.total.millis|io.confluent.kafka.server.controller.leader.election.rate.(?!.*delta).*|io.confluent.telemetry.http.exporter.batches.failed)
	proxy.password = null
	proxy.url = null
	proxy.username = null
	remote.configurable = true
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,330] INFO KafkaExporterConfig values:
	client =
	enabled = true
	events.enabled = true
	metrics.enabled = true
	metrics.include = (io\.confluent\.kafka\.server/fetch/broker_quota|io\.confluent\.kafka\.server/produce/broker_quota|io\.confluent\.kafka\.server/broker_load/broker_load_percent|io\.confluent\.kafka\.server/broker_topic/bytes_in/rate/1_min|io\.confluent\.kafka\.server/broker_topic/bytes_out/rate/1_min|io\.confluent\.kafka\.server/broker_topic/fetch_from_follower_bytes_out/rate/1_min|io\.confluent\.kafka\.server/broker_topic/messages_in/rate/1_min|io\.confluent\.kafka\.server/broker_topic/replication_bytes_in/rate/1_min|io\.confluent\.kafka\.server/broker_topic/replication_bytes_out/rate/1_min|io\.confluent\.kafka\.server/broker_topic/total_fetch_requests/rate/1_min|io\.confluent\.kafka\.server/broker_topic/total_follower_fetch_requests/rate/1_min|io\.confluent\.kafka\.server/broker_topic/mirror_bytes_in/rate/1_min|io\.confluent\.kafka\.server/broker_topic/total_fetch_from_follower_requests/rate/1_min|io\.confluent\.kafka\.server/broker_topic/total_produce_requests/rate/1_min|io\.confluent\.kafka\.server/log/size|io\.confluent\.kafka\.server/request/requests/rate/1_min|io\.confluent\.kafka\.server/request_handler_pool/request_handler_avg_idle_percent/rate/1_min|io\.confluent\.kafka\.server/server/linux_system_cpu_utilization_1m|io\.confluent\.kafka\.server/replica_manager/partition_count|io\.confluent\.system/volume/disk_total_bytes)
	producer.bootstrap.servers = localhost:29092
	remote.configurable = false
	topic.create = true
	topic.max.message.bytes = 10485760
	topic.name = _confluent-telemetry-metrics
	topic.partitions = 12
	topic.replicas = 1
	topic.retention.bytes = -1
	topic.retention.ms = 259200000
	topic.roll.ms = 14400000
	type = kafka
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,330] INFO PollingRemoteConfigurationConfig values:
	enabled = true
	refresh.interval.ms = 60000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,331] INFO Initializing the event logger (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-06-09 19:34:59,333] INFO EventLoggerConfig values:
	event.logger.cloudevent.codec = structured
	event.logger.exporter.class = class io.confluent.telemetry.events.exporter.http.EventHttpExporter
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,338] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = true
	events.enabled = true
	filtering.enabled = false
	filtering.routes.allowed = []
	metrics.enabled = true
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,353] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-06-09 19:34:59,355] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-06-09 19:34:59,356] INFO [AddPartitionsToTxnSenderThread-1]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-06-09 19:34:59,370] INFO [ClusterLinkTaskManager brokerId=1] Creating local admin client for task manager 0 (kafka.server.link.ClusterLinkTaskManager)
[2025-06-09 19:34:59,374] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = cluster-link--local-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,407] INFO These configurations '[confluent.link.metadata.topic.replication.factor, confluent.balancer.topics.replication.factor, confluent.command.topic.replication, cluster.link.metadata.topic.replication.factor, confluent.license.topic.replication.factor]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,408] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:34:59,408] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:34:59,408] INFO Kafka startTimeMs: 1749497699408 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:34:59,411] INFO [ClusterLinkRegionalMetadata-broker-1] Set local network type to persisted value NOT_SET (kafka.server.link.ClusterLinkRegionalMetadata)
[2025-06-09 19:34:59,412] INFO [ClusterLinkManager-broker-1] ClusterLinkManager has started up. (kafka.server.link.ClusterLinkManager)
[2025-06-09 19:34:59,412] INFO [GroupCoordinator id=1] Starting up. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
[2025-06-09 19:34:59,413] INFO [GroupCoordinator id=1] Startup complete. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
[2025-06-09 19:34:59,413] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-06-09 19:34:59,414] INFO [AdminClient clientId=cluster-link--local-admin-1] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-06-09 19:34:59,414] WARN [AdminClient clientId=cluster-link--local-admin-1] Connection to node -1 (localhost/127.0.0.1:29092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-06-09 19:34:59,415] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-06-09 19:34:59,415] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-06-09 19:34:59,425] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:59,425] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2025-06-09 19:34:59,427] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ClusterLinkCoordinatorListener with a snapshot at offset 5 (org.apache.kafka.image.loader.MetadataLoader)
[2025-06-09 19:34:59,427] INFO KafkaConfig values:
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = PLAINTEXT://localhost:29092,PLAINTEXT_HOST://localhost:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
	broker.rack = null
	broker.session.timeout.ms = 9000
	broker.session.uuid = GwXCsAj0RRqEIfy8wh6Zwg
	client.quota.callback.class = null
	client.quota.max.throttle.time.in.response.ms = 60000
	client.quota.max.throttle.time.ms = 5000
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	confluent.accp.enabled = false
	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
	confluent.alter.broker.health.max.demoted.brokers = 2147483647
	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
	confluent.ansible.managed = false
	confluent.api.visibility = DEFAULT
	confluent.append.record.interceptor.classes = []
	confluent.apply.create.topic.policy.to.create.partitions = false
	confluent.authorizer.authority.name =
	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
	confluent.backpressure.disk.enable = false
	confluent.backpressure.disk.free.threshold.bytes = 21474836480
	confluent.backpressure.disk.produce.bytes.per.second = 131072
	confluent.backpressure.disk.threshold.recovery.factor = 1.5
	confluent.backpressure.request.min.broker.limit = 200
	confluent.backpressure.request.queue.size.percentile = p95
	confluent.backpressure.types = null
	confluent.balancer.api.state.topic = _confluent_balancer_api_state
	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
	confluent.balancer.capacity.threshold.upper.limit = 0.95
	confluent.balancer.cell.load.upper.bound = 0.7
	confluent.balancer.cell.overload.detection.interval.ms = 3600000
	confluent.balancer.cell.overload.duration.ms = 86400000
	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.cpu.balance.threshold = 1.1
	confluent.balancer.cpu.goal.act.as.capacity.goal = false
	confluent.balancer.cpu.low.utilization.threshold = 0.2
	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
	confluent.balancer.disk.max.load = 0.85
	confluent.balancer.disk.min.free.space.gb = 0
	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
	confluent.balancer.disk.utilization.detector.duration.ms = 600000
	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
	confluent.balancer.enable = false
	confluent.balancer.enable.network.capacity.metric.ingestion = false
	confluent.balancer.exclude.topic.names = []
	confluent.balancer.exclude.topic.prefixes = []
	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	confluent.balancer.incremental.balancing.enabled = false
	confluent.balancer.incremental.balancing.goals = []
	confluent.balancer.incremental.balancing.lower.bound = 0.02
	confluent.balancer.incremental.balancing.min.valid.windows = 5
	confluent.balancer.incremental.balancing.step.ratio = 0.2
	confluent.balancer.inter.cell.balancing.enabled = false
	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
	confluent.balancer.max.replicas = 2147483647
	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.rebalancing.goals = []
	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.resource.utilization.detector.interval.ms = 60000
	confluent.balancer.sbc.metrics.parser.enabled = false
	confluent.balancer.self.healing.maximum.rounds = 1
	confluent.balancer.task.history.retention.days = 30
	confluent.balancer.tenant.maximum.movements = 0
	confluent.balancer.tenant.suspension.ms = 86400000
	confluent.balancer.throttle.bytes.per.second = 10485760
	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
	confluent.balancer.topic.partition.maximum.movements = 3
	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
	confluent.balancer.topic.partition.movements.history.limit = 900
	confluent.balancer.topic.partition.suspension.ms = 3600000
	confluent.balancer.topic.replication.factor = 1
	confluent.balancer.triggering.goals = []
	confluent.balancer.v2.addition.enabled = false
	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
	confluent.balancer.v2.executor.enabled = false
	confluent.basic.auth.credentials.source = null
	confluent.basic.auth.user.info = null
	confluent.bearer.assertion.claim.aud = null
	confluent.bearer.assertion.claim.exp.minutes = null
	confluent.bearer.assertion.claim.iss = null
	confluent.bearer.assertion.claim.jti.include = null
	confluent.bearer.assertion.claim.nbf.include = null
	confluent.bearer.assertion.claim.sub = null
	confluent.bearer.assertion.file = null
	confluent.bearer.assertion.private.key.file = null
	confluent.bearer.assertion.private.key.passphrase = null
	confluent.bearer.assertion.template.file = null
	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
	confluent.bearer.auth.client.id = null
	confluent.bearer.auth.client.secret = null
	confluent.bearer.auth.credentials.source = null
	confluent.bearer.auth.identity.pool.id = null
	confluent.bearer.auth.issuer.endpoint.url = null
	confluent.bearer.auth.logical.cluster = null
	confluent.bearer.auth.scope = null
	confluent.bearer.auth.scope.claim.name = scope
	confluent.bearer.auth.sub.claim.name = sub
	confluent.bearer.auth.token = null
	confluent.broker.health.manager.enabled = true
	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
	confluent.broker.health.manager.hard.kill.duration.ms = 60000
	confluent.broker.health.manager.mitigation.enabled = false
	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
	confluent.broker.health.manager.sample.duration.ms = 1000
	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
	confluent.broker.load.advertised.limit.load = 0.8
	confluent.broker.load.average.service.request.time.ms = 0.1
	confluent.broker.load.delay.metric.start.ms = 180000
	confluent.broker.load.enabled = false
	confluent.broker.load.num.samples = 60
	confluent.broker.load.tenant.metric.enable = false
	confluent.broker.load.update.metric.tags.interval.ms = 60000
	confluent.broker.load.window.size.ms = 60000
	confluent.broker.load.workload.coefficient = 20.0
	confluent.broker.registration.delay.ms = 0
	confluent.calling.resource.identity.type.map =
	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
	confluent.catalog.collector.enable = false
	confluent.catalog.collector.full.configs.enable = false
	confluent.catalog.collector.max.bytes.per.snapshot = 850000
	confluent.catalog.collector.max.topics.process = 500
	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
	confluent.catalog.collector.multitenant.topics.enable = true
	confluent.catalog.collector.snapshot.init.delay.sec = 60
	confluent.catalog.collector.snapshot.interval.sec = 300
	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
	confluent.cdc.api.keys.topic =
	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
	confluent.cdc.client.quotas.enable = false
	confluent.cdc.client.quotas.topic.name =
	confluent.cdc.lkc.metadata.topic =
	confluent.cdc.user.metadata.enable = false
	confluent.cdc.user.metadata.topic = _confluent-user_metadata
	confluent.cell.metrics.refresh.period.ms = 60000
	confluent.cells.default.size = 15
	confluent.cells.enable = false
	confluent.cells.implicit.creation.enable = false
	confluent.cells.k2.base.broker.index = -1
	confluent.cells.load.refresher.enable = true
	confluent.cells.max.size = 15
	confluent.cells.min.size = 6
	confluent.checksum.enabled.files = [none]
	confluent.client.topic.max.metrics.count = 1000
	confluent.client.topic.metrics.expiry.sec = 3600
	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
	confluent.clm.enabled = false
	confluent.clm.frequency.in.hours = 6
	confluent.clm.list.object.thread_pool.size = 1
	confluent.clm.max.backup.days = 3
	confluent.clm.min.delay.in.minutes = 30
	confluent.clm.thread.pool.size = 2
	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
	confluent.close.connections.on.credential.delete = false
	confluent.cluster.link.admin.max.in.flight.requests = 1000
	confluent.cluster.link.admin.request.batch.size = 1
	confluent.cluster.link.allow.config.providers = true
	confluent.cluster.link.allow.legacy.message.format = false
	confluent.cluster.link.allow.truncation.below.hwm = false
	confluent.cluster.link.availability.check.mode = ALL
	confluent.cluster.link.background.thread.affinity = LINK
	confluent.cluster.link.bootstrap.translation.feature.enable = true
	confluent.cluster.link.clients.max.idle.ms = 3153600000000
	confluent.cluster.link.enable = true
	confluent.cluster.link.enable.local.admin = false
	confluent.cluster.link.enable.metrics.reduction = false
	confluent.cluster.link.enable.metrics.reduction.advanced = false
	confluent.cluster.link.fetch.response.min.bytes = 1
	confluent.cluster.link.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.fetcher.auto.tune.enable = false
	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
	confluent.cluster.link.insync.fetch.response.min.bytes = 1
	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
	confluent.cluster.link.intranet.connectivity.enable = false
	confluent.cluster.link.intranet.connectivity.migration.enable = false
	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
	confluent.cluster.link.local.admin.multitenant.enable = false
	confluent.cluster.link.local.reverse.connection.listener.map = null
	confluent.cluster.link.max.client.connections = 2147483647
	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
	confluent.cluster.link.metadata.topic.enable = false
	confluent.cluster.link.metadata.topic.min.isr = 2
	confluent.cluster.link.metadata.topic.partitions = 50
	confluent.cluster.link.metadata.topic.replication.factor = 1
	confluent.cluster.link.mirror.transition.batch.size = 10
	confluent.cluster.link.num.background.threads = 1
	confluent.cluster.link.periodic.task.batch.size = 2147483647
	confluent.cluster.link.periodic.task.min.interval.ms = 1000
	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
	confluent.cluster.link.replica.fetch.connections.mode = combined
	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
	confluent.cluster.link.replication.quota.mode.per.tenant.overrides =
	confluent.cluster.link.replication.quota.window.num = 11
	confluent.cluster.link.replication.quota.window.size.seconds = 2
	confluent.cluster.link.request.quota.capacity = 400
	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
	confluent.cluster.link.switchover.disabled.principals = []
	confluent.cluster.link.switchover.enable = false
	confluent.cluster.link.switchover.listeners = []
	confluent.cluster.link.switchover.server.states = []
	confluent.cluster.link.tenant.replication.quota.enable = false
	confluent.cluster.link.tenant.request.quota.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
	confluent.cluster.metadata.snapshot.tier.upload.enable = false
	confluent.compacted.topic.prefer.tier.fetch.ms = -1
	confluent.connection.invalid.request.delay.enable = false
	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
	confluent.consumer.fetch.partition.pruning.enable = true
	confluent.consumer.lag.emitter.enabled = false
	confluent.consumer.lag.emitter.interval.ms = 60000
	confluent.dataflow.policy.watch.monitor.ms = 300000
	confluent.default.data.policy.enforcement = true
	confluent.defer.isr.shrink.enable = false
	confluent.describe.topic.partitions.enabled = true
	confluent.disk.io.manager.enable = false
	confluent.disk.throughput.headroom = 10485760
	confluent.disk.throughput.limit = 10485760000
	confluent.disk.throughput.quota.tier.archive = 1048576000
	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
	confluent.durability.audit.batch.flush.frequency.ms = 900000
	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
	confluent.durability.audit.enable = false
	confluent.durability.audit.idempotent.producer = false
	confluent.durability.audit.initial.job.delay.ms = 900000
	confluent.durability.audit.io.bytes.per.sec = 10485760
	confluent.durability.audit.log.ignored.event.types =
	confluent.durability.audit.reporting.batch.ms = 1800000
	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
	confluent.durability.topic.partition.count = 50
	confluent.durability.topic.replication.factor = 1
	confluent.e2e_checksum.protection.enabled = false
	confluent.e2e_checksum.protection.files = [none]
	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
	confluent.elastic.cku.enabled = false
	confluent.elastic.cku.scaletozero.enabled = false
	confluent.eligible.controllers = []
	confluent.enable.broker.reporting.min.usage.mode = true
	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.fail.unsatisfied.placement.constraints = false
	confluent.fetch.from.follower.require.leader.epoch.enable = false
	confluent.fetch.partition.pruning.enable = true
	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
	confluent.flexible.fanout.enabled = false
	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
	confluent.flexible.fanout.mode = TENANT_QUOTA
	confluent.floor.connection.rate.per.ip = -1.0
	confluent.floor.connection.rate.per.tenant = -1.0
	confluent.group.coordinator.dynamic.append.linger.enable = false
	confluent.group.coordinator.offsets.batching.enable = false
	confluent.group.coordinator.offsets.writer.threads = 2
	confluent.group.coordinator.txn.offset.validation.enable = false
	confluent.group.highest.offset.commit.rates.log.count = 10
	confluent.group.highest.offset.commit.rates.log.enable = false
	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
	confluent.group.metadata.load.threads = 32
	confluent.group.subscription.pattern.log.interval.ms = -1
	confluent.heap.tenured.notify.bytes = 0
	confluent.heap.tenured.notify.enabled = false
	confluent.hot.partition.ratio = 0.8
	confluent.http.server.start.timeout.ms = 60000
	confluent.http.server.stop.timeout.ms = 30000
	confluent.internal.metrics.enable = false
	confluent.internal.rest.server.bind.port = null
	confluent.internal.rest.server.ssl.enable = false
	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
	confluent.leader.epoch.checkpoint.checksum.enabled = false
	confluent.listener.protocol = TCP
	confluent.log.cleaner.timestamp.validation.enable = true
	confluent.log.placement.constraints =
	confluent.max.broker.load = 1.0
	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
	confluent.max.connection.rate.per.ip = -1.0
	confluent.max.connection.rate.per.tenant = -1.0
	confluent.max.connection.throttle.ms = null
	confluent.max.segment.ms = 9223372036854775807
	confluent.metadata.active.encryptor = null
	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
	confluent.metadata.encryptor.classes = null
	confluent.metadata.encryptor.required = false
	confluent.metadata.encryptor.secret.file = null
	confluent.metadata.encryptor.secrets = null
	confluent.metadata.jvm.warmup.ms = 60000
	confluent.metadata.leader.balance.slice.delay.ms = 100
	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
	confluent.metadata.max.leader.balance.changes.per.slice = 1000
	confluent.metadata.reject.when.throttled.enable = false
	confluent.metadata.server.cluster.registry.clusters = []
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.min.acks = 0
	confluent.min.connection.throttle.ms = 0
	confluent.min.segment.ms = 1
	confluent.missing.id.cache.ttl.sec = 60
	confluent.missing.id.query.range = 20000
	confluent.missing.schema.cache.ttl.sec = 60
	confluent.mtls.build.client.cert.chain.enable = false
	confluent.mtls.enable = false
	confluent.mtls.listener.name = EXTERNAL
	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
	confluent.mtls.truststore.manager.class.name = null
	confluent.multitenant.authorizer.enable.acl.state = false
	confluent.multitenant.interceptor.balancer.apis.enabled = false
	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
	confluent.multitenant.listener.names = null
	confluent.multitenant.parse.lkc.id.enable = false
	confluent.multitenant.parse.sni.host.name.enable = false
	confluent.network.health.manager.enabled = false
	confluent.network.health.manager.external.listener.name = EXTERNAL
	confluent.network.health.manager.externalconnectivitystartup.enabled = false
	confluent.network.health.manager.min.healthy.network.samples = 3
	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
	confluent.network.health.manager.mitigation.enabled = false
	confluent.network.health.manager.network.sample.window.size = 120
	confluent.network.health.manager.sample.duration.ms = 1000
	confluent.oauth.flat.networking.verification.enable = false
	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
	confluent.offsets.topic.placement.constraints =
	confluent.omit.network.processor.metric.tag = false
	confluent.operator.managed = false
	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings =
	confluent.ppv2.endpoint.scheme.enable = false
	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
	confluent.ppv2.endpoint.scheme.template.variable.cloud =
	confluent.ppv2.endpoint.scheme.template.variable.domain =
	confluent.ppv2.endpoint.scheme.template.variable.region =
	confluent.ppv2.endpoint.scheme.template.variables =
	confluent.ppv2.endpoint.scheme.templates =
	confluent.prefer.tier.fetch.ms = -1
	confluent.produce.throttle.pre.check.enable = false
	confluent.produce.throttle.pre.check.for.new.connection.enable = false
	confluent.producer.id.cache.broker.hard.limit = -1
	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
	confluent.producer.id.cache.extra.eviction.percentage = 0
	confluent.producer.id.cache.limit = 2147483647
	confluent.producer.id.cache.partition.hard.limit = -1
	confluent.producer.id.cache.tenant.hard.limit = -1
	confluent.producer.id.quota.manager.enable = false
	confluent.producer.id.quota.window.num = 11
	confluent.producer.id.quota.window.size.seconds = 1
	confluent.producer.id.throttle.enable = false
	confluent.producer.id.throttle.enable.threshold.percentage = 100
	confluent.proxy.mode.local.default = false
	confluent.proxy.protocol.fallback.enabled = false
	confluent.proxy.protocol.version = NONE
	confluent.quota.computing.usage.adjustment = 0.5
	confluent.quota.dynamic.adjustment.min.usage = 102400
	confluent.quota.dynamic.enable = false
	confluent.quota.dynamic.publishing.interval.ms = 60000
	confluent.quota.dynamic.reporting.interval.ms = 30000
	confluent.quota.tenant.broker.max.consumer.rate = 13107200
	confluent.quota.tenant.broker.max.producer.rate = 13107200
	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
	confluent.quota.tenant.fetch.multiplier = 1.0
	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
	confluent.quota.tenant.internal.throttling.enable = false
	confluent.quota.tenant.produce.multiplier = 1.0
	confluent.quota.tenant.user.quotas.enable = false
	confluent.rack.id.mapping = null
	confluent.regional.metadata.client.class = null
	confluent.regional.resource.manager.client.scheduler.threads = 2
	confluent.regional.resource.manager.endpoint = null
	confluent.regional.resource.manager.watch.endpoint = null
	confluent.replica.fetch.backoff.max.ms = 1000
	confluent.replica.fetch.connections.mode = combined
	confluent.replication.mode = PULL
	confluent.replication.push.feature.enable = false
	confluent.reporters.telemetry.auto.enable = true
	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
	confluent.request.pipelining.enable = true
	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
	confluent.require.calling.resource.identity = false
	confluent.require.compatible.keystore.updates = true
	confluent.require.confluent.issuer = false
	confluent.roll.check.interval.ms = 300000
	confluent.schema.registry.max.cache.size = 10000
	confluent.schema.registry.max.retries = 1
	confluent.schema.registry.retries.wait.ms = 0
	confluent.schema.registry.url = null
	confluent.schema.validation.context.name.enable = false
	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
	confluent.schema.validator.multitenant.enable = false
	confluent.schema.validator.samples.per.min = 0
	confluent.security.bc.approved.mode.enable = false
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.config =
	confluent.security.revoked.certificate.ids =
	confluent.segment.eager.roll.enable = false
	confluent.segment.speculative.prefetch.enable = false
	confluent.share.metadata.load.threads = 32
	confluent.spiffe.id.principal.extraction.rules =
	confluent.ssl.key.password = null
	confluent.ssl.keystore.location = null
	confluent.ssl.keystore.password = null
	confluent.ssl.keystore.type = null
	confluent.ssl.protocol = null
	confluent.ssl.truststore.location = null
	confluent.ssl.truststore.password = null
	confluent.ssl.truststore.type = null
	confluent.step.connection.rate.per.ip = -1.0
	confluent.step.connection.rate.per.tenant = -1.0
	confluent.storage.probe.period.ms = -1
	confluent.storage.probe.slow.write.threshold.ms = 5000
	confluent.stray.log.delete.delay.ms = 604800000
	confluent.stray.log.max.deletions.per.run = 72
	confluent.subdomain.prefix = null
	confluent.subdomain.separator.map = null
	confluent.subdomain.separator.variable = %sep
	confluent.system.time.roll.enable = false
	confluent.telemetry.enabled = false
	confluent.telemetry.external.client.metrics.delta.temporality = true
	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
	confluent.telemetry.external.client.metrics.push.enabled = false
	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
	confluent.telemetry.external.client.metrics.subscription.match.list = null
	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
	confluent.tenant.latency.metric.enabled = false
	confluent.tenantaware.encryption.key.manager.enable = false
	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
	confluent.tier.archiver.num.threads = 2
	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
	confluent.tier.azure.block.blob.container = null
	confluent.tier.azure.block.blob.cred.file.path = null
	confluent.tier.azure.block.blob.endpoint = null
	confluent.tier.azure.block.blob.prefix =
	confluent.tier.backend =
	confluent.tier.bucket.probe.period.ms = -1
	confluent.tier.cleaner.compact.min.efficiency = 0.5
	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
	confluent.tier.cleaner.dedupe.buffer.size = 134217728
	confluent.tier.cleaner.dual.compaction = false
	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
	confluent.tier.cleaner.dual.compaction.validation.percent = 0
	confluent.tier.cleaner.enable = false
	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
	confluent.tier.cleaner.feature.enable = false
	confluent.tier.cleaner.io.buffer.load.factor = 0.9
	confluent.tier.cleaner.io.buffer.size = 10485760
	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	confluent.tier.cleaner.min.cleanable.ratio = 0.75
	confluent.tier.cleaner.num.threads = 2
	confluent.tier.enable = false
	confluent.tier.feature = false
	confluent.tier.fenced.segment.delete.delay.ms = 600000
	confluent.tier.fetcher.async.enable = false
	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
	confluent.tier.fetcher.memorypool.bytes = 0
	confluent.tier.fetcher.num.threads = 4
	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
	confluent.tier.fetcher.offset.cache.period.ms = 60000
	confluent.tier.fetcher.offset.cache.size = 200000
	confluent.tier.gcs.bucket = null
	confluent.tier.gcs.cred.file.path = null
	confluent.tier.gcs.prefix =
	confluent.tier.gcs.region = null
	confluent.tier.gcs.sse.customer.encryption.key = null
	confluent.tier.gcs.write.chunk.size = 0
	confluent.tier.local.hotset.bytes = -1
	confluent.tier.local.hotset.ms = 86400000
	confluent.tier.max.partition.fetch.bytes.override = 0
	confluent.tier.metadata.bootstrap.servers = null
	confluent.tier.metadata.max.poll.ms = 100
	confluent.tier.metadata.namespace = null
	confluent.tier.metadata.num.partitions = 50
	confluent.tier.metadata.replication.factor = 1
	confluent.tier.metadata.request.timeout.ms = 30000
	confluent.tier.metadata.snapshots.enable = false
	confluent.tier.metadata.snapshots.interval.ms = 86400000
	confluent.tier.metadata.snapshots.retention.days = 7
	confluent.tier.metadata.snapshots.threads = 2
	confluent.tier.object.fetcher.num.threads = 1
	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
	confluent.tier.partition.state.cleanup.enable = false
	confluent.tier.partition.state.cleanup.interval.ms = 86400000
	confluent.tier.partition.state.commit.interval.ms = 15000
	confluent.tier.prefetch.cache.enable = false
	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
	confluent.tier.prefetch.cache.range.bytes = 5242880
	confluent.tier.prefetch.cache.total.size.bytes = 209715200
	confluent.tier.s3.assumerole.arn = null
	confluent.tier.s3.auto.abort.threshold.bytes = 500000
	confluent.tier.s3.aws.endpoint.override = null
	confluent.tier.s3.aws.signer.override = null
	confluent.tier.s3.bucket = null
	confluent.tier.s3.cred.file.path = null
	confluent.tier.s3.force.path.style.access = false
	confluent.tier.s3.ipv6.enabled = true
	confluent.tier.s3.prefix =
	confluent.tier.s3.region = null
	confluent.tier.s3.security.providers = null
	confluent.tier.s3.sse.algorithm = AES256
	confluent.tier.s3.sse.customer.encryption.key = null
	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.tier.s3.ssl.key.password = null
	confluent.tier.s3.ssl.keystore.location = null
	confluent.tier.s3.ssl.keystore.password = null
	confluent.tier.s3.ssl.keystore.type = null
	confluent.tier.s3.ssl.protocol = TLSv1.3
	confluent.tier.s3.ssl.provider = null
	confluent.tier.s3.ssl.truststore.location = null
	confluent.tier.s3.ssl.truststore.password = null
	confluent.tier.s3.ssl.truststore.type = null
	confluent.tier.s3.storage.class.override =
	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
	confluent.tier.s3.v2.enabled = false
	confluent.tier.segment.hotset.roll.min.bytes = 104857600
	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
	confluent.tier.topic.data.loss.validation.fencing.enable = false
	confluent.tier.topic.delete.backoff.ms = 21600000
	confluent.tier.topic.delete.check.interval.ms = 300000
	confluent.tier.topic.delete.max.inprogress.partitions = 100
	confluent.tier.topic.head.data.loss.validation.enable = true
	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
	confluent.tier.topic.materialization.from.snapshot.enable = false
	confluent.tier.topic.producer.enable.idempotence = true
	confluent.tier.topic.snapshots.enable = false
	confluent.tier.topic.snapshots.interval.ms = 300000
	confluent.tier.topic.snapshots.max.records = 100000
	confluent.tier.topic.snapshots.retention.hours = 168
	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
	confluent.topic.partition.default.placement = 2
	confluent.topic.policy.use.computed.assignments = false
	confluent.topic.replica.assignor.builder.class =
	confluent.track.api.key.per.ip = false
	confluent.track.per.ip.max.size = 100000
	confluent.track.tenant.id.per.ip = false
	confluent.traffic.cdc.network.id.routes.enable = false
	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
	confluent.traffic.network.id =
	confluent.traffic.network.type =
	confluent.transaction.2pc.timeout.ms = -1
	confluent.transaction.logging.verbosity = 0
	confluent.transaction.state.log.placement.constraints =
	confluent.unique.deprecated.request.metrics.per.tenant = 1000
	confluent.valid.broker.rack.set = null
	confluent.valid.sni.hostnames =
	confluent.valid.sni.hostnames.exclude.suffix =
	confluent.verify.group.subscription.prefix = false
	confluent.virtual.topic.creation.enabled = false
	confluent.zone.tagged.request.metrics.enable = false
	connection.failed.authentication.delay.ms = 100
	connection.min.expire.interval.ms = 250
	connections.max.age.ms = 3153600000000
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:29093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.cluster.link.policy.class.name = null
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	enable.fips = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	floor.max.connection.creation.rate = null
	follower.replication.throttled.rate = 9223372036854775807
	follower.replication.throttled.replicas = none
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	k2.stack.builder.class.name = null
	k2.startup.timeout.ms = 60000
	k2.topic.metadata.refresh.ms = 10000
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.replication.throttled.rate = 9223372036854775807
	leader.replication.throttled.replicas = none
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
	listeners = PLAINTEXT://localhost:29092,CONTROLLER://localhost:29093,PLAINTEXT_HOST://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.hash.algorithm = MD5
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.cleanup.policy.empty.validation = none
	log.deletion.max.segments.per.run = 2147483647
	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 1.7976931348623157E308
	max.connection.creation.rate.per.ip.enable.threshold = 0.0
	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.connections.per.tenant = 0
	max.connections.protected.listeners = []
	max.connections.reap.amount = 0
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	multitenant.authorizer.support.resource.ids = false
	multitenant.metadata.class = null
	multitenant.metadata.dir = null
	multitenant.metadata.reload.delay.ms = 120000
	multitenant.metadata.ssl.certs.path = null
	multitenant.tenant.delete.batch.size = 10
	multitenant.tenant.delete.check.ms = 120000
	multitenant.tenant.delete.delay = 604800000
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	otel.exporter.otlp.custom.endpoint = default
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	quotas.consumption.expiration.time.ms = 600000
	quotas.expiration.interval.ms = 3600000
	quotas.expiration.time.ms = 604800000
	quotas.lazy.evaluation.threshold = 0.5
	quotas.topic.append.timeout.ms = 5000
	quotas.topic.compression.codec = 3
	quotas.topic.load.buffer.size = 5242880
	quotas.topic.num.partitions = 50
	quotas.topic.placement.constraints =
	quotas.topic.replication.factor = 3
	quotas.topic.segment.bytes = 104857600
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.authn.async.enable = false
	sasl.server.authn.async.max.threads = 1
	sasl.server.authn.async.timeout.ms = 30000
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	throughput.quota.window.num = 11
	token.impersonation.validation = true
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.metadata.load.threads = 32
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,437] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-06-09 19:34:59,469] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2025-06-09 19:34:59,469] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2025-06-09 19:34:59,469] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
[2025-06-09 19:34:59,469] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2025-06-09 19:34:59,470] INFO Awaiting socket connections on localhost:29092. (kafka.network.DataPlaneAcceptor)
[2025-06-09 19:34:59,472] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-06-09 19:34:59,472] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2025-06-09 19:34:59,472] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-06-09 19:34:59,472] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2025-06-09 19:34:59,522] INFO Application provider 'MetadataApiApplicationProvider' provided 1 instance(s). (io.confluent.http.server.KafkaHttpApplicationLoader)
[2025-06-09 19:34:59,523] INFO MetadataServerConfig values:
	confluent.http.server.listeners = [http://0.0.0.0:8090]
	confluent.metadata.server.advertised.listeners = null
	confluent.metadata.server.enable = false
	confluent.metadata.server.kraft.controller.enabled = false
	confluent.metadata.server.listeners = null
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,523] INFO Application provider 'RbacApplicationProvider' did not provide any instances. (io.confluent.http.server.KafkaHttpApplicationLoader)
[2025-06-09 19:34:59,527] INFO KafkaConfig values:
	add.partitions.to.txn.retry.backoff.max.ms = 100
	add.partitions.to.txn.retry.backoff.ms = 20
	advertised.listeners = PLAINTEXT://localhost:29092,PLAINTEXT_HOST://localhost:9092
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name =
	auto.create.topics.enable = false
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.interceptor.class = class org.apache.kafka.server.interceptor.DefaultBrokerInterceptor
	broker.rack = null
	broker.session.timeout.ms = 9000
	broker.session.uuid = GwXCsAj0RRqEIfy8wh6Zwg
	client.quota.callback.class = null
	client.quota.max.throttle.time.in.response.ms = 60000
	client.quota.max.throttle.time.ms = 5000
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	confluent.accp.enabled = false
	confluent.acks.equal.to.one.request.replication.lag.threshold.ms = -1
	confluent.alter.broker.health.max.demoted.brokers = 2147483647
	confluent.alter.broker.health.max.demoted.brokers.percentage = 0
	confluent.ansible.managed = false
	confluent.api.visibility = DEFAULT
	confluent.append.record.interceptor.classes = []
	confluent.apply.create.topic.policy.to.create.partitions = false
	confluent.authorizer.authority.name =
	confluent.automatic.alter.broker.health.retry.backoff.ms = 2000
	confluent.backpressure.disk.enable = false
	confluent.backpressure.disk.free.threshold.bytes = 21474836480
	confluent.backpressure.disk.produce.bytes.per.second = 131072
	confluent.backpressure.disk.threshold.recovery.factor = 1.5
	confluent.backpressure.request.min.broker.limit = 200
	confluent.backpressure.request.queue.size.percentile = p95
	confluent.backpressure.types = null
	confluent.balancer.api.state.topic = _confluent_balancer_api_state
	confluent.balancer.broker.addition.elapsed.time.ms.completion.threshold = 57600000
	confluent.balancer.broker.addition.mean.cpu.percent.completion.threshold = 0.5
	confluent.balancer.capacity.threshold.upper.limit = 0.95
	confluent.balancer.cell.load.upper.bound = 0.7
	confluent.balancer.cell.overload.detection.interval.ms = 3600000
	confluent.balancer.cell.overload.duration.ms = 86400000
	confluent.balancer.class = io.confluent.databalancer.SbcDataBalanceManager
	confluent.balancer.consumer.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.cpu.balance.threshold = 1.1
	confluent.balancer.cpu.goal.act.as.capacity.goal = false
	confluent.balancer.cpu.low.utilization.threshold = 0.2
	confluent.balancer.cpu.utilization.detector.duration.ms = 600000
	confluent.balancer.cpu.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.cpu.utilization.detector.underutilization.threshold = 50.0
	confluent.balancer.disk.max.load = 0.85
	confluent.balancer.disk.min.free.space.gb = 0
	confluent.balancer.disk.min.free.space.lower.limit.gb = 0
	confluent.balancer.disk.utilization.detector.duration.ms = 600000
	confluent.balancer.disk.utilization.detector.overutilization.threshold = 80.0
	confluent.balancer.disk.utilization.detector.reserved.capacity = 150000.0
	confluent.balancer.disk.utilization.detector.underutilization.threshold = 35.0
	confluent.balancer.enable = false
	confluent.balancer.enable.network.capacity.metric.ingestion = false
	confluent.balancer.exclude.topic.names = []
	confluent.balancer.exclude.topic.prefixes = []
	confluent.balancer.flex.fanout.network.capacity.metrics.avg.period.ms = 1800000
	confluent.balancer.goal.violation.delay.on.new.brokers.ms = 1800000
	confluent.balancer.goal.violation.distribution.threshold.multiplier = 1.1
	confluent.balancer.heal.broker.failure.threshold.ms = 3600000
	confluent.balancer.heal.uneven.load.trigger = EMPTY_BROKER
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.enabled = true
	confluent.balancer.incremental.balancing.cpu.top.proposal.tracking.num.proposals = 15
	confluent.balancer.incremental.balancing.enabled = false
	confluent.balancer.incremental.balancing.goals = []
	confluent.balancer.incremental.balancing.lower.bound = 0.02
	confluent.balancer.incremental.balancing.min.valid.windows = 5
	confluent.balancer.incremental.balancing.step.ratio = 0.2
	confluent.balancer.inter.cell.balancing.enabled = false
	confluent.balancer.max.capacity.balancing.delta.percentage = 0.0
	confluent.balancer.max.replicas = 2147483647
	confluent.balancer.minimum.reported.brokers.with.network.capacity.metrics.percentage = 0.8
	confluent.balancer.network.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.network.out.max.bytes.per.second = 9223372036854775807
	confluent.balancer.num.concurrent.replica.movements.as.destination.per.broker = 18
	confluent.balancer.num.concurrent.replica.movements.as.source.per.broker = 12
	confluent.balancer.plan.computation.retry.timeout.ms = 3600000
	confluent.balancer.producer.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.rebalancing.goals = []
	confluent.balancer.replication.in.max.bytes.per.second = 9223372036854775807
	confluent.balancer.resource.utilization.detector.interval.ms = 60000
	confluent.balancer.sbc.metrics.parser.enabled = false
	confluent.balancer.self.healing.maximum.rounds = 1
	confluent.balancer.task.history.retention.days = 30
	confluent.balancer.tenant.maximum.movements = 0
	confluent.balancer.tenant.suspension.ms = 86400000
	confluent.balancer.throttle.bytes.per.second = 10485760
	confluent.balancer.topic.balancing.itrdg.with.hard.goals.enabled = false
	confluent.balancer.topic.partition.maximum.movements = 3
	confluent.balancer.topic.partition.movement.expiration.ms = 3600000
	confluent.balancer.topic.partition.movements.history.limit = 900
	confluent.balancer.topic.partition.suspension.ms = 3600000
	confluent.balancer.topic.replication.factor = 1
	confluent.balancer.triggering.goals = []
	confluent.balancer.v2.addition.enabled = false
	confluent.balancer.v2.addition.reassignment.cancellations.enabled = false
	confluent.balancer.v2.executor.enabled = false
	confluent.basic.auth.credentials.source = null
	confluent.basic.auth.user.info = null
	confluent.bearer.assertion.claim.aud = null
	confluent.bearer.assertion.claim.exp.minutes = null
	confluent.bearer.assertion.claim.iss = null
	confluent.bearer.assertion.claim.jti.include = null
	confluent.bearer.assertion.claim.nbf.include = null
	confluent.bearer.assertion.claim.sub = null
	confluent.bearer.assertion.file = null
	confluent.bearer.assertion.private.key.file = null
	confluent.bearer.assertion.private.key.passphrase = null
	confluent.bearer.assertion.template.file = null
	confluent.bearer.auth.cache.expiry.buffer.seconds = 300
	confluent.bearer.auth.client.id = null
	confluent.bearer.auth.client.secret = null
	confluent.bearer.auth.credentials.source = null
	confluent.bearer.auth.identity.pool.id = null
	confluent.bearer.auth.issuer.endpoint.url = null
	confluent.bearer.auth.logical.cluster = null
	confluent.bearer.auth.scope = null
	confluent.bearer.auth.scope.claim.name = scope
	confluent.bearer.auth.sub.claim.name = sub
	confluent.bearer.auth.token = null
	confluent.broker.health.manager.enabled = true
	confluent.broker.health.manager.engine.request.handler.threads.stuck.criteria = AllThreadsStuck
	confluent.broker.health.manager.hard.kill.duration.ms = 60000
	confluent.broker.health.manager.mitigation.enabled = false
	confluent.broker.health.manager.num.samples.before.broker.suspect = 30
	confluent.broker.health.manager.num.samples.before.broker.unhealthy = 180
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.suspect = 90
	confluent.broker.health.manager.percentage.unhealthy.samples.before.broker.unhealthy = 70
	confluent.broker.health.manager.sample.duration.ms = 1000
	confluent.broker.health.manager.storage.background.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.network.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.health.manager.storage.request.handler.threads.stuck.criteria = AnyThreadStuck
	confluent.broker.limit.consumer.bytes.per.second = 9223372036854775807
	confluent.broker.limit.producer.bytes.per.second = 9223372036854775807
	confluent.broker.load.advertised.limit.load = 0.8
	confluent.broker.load.average.service.request.time.ms = 0.1
	confluent.broker.load.delay.metric.start.ms = 180000
	confluent.broker.load.enabled = false
	confluent.broker.load.num.samples = 60
	confluent.broker.load.tenant.metric.enable = false
	confluent.broker.load.update.metric.tags.interval.ms = 60000
	confluent.broker.load.window.size.ms = 60000
	confluent.broker.load.workload.coefficient = 20.0
	confluent.broker.registration.delay.ms = 0
	confluent.calling.resource.identity.type.map =
	confluent.catalog.collector.destination.topic = telemetry.events.data_catalog_source
	confluent.catalog.collector.enable = false
	confluent.catalog.collector.full.configs.enable = false
	confluent.catalog.collector.max.bytes.per.snapshot = 850000
	confluent.catalog.collector.max.topics.process = 500
	confluent.catalog.collector.max.zookeeper.request.per.sec = 100
	confluent.catalog.collector.multitenant.topics.enable = true
	confluent.catalog.collector.snapshot.init.delay.sec = 60
	confluent.catalog.collector.snapshot.interval.sec = 300
	confluent.ccloud.host.suffixes = .confluent.cloud,.cpdev.cloud,.confluentgov.com,.confluentgov-internal.com
	confluent.ccloud.intranet.host.suffixes = .intranet.stag.cpdev.cloud,.intranet.stag.cpdev-untrusted.cloud,.intranet.devel.cpdev.cloud,.intranet.devel.cpdev-untrusted.cloud,.intranet.confluent.cloud,.intranet.confluent-untrusted.cloud
	confluent.cdc.api.keys.topic =
	confluent.cdc.api.keys.topic.load.timeout.ms = 600000
	confluent.cdc.client.quotas.enable = false
	confluent.cdc.client.quotas.topic.name =
	confluent.cdc.lkc.metadata.topic =
	confluent.cdc.user.metadata.enable = false
	confluent.cdc.user.metadata.topic = _confluent-user_metadata
	confluent.cell.metrics.refresh.period.ms = 60000
	confluent.cells.default.size = 15
	confluent.cells.enable = false
	confluent.cells.implicit.creation.enable = false
	confluent.cells.k2.base.broker.index = -1
	confluent.cells.load.refresher.enable = true
	confluent.cells.max.size = 15
	confluent.cells.min.size = 6
	confluent.checksum.enabled.files = [none]
	confluent.client.topic.max.metrics.count = 1000
	confluent.client.topic.metrics.expiry.sec = 3600
	confluent.client.topic.metrics.manager = class org.apache.kafka.server.metrics.ClientTopicMetricsManager$NoOpClientTopicMetricsManager
	confluent.clm.enabled = false
	confluent.clm.frequency.in.hours = 6
	confluent.clm.list.object.thread_pool.size = 1
	confluent.clm.max.backup.days = 3
	confluent.clm.min.delay.in.minutes = 30
	confluent.clm.thread.pool.size = 2
	confluent.clm.topic.retention.days.to.backup.days = 0:0,3:3
	confluent.close.connections.on.credential.delete = false
	confluent.cluster.link.admin.max.in.flight.requests = 1000
	confluent.cluster.link.admin.request.batch.size = 1
	confluent.cluster.link.allow.config.providers = true
	confluent.cluster.link.allow.legacy.message.format = false
	confluent.cluster.link.allow.truncation.below.hwm = false
	confluent.cluster.link.availability.check.mode = ALL
	confluent.cluster.link.background.thread.affinity = LINK
	confluent.cluster.link.bootstrap.translation.feature.enable = true
	confluent.cluster.link.clients.max.idle.ms = 3153600000000
	confluent.cluster.link.enable = true
	confluent.cluster.link.enable.local.admin = false
	confluent.cluster.link.enable.metrics.reduction = false
	confluent.cluster.link.enable.metrics.reduction.advanced = false
	confluent.cluster.link.fetch.response.min.bytes = 1
	confluent.cluster.link.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.fetcher.auto.tune.enable = false
	confluent.cluster.link.fetcher.thread.pool.mode = ENDPOINT
	confluent.cluster.link.insync.fetch.response.min.bytes = 1
	confluent.cluster.link.insync.fetch.response.total.bytes = 2147483647
	confluent.cluster.link.intranet.connectivity.denied.org.ids = []
	confluent.cluster.link.intranet.connectivity.enable = false
	confluent.cluster.link.intranet.connectivity.migration.enable = false
	confluent.cluster.link.io.max.bytes.per.second = 9223372036854775807
	confluent.cluster.link.local.admin.multitenant.enable = false
	confluent.cluster.link.local.reverse.connection.listener.map = null
	confluent.cluster.link.max.client.connections = 2147483647
	confluent.cluster.link.metadata.topic.create.retry.delay.ms = 1000
	confluent.cluster.link.metadata.topic.enable = false
	confluent.cluster.link.metadata.topic.min.isr = 2
	confluent.cluster.link.metadata.topic.partitions = 50
	confluent.cluster.link.metadata.topic.replication.factor = 1
	confluent.cluster.link.mirror.transition.batch.size = 10
	confluent.cluster.link.num.background.threads = 1
	confluent.cluster.link.periodic.task.batch.size = 2147483647
	confluent.cluster.link.periodic.task.min.interval.ms = 1000
	confluent.cluster.link.persistent.connection.backoff.max.ms = 0
	confluent.cluster.link.replica.fetch.connections.mode = combined
	confluent.cluster.link.replication.quota.mode = CLUSTER_LINK_ONLY
	confluent.cluster.link.replication.quota.mode.per.tenant.overrides =
	confluent.cluster.link.replication.quota.window.num = 11
	confluent.cluster.link.replication.quota.window.size.seconds = 2
	confluent.cluster.link.request.quota.capacity = 400
	confluent.cluster.link.request.quota.request.percentage.multiplier = 1.0
	confluent.cluster.link.switchover.disabled.principals = []
	confluent.cluster.link.switchover.enable = false
	confluent.cluster.link.switchover.listeners = []
	confluent.cluster.link.switchover.server.states = []
	confluent.cluster.link.tenant.replication.quota.enable = false
	confluent.cluster.link.tenant.request.quota.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.enable = false
	confluent.cluster.metadata.snapshot.tier.delete.maintain.min.snapshots = 3
	confluent.cluster.metadata.snapshot.tier.delete.retention.ms = 604800000
	confluent.cluster.metadata.snapshot.tier.upload.enable = false
	confluent.compacted.topic.prefer.tier.fetch.ms = -1
	confluent.connection.invalid.request.delay.enable = false
	confluent.connections.idle.expiry.manager.ignore.idleness.requests = []
	confluent.consumer.fetch.partition.pruning.enable = true
	confluent.consumer.lag.emitter.enabled = false
	confluent.consumer.lag.emitter.interval.ms = 60000
	confluent.dataflow.policy.watch.monitor.ms = 300000
	confluent.default.data.policy.enforcement = true
	confluent.defer.isr.shrink.enable = false
	confluent.describe.topic.partitions.enabled = true
	confluent.disk.io.manager.enable = false
	confluent.disk.throughput.headroom = 10485760
	confluent.disk.throughput.limit = 10485760000
	confluent.disk.throughput.quota.tier.archive = 1048576000
	confluent.disk.throughput.quota.tier.archive.throttled = 104857600
	confluent.durability.audit.batch.flush.frequency.ms = 900000
	confluent.durability.audit.checks = PeriodicalAudit,ChecksumAudit
	confluent.durability.audit.enable = false
	confluent.durability.audit.idempotent.producer = false
	confluent.durability.audit.initial.job.delay.ms = 900000
	confluent.durability.audit.io.bytes.per.sec = 10485760
	confluent.durability.audit.log.ignored.event.types =
	confluent.durability.audit.reporting.batch.ms = 1800000
	confluent.durability.audit.tier.compaction.audit.duration.ms = 14400000
	confluent.durability.events.allowed = OffsetChangeType,EpochChangeType,IsrExpandType,DeleteRecordsType,RetentionChangeType,StartOffsetChangeType,DeletePartitionType,HealthCheckType
	confluent.durability.topic.partition.count = 50
	confluent.durability.topic.replication.factor = 1
	confluent.e2e_checksum.protection.enabled = false
	confluent.e2e_checksum.protection.files = [none]
	confluent.e2e_checksum.protection.store.entry.ttl.ms = 2592000000
	confluent.elastic.cku.enabled = false
	confluent.elastic.cku.scaletozero.enabled = false
	confluent.eligible.controllers = []
	confluent.enable.broker.reporting.min.usage.mode = true
	confluent.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.fail.unsatisfied.placement.constraints = false
	confluent.fetch.from.follower.require.leader.epoch.enable = false
	confluent.fetch.partition.pruning.enable = true
	confluent.flexible.fanout.broker.max.fetch.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.max.produce.bytes.per.second = 9223372036854775807
	confluent.flexible.fanout.broker.min.producer.percentage = 10.0
	confluent.flexible.fanout.broker.network.out.bytes.per.second = 6200000
	confluent.flexible.fanout.broker.recompute.interval.ms = 30000
	confluent.flexible.fanout.broker.storage.bytes.per.second = 512000000
	confluent.flexible.fanout.enabled = false
	confluent.flexible.fanout.lazy.evaluation.threshold = 0.5
	confluent.flexible.fanout.mode = TENANT_QUOTA
	confluent.floor.connection.rate.per.ip = -1.0
	confluent.floor.connection.rate.per.tenant = -1.0
	confluent.group.coordinator.dynamic.append.linger.enable = false
	confluent.group.coordinator.offsets.batching.enable = false
	confluent.group.coordinator.offsets.writer.threads = 2
	confluent.group.coordinator.txn.offset.validation.enable = false
	confluent.group.highest.offset.commit.rates.log.count = 10
	confluent.group.highest.offset.commit.rates.log.enable = false
	confluent.group.highest.offset.commit.rates.log.interval.ms = 300000
	confluent.group.metadata.load.threads = 32
	confluent.group.subscription.pattern.log.interval.ms = -1
	confluent.heap.tenured.notify.bytes = 0
	confluent.heap.tenured.notify.enabled = false
	confluent.hot.partition.ratio = 0.8
	confluent.http.server.start.timeout.ms = 60000
	confluent.http.server.stop.timeout.ms = 30000
	confluent.internal.metrics.enable = false
	confluent.internal.rest.server.bind.port = null
	confluent.internal.rest.server.ssl.enable = false
	confluent.internal.tenant.scoped.listener.name = INTERNAL_TENANT_SCOPED
	confluent.leader.epoch.checkpoint.checksum.enabled = false
	confluent.listener.protocol = TCP
	confluent.log.cleaner.timestamp.validation.enable = true
	confluent.log.placement.constraints =
	confluent.max.broker.load = 1.0
	confluent.max.connection.creation.rate.per.ip = 1.7976931348623157E308
	confluent.max.connection.creation.rate.per.tenant = 1.7976931348623157E308
	confluent.max.connection.rate.per.ip = -1.0
	confluent.max.connection.rate.per.tenant = -1.0
	confluent.max.connection.throttle.ms = null
	confluent.max.segment.ms = 9223372036854775807
	confluent.metadata.active.encryptor = null
	confluent.metadata.controlled.shutdown.partition.slice.delay.ms = 100
	confluent.metadata.encryptor.classes = null
	confluent.metadata.encryptor.required = false
	confluent.metadata.encryptor.secret.file = null
	confluent.metadata.encryptor.secrets = null
	confluent.metadata.jvm.warmup.ms = 60000
	confluent.metadata.leader.balance.slice.delay.ms = 100
	confluent.metadata.max.controlled.shutdown.partition.changes.per.slice = 1000
	confluent.metadata.max.leader.balance.changes.per.slice = 1000
	confluent.metadata.reject.when.throttled.enable = false
	confluent.metadata.server.cluster.registry.clusters = []
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.min.acks = 0
	confluent.min.connection.throttle.ms = 0
	confluent.min.segment.ms = 1
	confluent.missing.id.cache.ttl.sec = 60
	confluent.missing.id.query.range = 20000
	confluent.missing.schema.cache.ttl.sec = 60
	confluent.mtls.build.client.cert.chain.enable = false
	confluent.mtls.enable = false
	confluent.mtls.listener.name = EXTERNAL
	confluent.mtls.sasl.authenticator.request.max.bytes = 104857600
	confluent.mtls.truststore.alter.configs.timeout.ms = 300000
	confluent.mtls.truststore.manager.class.name = null
	confluent.multitenant.authorizer.enable.acl.state = false
	confluent.multitenant.interceptor.balancer.apis.enabled = false
	confluent.multitenant.interceptor.collect.client.apiversions.max.per.tenant = 1000
	confluent.multitenant.interceptor.collect.client.apiversions.metric = false
	confluent.multitenant.listener.hostname.cluster.prefix.enable = false
	confluent.multitenant.listener.hostname.subdomain.suffix.enable = false
	confluent.multitenant.listener.names = null
	confluent.multitenant.parse.lkc.id.enable = false
	confluent.multitenant.parse.sni.host.name.enable = false
	confluent.network.health.manager.enabled = false
	confluent.network.health.manager.external.listener.name = EXTERNAL
	confluent.network.health.manager.externalconnectivitystartup.enabled = false
	confluent.network.health.manager.min.healthy.network.samples = 3
	confluent.network.health.manager.min.percentage.healthy.network.samples = 3
	confluent.network.health.manager.mitigation.enabled = false
	confluent.network.health.manager.network.sample.window.size = 120
	confluent.network.health.manager.sample.duration.ms = 1000
	confluent.oauth.flat.networking.verification.enable = false
	confluent.offsets.log.cleaner.delete.retention.ms = 86400000
	confluent.offsets.log.cleaner.max.compaction.lag.ms = 9223372036854775807
	confluent.offsets.log.cleaner.min.cleanable.dirty.ratio = 0.5
	confluent.offsets.topic.placement.constraints =
	confluent.omit.network.processor.metric.tag = false
	confluent.operator.managed = false
	confluent.password.encoder.old.secret.ttl.ms = 9223372036854775807
	confluent.plugins.cluster.link.policy.max.destination.links.per.tenant = 10
	confluent.plugins.cluster.link.policy.max.source.links.per.tenant = 10
	confluent.plugins.topic.policy.max.partitions.per.cluster = 2147483647
	confluent.plugins.topic.policy.max.partitions.per.tenant = 512
	confluent.plugins.topic.policy.max.replicas.per.broker = 2147483647
	confluent.plugins.topic.policy.max.topics.per.cluster = 2147483647
	confluent.ppv2.endpoint.scheme.bootstrap.broker.template.mappings =
	confluent.ppv2.endpoint.scheme.enable = false
	confluent.ppv2.endpoint.scheme.map.broker.zone.to.gateway.zone = false
	confluent.ppv2.endpoint.scheme.template.variable.cloud =
	confluent.ppv2.endpoint.scheme.template.variable.domain =
	confluent.ppv2.endpoint.scheme.template.variable.region =
	confluent.ppv2.endpoint.scheme.template.variables =
	confluent.ppv2.endpoint.scheme.templates =
	confluent.prefer.tier.fetch.ms = -1
	confluent.produce.throttle.pre.check.enable = false
	confluent.produce.throttle.pre.check.for.new.connection.enable = false
	confluent.producer.id.cache.broker.hard.limit = -1
	confluent.producer.id.cache.eviction.minimal.expiration.ms = 900000
	confluent.producer.id.cache.extra.eviction.percentage = 0
	confluent.producer.id.cache.limit = 2147483647
	confluent.producer.id.cache.partition.hard.limit = -1
	confluent.producer.id.cache.tenant.hard.limit = -1
	confluent.producer.id.quota.manager.enable = false
	confluent.producer.id.quota.window.num = 11
	confluent.producer.id.quota.window.size.seconds = 1
	confluent.producer.id.throttle.enable = false
	confluent.producer.id.throttle.enable.threshold.percentage = 100
	confluent.proxy.mode.local.default = false
	confluent.proxy.protocol.fallback.enabled = false
	confluent.proxy.protocol.version = NONE
	confluent.quota.computing.usage.adjustment = 0.5
	confluent.quota.dynamic.adjustment.min.usage = 102400
	confluent.quota.dynamic.enable = false
	confluent.quota.dynamic.publishing.interval.ms = 60000
	confluent.quota.dynamic.reporting.interval.ms = 30000
	confluent.quota.tenant.broker.max.consumer.rate = 13107200
	confluent.quota.tenant.broker.max.producer.rate = 13107200
	confluent.quota.tenant.default.controller.mutation.rate = 2.147483647E9
	confluent.quota.tenant.default.producer.id.rate = 2.147483647E9
	confluent.quota.tenant.fetch.multiplier = 1.0
	confluent.quota.tenant.follower.broker.min.consumer.rate = 10485760
	confluent.quota.tenant.follower.broker.min.producer.rate = 10485760
	confluent.quota.tenant.internal.broker.max.consumer.rate = 9223372036854775807
	confluent.quota.tenant.internal.broker.max.producer.rate = 9223372036854775807
	confluent.quota.tenant.internal.throttling.enable = false
	confluent.quota.tenant.produce.multiplier = 1.0
	confluent.quota.tenant.user.quotas.enable = false
	confluent.rack.id.mapping = null
	confluent.regional.metadata.client.class = null
	confluent.regional.resource.manager.client.scheduler.threads = 2
	confluent.regional.resource.manager.endpoint = null
	confluent.regional.resource.manager.watch.endpoint = null
	confluent.replica.fetch.backoff.max.ms = 1000
	confluent.replica.fetch.connections.mode = combined
	confluent.replication.mode = PULL
	confluent.replication.push.feature.enable = false
	confluent.reporters.telemetry.auto.enable = true
	confluent.request.log.filter.class = class org.apache.kafka.common.requests.SamplingRequestLogFilter
	confluent.request.pipelining.enable = true
	confluent.request.pipelining.max.in.flight.requests.per.connection = 5
	confluent.require.calling.resource.identity = false
	confluent.require.compatible.keystore.updates = true
	confluent.require.confluent.issuer = false
	confluent.roll.check.interval.ms = 300000
	confluent.schema.registry.max.cache.size = 10000
	confluent.schema.registry.max.retries = 1
	confluent.schema.registry.retries.wait.ms = 0
	confluent.schema.registry.url = null
	confluent.schema.validation.context.name.enable = false
	confluent.schema.validator.interceptor.class = io.confluent.kafka.schemaregistry.validator.RecordSchemaValidator
	confluent.schema.validator.multitenant.enable = false
	confluent.schema.validator.samples.per.min = 0
	confluent.security.bc.approved.mode.enable = false
	confluent.security.event.logger.authentication.enable = false
	confluent.security.event.logger.authentication.event.rate.limit = -1
	confluent.security.event.logger.authorization.event.rate.limit = -1
	confluent.security.event.logger.detailed.audit.logs.filter.class = class org.apache.kafka.common.requests.DetailedRequestAuditLogFilter
	confluent.security.event.logger.enable = true
	confluent.security.event.logger.kafka.request.rate.limit = -1
	confluent.security.event.logger.physical.cluster.id =
	confluent.security.event.router.config =
	confluent.security.revoked.certificate.ids =
	confluent.segment.eager.roll.enable = false
	confluent.segment.speculative.prefetch.enable = false
	confluent.share.metadata.load.threads = 32
	confluent.spiffe.id.principal.extraction.rules =
	confluent.ssl.key.password = null
	confluent.ssl.keystore.location = null
	confluent.ssl.keystore.password = null
	confluent.ssl.keystore.type = null
	confluent.ssl.protocol = null
	confluent.ssl.truststore.location = null
	confluent.ssl.truststore.password = null
	confluent.ssl.truststore.type = null
	confluent.step.connection.rate.per.ip = -1.0
	confluent.step.connection.rate.per.tenant = -1.0
	confluent.storage.probe.period.ms = -1
	confluent.storage.probe.slow.write.threshold.ms = 5000
	confluent.stray.log.delete.delay.ms = 604800000
	confluent.stray.log.max.deletions.per.run = 72
	confluent.subdomain.prefix = null
	confluent.subdomain.separator.map = null
	confluent.subdomain.separator.variable = %sep
	confluent.system.time.roll.enable = false
	confluent.telemetry.enabled = false
	confluent.telemetry.external.client.metrics.delta.temporality = true
	confluent.telemetry.external.client.metrics.instance.cache.size = 16384
	confluent.telemetry.external.client.metrics.push.enabled = false
	confluent.telemetry.external.client.metrics.subscription.interval.ms.list = null
	confluent.telemetry.external.client.metrics.subscription.match.list = null
	confluent.telemetry.external.client.metrics.subscription.metrics.list = null
	confluent.tenant.latency.metric.enabled = false
	confluent.tenantaware.encryption.key.manager.enable = false
	confluent.tenantaware.encryption.key.manager.rotation.interval.ms = 31536000000
	confluent.tenantaware.encryption.key.manager.tenant.cache.eviction.time.sec = 172800
	confluent.tenantaware.encryption.key.manager.tenant.cache.size = 100
	confluent.tier.archiver.num.threads = 2
	confluent.tier.azure.block.blob.auto.abort.threshold.bytes = 500000
	confluent.tier.azure.block.blob.container = null
	confluent.tier.azure.block.blob.cred.file.path = null
	confluent.tier.azure.block.blob.endpoint = null
	confluent.tier.azure.block.blob.prefix =
	confluent.tier.backend =
	confluent.tier.bucket.probe.period.ms = -1
	confluent.tier.cleaner.compact.min.efficiency = 0.5
	confluent.tier.cleaner.compact.segment.min.bytes = 20971520
	confluent.tier.cleaner.dedupe.buffer.size = 134217728
	confluent.tier.cleaner.dual.compaction = false
	confluent.tier.cleaner.dual.compaction.validation.max.bytes = 1073741824
	confluent.tier.cleaner.dual.compaction.validation.percent = 0
	confluent.tier.cleaner.enable = false
	confluent.tier.cleaner.excluded.topics = [^_confluent.*]
	confluent.tier.cleaner.feature.enable = false
	confluent.tier.cleaner.io.buffer.load.factor = 0.9
	confluent.tier.cleaner.io.buffer.size = 10485760
	confluent.tier.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	confluent.tier.cleaner.min.cleanable.ratio = 0.75
	confluent.tier.cleaner.num.threads = 2
	confluent.tier.enable = false
	confluent.tier.feature = false
	confluent.tier.fenced.segment.delete.delay.ms = 600000
	confluent.tier.fetcher.async.enable = false
	confluent.tier.fetcher.async.timestamp.offset.parallelism = 1
	confluent.tier.fetcher.fetch.based.on.segment_and_metadata_layout.field = false
	confluent.tier.fetcher.memorypool.bytes = 0
	confluent.tier.fetcher.num.threads = 4
	confluent.tier.fetcher.offset.cache.expiration.ms = 1800000
	confluent.tier.fetcher.offset.cache.period.ms = 60000
	confluent.tier.fetcher.offset.cache.size = 200000
	confluent.tier.gcs.bucket = null
	confluent.tier.gcs.cred.file.path = null
	confluent.tier.gcs.prefix =
	confluent.tier.gcs.region = null
	confluent.tier.gcs.sse.customer.encryption.key = null
	confluent.tier.gcs.write.chunk.size = 0
	confluent.tier.local.hotset.bytes = -1
	confluent.tier.local.hotset.ms = 86400000
	confluent.tier.max.partition.fetch.bytes.override = 0
	confluent.tier.metadata.bootstrap.servers = null
	confluent.tier.metadata.max.poll.ms = 100
	confluent.tier.metadata.namespace = null
	confluent.tier.metadata.num.partitions = 50
	confluent.tier.metadata.replication.factor = 1
	confluent.tier.metadata.request.timeout.ms = 30000
	confluent.tier.metadata.snapshots.enable = false
	confluent.tier.metadata.snapshots.interval.ms = 86400000
	confluent.tier.metadata.snapshots.retention.days = 7
	confluent.tier.metadata.snapshots.threads = 2
	confluent.tier.object.fetcher.num.threads = 1
	confluent.tier.partition.state.cleanup.delay.ms = 2592000000
	confluent.tier.partition.state.cleanup.enable = false
	confluent.tier.partition.state.cleanup.interval.ms = 86400000
	confluent.tier.partition.state.commit.interval.ms = 15000
	confluent.tier.prefetch.cache.enable = false
	confluent.tier.prefetch.cache.entry.size.bytes = 1048576
	confluent.tier.prefetch.cache.range.bytes = 5242880
	confluent.tier.prefetch.cache.total.size.bytes = 209715200
	confluent.tier.s3.assumerole.arn = null
	confluent.tier.s3.auto.abort.threshold.bytes = 500000
	confluent.tier.s3.aws.endpoint.override = null
	confluent.tier.s3.aws.signer.override = null
	confluent.tier.s3.bucket = null
	confluent.tier.s3.cred.file.path = null
	confluent.tier.s3.force.path.style.access = false
	confluent.tier.s3.ipv6.enabled = true
	confluent.tier.s3.prefix =
	confluent.tier.s3.region = null
	confluent.tier.s3.security.providers = null
	confluent.tier.s3.sse.algorithm = AES256
	confluent.tier.s3.sse.customer.encryption.key = null
	confluent.tier.s3.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.tier.s3.ssl.key.password = null
	confluent.tier.s3.ssl.keystore.location = null
	confluent.tier.s3.ssl.keystore.password = null
	confluent.tier.s3.ssl.keystore.type = null
	confluent.tier.s3.ssl.protocol = TLSv1.3
	confluent.tier.s3.ssl.provider = null
	confluent.tier.s3.ssl.truststore.location = null
	confluent.tier.s3.ssl.truststore.password = null
	confluent.tier.s3.ssl.truststore.type = null
	confluent.tier.s3.storage.class.override =
	confluent.tier.s3.user.agent.prefix = APN/1.0 Confluent/1.0 TieredStorageS3/1.0
	confluent.tier.s3.v2.enabled = false
	confluent.tier.segment.hotset.roll.min.bytes = 104857600
	confluent.tier.segment.metadata.layout.put.mode = LegacyMultiObject
	confluent.tier.topic.data.loss.validation.fencing.enable = false
	confluent.tier.topic.delete.backoff.ms = 21600000
	confluent.tier.topic.delete.check.interval.ms = 300000
	confluent.tier.topic.delete.max.inprogress.partitions = 100
	confluent.tier.topic.head.data.loss.validation.enable = true
	confluent.tier.topic.head.data.loss.validation.max.timeout.ms = 900000
	confluent.tier.topic.materialization.from.snapshot.enable = false
	confluent.tier.topic.producer.enable.idempotence = true
	confluent.tier.topic.snapshots.enable = false
	confluent.tier.topic.snapshots.interval.ms = 300000
	confluent.tier.topic.snapshots.max.records = 100000
	confluent.tier.topic.snapshots.retention.hours = 168
	confluent.topic.metadata.throttle.pre.check.partition.count.threshold = 1000
	confluent.topic.partition.default.placement = 2
	confluent.topic.policy.use.computed.assignments = false
	confluent.topic.replica.assignor.builder.class =
	confluent.track.api.key.per.ip = false
	confluent.track.per.ip.max.size = 100000
	confluent.track.tenant.id.per.ip = false
	confluent.traffic.cdc.network.id.routes.enable = false
	confluent.traffic.cdc.network.id.routes.listener.names = EXTERNAL_BACKCHANNEL
	confluent.traffic.cdc.network.id.routes.periodic.start.task.ms = 300000
	confluent.traffic.cdc.network.id.routes.topic.name = _confluent-network_id_routes
	confluent.traffic.network.id =
	confluent.traffic.network.type =
	confluent.transaction.2pc.timeout.ms = -1
	confluent.transaction.logging.verbosity = 0
	confluent.transaction.state.log.placement.constraints =
	confluent.unique.deprecated.request.metrics.per.tenant = 1000
	confluent.valid.broker.rack.set = null
	confluent.valid.sni.hostnames =
	confluent.valid.sni.hostnames.exclude.suffix =
	confluent.verify.group.subscription.prefix = false
	confluent.virtual.topic.creation.enabled = false
	confluent.zone.tagged.request.metrics.enable = false
	connection.failed.authentication.delay.ms = 100
	connection.min.expire.interval.ms = 250
	connections.max.age.ms = 3153600000000
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	controlled.shutdown.enable = true
	controller.listener.names = CONTROLLER
	controller.performance.always.log.threshold.ms = 2000
	controller.performance.sample.period.ms = 60000
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [1@localhost:29093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.cluster.link.policy.class.name = null
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	enable.fips = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	floor.max.connection.creation.rate = null
	follower.replication.throttled.rate = 9223372036854775807
	follower.replication.throttled.replicas = none
	group.consumer.assignors = [uniform, range]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = bidirectional
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 5
	group.coordinator.new.enable = true
	group.coordinator.rebalance.protocols = [classic, consumer]
	group.coordinator.threads = 4
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	k2.stack.builder.class.name = null
	k2.startup.timeout.ms = 60000
	k2.topic.metadata.refresh.ms = 10000
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.replication.throttled.rate = 9223372036854775807
	leader.replication.throttled.replicas = none
	listener.security.protocol.map = CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
	listeners = PLAINTEXT://localhost:29092,CONTROLLER://localhost:29093,PLAINTEXT_HOST://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.hash.algorithm = MD5
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.cleanup.policy.empty.validation = none
	log.deletion.max.segments.per.run = 2147483647
	log.deletion.throttler.disk.free.headroom.bytes = 21474836480
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /var/lib/kafka/data
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.timestamp.after.max.ms = 3600000
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 1.7976931348623157E308
	max.connection.creation.rate.per.ip.enable.threshold = 0.0
	max.connection.creation.rate.per.tenant.enable.threshold = 0.0
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides =
	max.connections.per.tenant = 0
	max.connections.protected.listeners = []
	max.connections.reap.amount = 0
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	multitenant.authorizer.support.resource.ids = false
	multitenant.metadata.class = null
	multitenant.metadata.dir = null
	multitenant.metadata.reload.delay.ms = 120000
	multitenant.metadata.ssl.certs.path = null
	multitenant.tenant.delete.batch.size = 10
	multitenant.tenant.delete.check.ms = 120000
	multitenant.tenant.delete.delay = 604800000
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 2
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	otel.exporter.otlp.custom.endpoint = default
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker, controller]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	quotas.consumption.expiration.time.ms = 600000
	quotas.expiration.interval.ms = 3600000
	quotas.expiration.time.ms = 604800000
	quotas.lazy.evaluation.threshold = 0.5
	quotas.topic.append.timeout.ms = 5000
	quotas.topic.compression.codec = 3
	quotas.topic.load.buffer.size = 5242880
	quotas.topic.num.partitions = 50
	quotas.topic.placement.constraints =
	quotas.topic.replication.factor = 3
	quotas.topic.segment.bytes = 104857600
	remote.fetch.max.wait.ms = 500
	remote.list.offsets.request.timeout.ms = 30000
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 2
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.authn.async.enable = false
	sasl.server.authn.async.max.threads = 1
	sasl.server.authn.async.timeout.ms = 30000
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	share.coordinator.append.linger.ms = 5
	share.coordinator.load.buffer.size = 5242880
	share.coordinator.snapshot.update.records.per.snapshot = 500
	share.coordinator.state.topic.compression.codec = 0
	share.coordinator.state.topic.min.isr = 2
	share.coordinator.state.topic.num.partitions = 50
	share.coordinator.state.topic.prune.interval.ms = 300000
	share.coordinator.state.topic.replication.factor = 3
	share.coordinator.state.topic.segment.bytes = 104857600
	share.coordinator.threads = 1
	share.coordinator.write.timeout.ms = 5000
	share.fetch.max.fetch.records = 2147483647
	share.fetch.purgatory.purge.interval.requests = 1000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	throughput.quota.window.num = 11
	token.impersonation.validation = true
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.metadata.load.threads = 32
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,541] INFO Unexpected credentials store injected: null (io.confluent.kafkarest.servlet.KafkaRestApplicationProvider)
[2025-06-09 19:34:59,545] INFO For rest-app with listener null, configuring custom request logging (io.confluent.kafkarest.KafkaRestApplication)
[2025-06-09 19:34:59,547] INFO EventEmitterConfig values:
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,547] INFO EventEmitterConfig values:
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,547] INFO Applying value of confluent.telemetry.enabled flag for default '_confluent' http exporter as confluent.telemetry.exporter._confluent.enabled isn't passed (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-06-09 19:34:59,547] INFO ConfluentTelemetryConfig values:
	confluent.telemetry.api.key = null
	confluent.telemetry.api.secret = null
	confluent.telemetry.cluster.id = null
	confluent.telemetry.debug.enabled = false
	confluent.telemetry.enabled = false
	confluent.telemetry.events.collector.include = .*transaction.remove.expired.transaction.cleanup.interval.ms.*|.*transaction.state.log.load.buffer.size.*|.*transaction.state.log.min.isr.*|.*transaction.state.log.num.partitions.*|.*transaction.state.log.replication.factor.*|.*transaction.state.log.segment.bytes.*|.*transactional.id.expiration.ms.*|.*controlled.shutdown.enable.*|.*fetch.max.bytes.*|.*fetch.purgatory.purge.interval.requests.*|.*group.initial.rebalance.delay.ms.*|.*group.max.session.timeout.ms.*|.*group.max.size.*|.*group.min.session.timeout.ms.*|.*log.cleaner.backoff.ms.*|.*log.cleaner.dedupe.buffer.size.*|.*log.cleaner.delete.retention.ms.*|.*log.cleaner.enable.*|.*log.cleaner.io.buffer.load.factor.*|.*log.cleaner.io.buffer.size.*|.*log.cleaner.io.max.bytes.per.second.*|.*log.cleaner.max.compaction.lag.ms.*|.*log.cleaner.min.cleanable.ratio.*|.*log.cleaner.min.compaction.lag.ms.*|.*log.cleaner.threads.*|.*log.cleanup.policy.*|.*log.index.interval.bytes.*|.*log.index.size.max.bytes.*|.*log.message.downconversion.enable.*|.*log.message.format.version.*|.*log.message.timestamp.difference.max.ms.*|.*log.message.timestamp.type.*|.*max.connection.creation.rate.*|.*max.connections.*|.*max.connections.per.ip.*|.*max.incremental.fetch.session.cache.slots.*|.*replica.fetch.backoff.ms.*|.*replica.fetch.max.bytes.*|.*replica.fetch.min.bytes.*|.*replica.fetch.response.max.bytes.*|.*replica.fetch.wait.max.ms.*|.*replica.high.watermark.checkpoint.interval.ms.*|.*replica.lag.time.max.ms.*|.*replica.selector.class.*|.*replica.socket.receive.buffer.bytes.*|.*replica.socket.timeout.ms.*|.*alter.config.policy.class.name.*|.*alter.log.dirs.replication.quota.window.num.*|.*alter.log.dirs.replication.quota.window.size.seconds.*|.*metrics.num.samples.*|.*metrics.recording.level.*|.*metrics.sample.window.ms.*|.*quota.window.num.*|.*quota.window.size.seconds.*|.*replication.quota.window.num.*|.*replication.quota.window.size.seconds.*|.*confluent.balancer.enable.*|.*confluent.balancer.throttle.bytes.per.second.*|.*confluent.balancer.heal.uneven.load.trigger.*|.*confluent.balancer.heal.broker.failure.threshold.ms.*|.*confluent.balancer.disk.max.load.*|.*confluent.balancer.exclude.topic.prefixes.*|.*confluent.balancer.exclude.topic.names.*|.*confluent.tier.local.hotset.bytes.*|.*confluent.tier.local.hotset.ms.*|.*confluent.tier.archiver.num.threads.*|.*confluent.tier.backend.*|.*confluent.tier.enable.*|.*confluent.tier.feature.*|.*confluent.tier.fetcher.num.threads.*|.*confluent.tier.max.partition.fetch.bytes.override.*|.*confluent.tier.metadata.replication.factor.*|.*confluent.operator.managed.*|.*confluent.ansible.managed.*|.*confluent.license.*
	confluent.telemetry.events.enable = true
	confluent.telemetry.external.client.metrics.exclude.labels =
	confluent.telemetry.metrics.collector.include = .*io\.confluent\.system/(?:.*/)?(process_cpu_load|max_file_descriptor_count|open_file_descriptor_count|system_cpu_load|system_load_average|free_physical_memory_size|total_physical_memory_size|disk_total_bytes|disk_usable_bytes|jvm/mem|jvm/gc).*
	confluent.telemetry.metrics.collector.interval.ms = 60000
	confluent.telemetry.metrics.collector.slo.enabled = false
	confluent.telemetry.proxy.password = null
	confluent.telemetry.proxy.url = null
	confluent.telemetry.proxy.username = null
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,548] INFO VolumeMetricsCollectorConfig values:
	confluent.telemetry.metrics.collector.volume.update.ms = 15000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,548] INFO HttpClientConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = httpTelemetryClient
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,548] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client = _confluentClient
	client.attempts.max = null
	client.base.url = null
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = false
	events.enabled = true
	metrics.enabled = true
	metrics.include = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	remote.configurable = true
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,548] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
[2025-06-09 19:34:59,548] WARN no telemetry exporters are enabled (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-06-09 19:34:59,548] INFO PollingRemoteConfigurationConfig values:
	enabled = true
	refresh.interval.ms = 60000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,548] WARN Ignoring redefinition of existing telemetry label kafka_rest.version (io.confluent.telemetry.ResourceBuilderFacade)
[2025-06-09 19:34:59,548] INFO Applying value of confluent.telemetry.enabled flag for default '_confluent' http exporter as confluent.telemetry.exporter._confluent.enabled isn't passed (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-06-09 19:34:59,549] INFO ConfluentTelemetryConfig values:
	confluent.telemetry.api.key = null
	confluent.telemetry.api.secret = null
	confluent.telemetry.cluster.id = null
	confluent.telemetry.debug.enabled = false
	confluent.telemetry.enabled = false
	confluent.telemetry.events.collector.include = .*transaction.remove.expired.transaction.cleanup.interval.ms.*|.*transaction.state.log.load.buffer.size.*|.*transaction.state.log.min.isr.*|.*transaction.state.log.num.partitions.*|.*transaction.state.log.replication.factor.*|.*transaction.state.log.segment.bytes.*|.*transactional.id.expiration.ms.*|.*controlled.shutdown.enable.*|.*fetch.max.bytes.*|.*fetch.purgatory.purge.interval.requests.*|.*group.initial.rebalance.delay.ms.*|.*group.max.session.timeout.ms.*|.*group.max.size.*|.*group.min.session.timeout.ms.*|.*log.cleaner.backoff.ms.*|.*log.cleaner.dedupe.buffer.size.*|.*log.cleaner.delete.retention.ms.*|.*log.cleaner.enable.*|.*log.cleaner.io.buffer.load.factor.*|.*log.cleaner.io.buffer.size.*|.*log.cleaner.io.max.bytes.per.second.*|.*log.cleaner.max.compaction.lag.ms.*|.*log.cleaner.min.cleanable.ratio.*|.*log.cleaner.min.compaction.lag.ms.*|.*log.cleaner.threads.*|.*log.cleanup.policy.*|.*log.index.interval.bytes.*|.*log.index.size.max.bytes.*|.*log.message.downconversion.enable.*|.*log.message.format.version.*|.*log.message.timestamp.difference.max.ms.*|.*log.message.timestamp.type.*|.*max.connection.creation.rate.*|.*max.connections.*|.*max.connections.per.ip.*|.*max.incremental.fetch.session.cache.slots.*|.*replica.fetch.backoff.ms.*|.*replica.fetch.max.bytes.*|.*replica.fetch.min.bytes.*|.*replica.fetch.response.max.bytes.*|.*replica.fetch.wait.max.ms.*|.*replica.high.watermark.checkpoint.interval.ms.*|.*replica.lag.time.max.ms.*|.*replica.selector.class.*|.*replica.socket.receive.buffer.bytes.*|.*replica.socket.timeout.ms.*|.*alter.config.policy.class.name.*|.*alter.log.dirs.replication.quota.window.num.*|.*alter.log.dirs.replication.quota.window.size.seconds.*|.*metrics.num.samples.*|.*metrics.recording.level.*|.*metrics.sample.window.ms.*|.*quota.window.num.*|.*quota.window.size.seconds.*|.*replication.quota.window.num.*|.*replication.quota.window.size.seconds.*|.*confluent.balancer.enable.*|.*confluent.balancer.throttle.bytes.per.second.*|.*confluent.balancer.heal.uneven.load.trigger.*|.*confluent.balancer.heal.broker.failure.threshold.ms.*|.*confluent.balancer.disk.max.load.*|.*confluent.balancer.exclude.topic.prefixes.*|.*confluent.balancer.exclude.topic.names.*|.*confluent.tier.local.hotset.bytes.*|.*confluent.tier.local.hotset.ms.*|.*confluent.tier.archiver.num.threads.*|.*confluent.tier.backend.*|.*confluent.tier.enable.*|.*confluent.tier.feature.*|.*confluent.tier.fetcher.num.threads.*|.*confluent.tier.max.partition.fetch.bytes.override.*|.*confluent.tier.metadata.replication.factor.*|.*confluent.operator.managed.*|.*confluent.ansible.managed.*|.*confluent.license.*
	confluent.telemetry.events.enable = true
	confluent.telemetry.external.client.metrics.exclude.labels =
	confluent.telemetry.metrics.collector.include = .*io.confluent.telemetry/.*.*|.*io\.confluent\.system/(?:.*/)?(process_cpu_load|max_file_descriptor_count|open_file_descriptor_count|system_cpu_load|system_load_average|free_physical_memory_size|total_physical_memory_size|disk_total_bytes|disk_usable_bytes|jvm/mem|jvm/gc).*|.*io.confluent.kafka.rest/.*(connections_active|connections_closed_rate|request_error_rate|request_latency_avg|request_latency_max|request_rate|response_size_avg|response_size_max).*
	confluent.telemetry.metrics.collector.interval.ms = 60000
	confluent.telemetry.metrics.collector.slo.enabled = false
	confluent.telemetry.proxy.password = null
	confluent.telemetry.proxy.url = null
	confluent.telemetry.proxy.username = null
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,549] INFO VolumeMetricsCollectorConfig values:
	confluent.telemetry.metrics.collector.volume.update.ms = 15000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,549] INFO HttpClientConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = httpTelemetryClient
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,549] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client = _confluentClient
	client.attempts.max = null
	client.base.url = null
	client.compression = null
	client.connect.timeout.ms = null
	client.metrics.path.override = /v1/metrics
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = false
	events.enabled = true
	metrics.enabled = true
	metrics.include = null
	proxy.password = null
	proxy.url = null
	proxy.username = null
	remote.configurable = true
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,549] INFO Configuring named client _confluentClient for exporter _confluent (io.confluent.telemetry.exporter.http.HttpExporterConfig)
[2025-06-09 19:34:59,550] WARN no telemetry exporters are enabled (io.confluent.telemetry.ConfluentTelemetryConfig)
[2025-06-09 19:34:59,550] INFO PollingRemoteConfigurationConfig values:
	enabled = true
	refresh.interval.ms = 60000
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,550] INFO Initializing the event logger (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-06-09 19:34:59,550] INFO EventLoggerConfig values:
	event.logger.cloudevent.codec = structured
	event.logger.exporter.class = class io.confluent.telemetry.events.exporter.http.EventHttpExporter
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,550] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = true
	events.enabled = true
	filtering.enabled = false
	filtering.routes.allowed = []
	metrics.enabled = true
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,570] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-link-metadata. (kafka.assignor.ConfluentReplicaPlacer)
[2025-06-09 19:34:59,619] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-link-metadata-43, _confluent-link-metadata-10, _confluent-link-metadata-39, _confluent-link-metadata-6, _confluent-link-metadata-18, _confluent-link-metadata-47, _confluent-link-metadata-14, _confluent-link-metadata-27, _confluent-link-metadata-23, _confluent-link-metadata-35, _confluent-link-metadata-2, _confluent-link-metadata-31, _confluent-link-metadata-42, _confluent-link-metadata-13, _confluent-link-metadata-38, _confluent-link-metadata-9, _confluent-link-metadata-21, _confluent-link-metadata-46, _confluent-link-metadata-17, _confluent-link-metadata-26, _confluent-link-metadata-22, _confluent-link-metadata-34, _confluent-link-metadata-5, _confluent-link-metadata-30, _confluent-link-metadata-1, _confluent-link-metadata-45, _confluent-link-metadata-12, _confluent-link-metadata-41, _confluent-link-metadata-8, _confluent-link-metadata-20, _confluent-link-metadata-49, _confluent-link-metadata-16, _confluent-link-metadata-29, _confluent-link-metadata-25, _confluent-link-metadata-37, _confluent-link-metadata-4, _confluent-link-metadata-33, _confluent-link-metadata-0, _confluent-link-metadata-11, _confluent-link-metadata-44, _confluent-link-metadata-7, _confluent-link-metadata-40, _confluent-link-metadata-19, _confluent-link-metadata-15, _confluent-link-metadata-48, _confluent-link-metadata-28, _confluent-link-metadata-24, _confluent-link-metadata-3, _confluent-link-metadata-36, _confluent-link-metadata-32) (kafka.server.ReplicaFetcherManager)
[2025-06-09 19:34:59,665] INFO [MergedLog partition=_confluent-link-metadata-23, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,666] INFO Created log for partition _confluent-link-metadata-23 in /var/lib/kafka/data/_confluent-link-metadata-23 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,667] INFO [Partition _confluent-link-metadata-23 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-23 (kafka.cluster.Partition)
[2025-06-09 19:34:59,668] INFO [Partition _confluent-link-metadata-23 broker=1] Log loaded for partition _confluent-link-metadata-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,669] INFO [MergedLog partition=_confluent-link-metadata-22, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,670] INFO Created log for partition _confluent-link-metadata-22 in /var/lib/kafka/data/_confluent-link-metadata-22 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,670] INFO [Partition _confluent-link-metadata-22 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-22 (kafka.cluster.Partition)
[2025-06-09 19:34:59,671] INFO [Partition _confluent-link-metadata-22 broker=1] Log loaded for partition _confluent-link-metadata-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,669] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-23 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,671] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-22 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,673] INFO [MergedLog partition=_confluent-link-metadata-25, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,674] INFO Created log for partition _confluent-link-metadata-25 in /var/lib/kafka/data/_confluent-link-metadata-25 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,674] INFO [MergedLog partition=_confluent-link-metadata-23, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-23 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,674] INFO [Partition _confluent-link-metadata-25 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-25 (kafka.cluster.Partition)
[2025-06-09 19:34:59,675] INFO [MergedLog partition=_confluent-link-metadata-22, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-22 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,675] INFO [Partition _confluent-link-metadata-25 broker=1] Log loaded for partition _confluent-link-metadata-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,675] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-25 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,675] INFO [MergedLog partition=_confluent-link-metadata-25, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-25 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,677] INFO [MergedLog partition=_confluent-link-metadata-43, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,677] INFO Created log for partition _confluent-link-metadata-43 in /var/lib/kafka/data/_confluent-link-metadata-43 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,678] INFO [Partition _confluent-link-metadata-43 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-43 (kafka.cluster.Partition)
[2025-06-09 19:34:59,678] INFO [Partition _confluent-link-metadata-43 broker=1] Log loaded for partition _confluent-link-metadata-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,678] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-43 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,679] INFO [MergedLog partition=_confluent-link-metadata-43, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-43 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,681] INFO [MergedLog partition=_confluent-link-metadata-21, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,682] INFO Created log for partition _confluent-link-metadata-21 in /var/lib/kafka/data/_confluent-link-metadata-21 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,683] INFO [Partition _confluent-link-metadata-21 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-21 (kafka.cluster.Partition)
[2025-06-09 19:34:59,683] INFO [Partition _confluent-link-metadata-21 broker=1] Log loaded for partition _confluent-link-metadata-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,684] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-21 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,684] INFO [MergedLog partition=_confluent-link-metadata-21, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-21 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,685] INFO [MergedLog partition=_confluent-link-metadata-24, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,686] INFO Created log for partition _confluent-link-metadata-24 in /var/lib/kafka/data/_confluent-link-metadata-24 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,686] INFO [Partition _confluent-link-metadata-24 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-24 (kafka.cluster.Partition)
[2025-06-09 19:34:59,686] INFO [Partition _confluent-link-metadata-24 broker=1] Log loaded for partition _confluent-link-metadata-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,686] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-24 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,687] INFO [MergedLog partition=_confluent-link-metadata-24, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-24 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,689] INFO [MergedLog partition=_confluent-link-metadata-34, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,691] INFO Created log for partition _confluent-link-metadata-34 in /var/lib/kafka/data/_confluent-link-metadata-34 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,694] INFO [MergedLog partition=_confluent-link-metadata-20, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,694] INFO [Partition _confluent-link-metadata-34 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-34 (kafka.cluster.Partition)
[2025-06-09 19:34:59,694] INFO [Partition _confluent-link-metadata-34 broker=1] Log loaded for partition _confluent-link-metadata-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,694] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-34 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,695] INFO Created log for partition _confluent-link-metadata-20 in /var/lib/kafka/data/_confluent-link-metadata-20 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,695] INFO [MergedLog partition=_confluent-link-metadata-34, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-34 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,698] INFO [MergedLog partition=_confluent-link-metadata-39, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,698] INFO Created log for partition _confluent-link-metadata-39 in /var/lib/kafka/data/_confluent-link-metadata-39 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,698] INFO [Partition _confluent-link-metadata-20 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-20 (kafka.cluster.Partition)
[2025-06-09 19:34:59,698] INFO [Partition _confluent-link-metadata-39 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-39 (kafka.cluster.Partition)
[2025-06-09 19:34:59,700] INFO [Partition _confluent-link-metadata-39 broker=1] Log loaded for partition _confluent-link-metadata-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,700] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-39 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,700] INFO [MergedLog partition=_confluent-link-metadata-39, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-39 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,700] INFO [Partition _confluent-link-metadata-20 broker=1] Log loaded for partition _confluent-link-metadata-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,701] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-20 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,701] INFO [MergedLog partition=_confluent-link-metadata-20, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-20 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,701] INFO [MergedLog partition=_confluent-link-metadata-18, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,701] INFO Created log for partition _confluent-link-metadata-18 in /var/lib/kafka/data/_confluent-link-metadata-18 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,702] INFO [Partition _confluent-link-metadata-18 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-18 (kafka.cluster.Partition)
[2025-06-09 19:34:59,702] INFO [Partition _confluent-link-metadata-18 broker=1] Log loaded for partition _confluent-link-metadata-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,702] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-18 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,702] INFO [MergedLog partition=_confluent-link-metadata-18, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-18 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,705] INFO [MergedLog partition=_confluent-link-metadata-6, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,706] INFO Created log for partition _confluent-link-metadata-6 in /var/lib/kafka/data/_confluent-link-metadata-6 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,706] INFO [Partition _confluent-link-metadata-6 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-6 (kafka.cluster.Partition)
[2025-06-09 19:34:59,706] INFO [Partition _confluent-link-metadata-6 broker=1] Log loaded for partition _confluent-link-metadata-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,706] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-6 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,706] INFO [MergedLog partition=_confluent-link-metadata-6, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-6 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,709] INFO [MergedLog partition=_confluent-link-metadata-49, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,710] INFO Created log for partition _confluent-link-metadata-49 in /var/lib/kafka/data/_confluent-link-metadata-49 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,710] INFO [Partition _confluent-link-metadata-49 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-49 (kafka.cluster.Partition)
[2025-06-09 19:34:59,710] INFO [Partition _confluent-link-metadata-49 broker=1] Log loaded for partition _confluent-link-metadata-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,710] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-49 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,711] INFO [MergedLog partition=_confluent-link-metadata-49, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-49 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,713] INFO [MergedLog partition=_confluent-link-metadata-5, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,713] INFO Created log for partition _confluent-link-metadata-5 in /var/lib/kafka/data/_confluent-link-metadata-5 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,714] INFO [Partition _confluent-link-metadata-5 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-5 (kafka.cluster.Partition)
[2025-06-09 19:34:59,714] INFO [Partition _confluent-link-metadata-5 broker=1] Log loaded for partition _confluent-link-metadata-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,714] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-5 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,714] INFO [MergedLog partition=_confluent-link-metadata-5, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-5 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,715] INFO [MergedLog partition=_confluent-link-metadata-46, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,716] INFO Created log for partition _confluent-link-metadata-46 in /var/lib/kafka/data/_confluent-link-metadata-46 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,716] INFO [Partition _confluent-link-metadata-46 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-46 (kafka.cluster.Partition)
[2025-06-09 19:34:59,716] INFO [Partition _confluent-link-metadata-46 broker=1] Log loaded for partition _confluent-link-metadata-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,716] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-46 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,717] INFO [MergedLog partition=_confluent-link-metadata-46, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-46 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,719] INFO [MergedLog partition=_confluent-link-metadata-26, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,719] INFO Created log for partition _confluent-link-metadata-26 in /var/lib/kafka/data/_confluent-link-metadata-26 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,719] INFO [Partition _confluent-link-metadata-26 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-26 (kafka.cluster.Partition)
[2025-06-09 19:34:59,720] INFO [Partition _confluent-link-metadata-26 broker=1] Log loaded for partition _confluent-link-metadata-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,720] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-26 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,720] INFO [MergedLog partition=_confluent-link-metadata-26, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-26 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,721] INFO [MergedLog partition=_confluent-link-metadata-10, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,722] INFO Created log for partition _confluent-link-metadata-10 in /var/lib/kafka/data/_confluent-link-metadata-10 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,722] INFO [Partition _confluent-link-metadata-10 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-10 (kafka.cluster.Partition)
[2025-06-09 19:34:59,722] INFO [Partition _confluent-link-metadata-10 broker=1] Log loaded for partition _confluent-link-metadata-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,722] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-10 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,723] INFO [MergedLog partition=_confluent-link-metadata-10, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-10 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,724] INFO [MergedLog partition=_confluent-link-metadata-28, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,725] INFO Created log for partition _confluent-link-metadata-28 in /var/lib/kafka/data/_confluent-link-metadata-28 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,725] INFO [Partition _confluent-link-metadata-28 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-28 (kafka.cluster.Partition)
[2025-06-09 19:34:59,725] INFO [Partition _confluent-link-metadata-28 broker=1] Log loaded for partition _confluent-link-metadata-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,725] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-28 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,725] INFO [MergedLog partition=_confluent-link-metadata-28, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-28 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,728] INFO [MergedLog partition=_confluent-link-metadata-29, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,728] INFO Created log for partition _confluent-link-metadata-29 in /var/lib/kafka/data/_confluent-link-metadata-29 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,728] INFO [Partition _confluent-link-metadata-29 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-29 (kafka.cluster.Partition)
[2025-06-09 19:34:59,728] INFO [Partition _confluent-link-metadata-29 broker=1] Log loaded for partition _confluent-link-metadata-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,729] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-29 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,730] INFO [MergedLog partition=_confluent-link-metadata-29, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-29 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,731] INFO [MergedLog partition=_confluent-link-metadata-27, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,732] INFO Created log for partition _confluent-link-metadata-27 in /var/lib/kafka/data/_confluent-link-metadata-27 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,732] INFO [Partition _confluent-link-metadata-27 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-27 (kafka.cluster.Partition)
[2025-06-09 19:34:59,732] INFO [Partition _confluent-link-metadata-27 broker=1] Log loaded for partition _confluent-link-metadata-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,733] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-27 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,733] INFO [MergedLog partition=_confluent-link-metadata-27, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-27 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,735] INFO [MergedLog partition=_confluent-link-metadata-33, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,735] INFO Created log for partition _confluent-link-metadata-33 in /var/lib/kafka/data/_confluent-link-metadata-33 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,736] INFO [Partition _confluent-link-metadata-33 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-33 (kafka.cluster.Partition)
[2025-06-09 19:34:59,736] INFO [Partition _confluent-link-metadata-33 broker=1] Log loaded for partition _confluent-link-metadata-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,736] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-33 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,736] INFO [MergedLog partition=_confluent-link-metadata-33, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-33 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,738] INFO [MergedLog partition=_confluent-link-metadata-32, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,739] INFO Created log for partition _confluent-link-metadata-32 in /var/lib/kafka/data/_confluent-link-metadata-32 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,739] INFO [Partition _confluent-link-metadata-32 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-32 (kafka.cluster.Partition)
[2025-06-09 19:34:59,739] INFO [Partition _confluent-link-metadata-32 broker=1] Log loaded for partition _confluent-link-metadata-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,739] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-32 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,740] INFO [MergedLog partition=_confluent-link-metadata-32, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-32 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,743] INFO [MergedLog partition=_confluent-link-metadata-3, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,744] INFO Created log for partition _confluent-link-metadata-3 in /var/lib/kafka/data/_confluent-link-metadata-3 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,744] INFO [Partition _confluent-link-metadata-3 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-3 (kafka.cluster.Partition)
[2025-06-09 19:34:59,744] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = true
	events.enabled = true
	filtering.enabled = false
	filtering.routes.allowed = []
	metrics.enabled = true
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,744] INFO [Partition _confluent-link-metadata-3 broker=1] Log loaded for partition _confluent-link-metadata-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,744] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-3 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,744] INFO HttpExporterConfig values:
	api.key = null
	api.secret = null
	buffer.batch.duration.max.ms = null
	buffer.batch.items.max = null
	buffer.inflight.submissions.max = null
	buffer.pending.batches.max = null
	client.attempts.max = null
	client.base.url = https://collector.telemetry.confluent.cloud
	client.compression = null
	client.connect.timeout.ms = null
	client.request.timeout.ms = null
	client.retry.delay.seconds = null
	enabled = true
	events.enabled = true
	filtering.enabled = false
	filtering.routes.allowed = []
	metrics.enabled = true
	proxy.password = null
	proxy.url = null
	proxy.username = null
	type = http
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,744] INFO [MergedLog partition=_confluent-link-metadata-3, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-3 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,747] INFO [MergedLog partition=_confluent-link-metadata-35, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,748] INFO Created log for partition _confluent-link-metadata-35 in /var/lib/kafka/data/_confluent-link-metadata-35 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,748] INFO [Partition _confluent-link-metadata-35 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-35 (kafka.cluster.Partition)
[2025-06-09 19:34:59,748] INFO [Partition _confluent-link-metadata-35 broker=1] Log loaded for partition _confluent-link-metadata-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,748] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-35 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,749] INFO [MergedLog partition=_confluent-link-metadata-35, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-35 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,751] INFO [MergedLog partition=_confluent-link-metadata-41, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,751] INFO Created log for partition _confluent-link-metadata-41 in /var/lib/kafka/data/_confluent-link-metadata-41 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,752] INFO [Partition _confluent-link-metadata-41 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-41 (kafka.cluster.Partition)
[2025-06-09 19:34:59,752] INFO [Partition _confluent-link-metadata-41 broker=1] Log loaded for partition _confluent-link-metadata-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,752] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-41 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,753] INFO [MergedLog partition=_confluent-link-metadata-41, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-41 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,754] INFO [MergedLog partition=_confluent-link-metadata-17, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,754] INFO Created log for partition _confluent-link-metadata-17 in /var/lib/kafka/data/_confluent-link-metadata-17 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,756] INFO [Partition _confluent-link-metadata-17 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-17 (kafka.cluster.Partition)
[2025-06-09 19:34:59,756] INFO [Partition _confluent-link-metadata-17 broker=1] Log loaded for partition _confluent-link-metadata-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,756] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-17 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,756] INFO [MergedLog partition=_confluent-link-metadata-17, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-17 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,758] INFO [MergedLog partition=_confluent-link-metadata-30, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,758] INFO Created log for partition _confluent-link-metadata-30 in /var/lib/kafka/data/_confluent-link-metadata-30 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,759] INFO [Partition _confluent-link-metadata-30 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-30 (kafka.cluster.Partition)
[2025-06-09 19:34:59,759] INFO [Partition _confluent-link-metadata-30 broker=1] Log loaded for partition _confluent-link-metadata-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,759] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-30 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,759] INFO [MergedLog partition=_confluent-link-metadata-30, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-30 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,762] INFO [MergedLog partition=_confluent-link-metadata-16, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,762] INFO Created log for partition _confluent-link-metadata-16 in /var/lib/kafka/data/_confluent-link-metadata-16 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,762] INFO [Partition _confluent-link-metadata-16 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-16 (kafka.cluster.Partition)
[2025-06-09 19:34:59,763] INFO [Partition _confluent-link-metadata-16 broker=1] Log loaded for partition _confluent-link-metadata-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,763] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-16 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,763] INFO [MergedLog partition=_confluent-link-metadata-16, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-16 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,764] INFO [MergedLog partition=_confluent-link-metadata-31, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,765] INFO Created log for partition _confluent-link-metadata-31 in /var/lib/kafka/data/_confluent-link-metadata-31 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,765] INFO [Partition _confluent-link-metadata-31 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-31 (kafka.cluster.Partition)
[2025-06-09 19:34:59,765] INFO [Partition _confluent-link-metadata-31 broker=1] Log loaded for partition _confluent-link-metadata-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,765] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-31 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,766] INFO [MergedLog partition=_confluent-link-metadata-31, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-31 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,768] INFO [MergedLog partition=_confluent-link-metadata-42, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,768] INFO Created log for partition _confluent-link-metadata-42 in /var/lib/kafka/data/_confluent-link-metadata-42 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,768] INFO [Partition _confluent-link-metadata-42 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-42 (kafka.cluster.Partition)
[2025-06-09 19:34:59,768] INFO [Partition _confluent-link-metadata-42 broker=1] Log loaded for partition _confluent-link-metadata-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,769] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-42 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,769] INFO [MergedLog partition=_confluent-link-metadata-42, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-42 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,771] INFO [MergedLog partition=_confluent-link-metadata-13, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,772] INFO Created log for partition _confluent-link-metadata-13 in /var/lib/kafka/data/_confluent-link-metadata-13 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,772] INFO [Partition _confluent-link-metadata-13 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-13 (kafka.cluster.Partition)
[2025-06-09 19:34:59,774] INFO [Partition _confluent-link-metadata-13 broker=1] Log loaded for partition _confluent-link-metadata-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,774] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-13 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,775] INFO [MergedLog partition=_confluent-link-metadata-13, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-13 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,776] INFO [MergedLog partition=_confluent-link-metadata-47, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,777] INFO Created log for partition _confluent-link-metadata-47 in /var/lib/kafka/data/_confluent-link-metadata-47 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,777] INFO [Partition _confluent-link-metadata-47 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-47 (kafka.cluster.Partition)
[2025-06-09 19:34:59,778] INFO [Partition _confluent-link-metadata-47 broker=1] Log loaded for partition _confluent-link-metadata-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,778] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-47 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,778] INFO [MergedLog partition=_confluent-link-metadata-47, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-47 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,779] INFO [MergedLog partition=_confluent-link-metadata-19, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,780] INFO Created log for partition _confluent-link-metadata-19 in /var/lib/kafka/data/_confluent-link-metadata-19 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,780] INFO [Partition _confluent-link-metadata-19 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-19 (kafka.cluster.Partition)
[2025-06-09 19:34:59,780] INFO [Partition _confluent-link-metadata-19 broker=1] Log loaded for partition _confluent-link-metadata-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,781] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-19 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,781] INFO [MergedLog partition=_confluent-link-metadata-19, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-19 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,783] INFO [MergedLog partition=_confluent-link-metadata-45, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,784] INFO Created log for partition _confluent-link-metadata-45 in /var/lib/kafka/data/_confluent-link-metadata-45 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,784] INFO [Partition _confluent-link-metadata-45 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-45 (kafka.cluster.Partition)
[2025-06-09 19:34:59,784] INFO [Partition _confluent-link-metadata-45 broker=1] Log loaded for partition _confluent-link-metadata-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,785] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-45 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,785] INFO [MergedLog partition=_confluent-link-metadata-45, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-45 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,786] INFO [MergedLog partition=_confluent-link-metadata-1, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,787] INFO Created log for partition _confluent-link-metadata-1 in /var/lib/kafka/data/_confluent-link-metadata-1 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,787] INFO [Partition _confluent-link-metadata-1 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-1 (kafka.cluster.Partition)
[2025-06-09 19:34:59,787] INFO [Partition _confluent-link-metadata-1 broker=1] Log loaded for partition _confluent-link-metadata-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,787] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-1 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,787] INFO [MergedLog partition=_confluent-link-metadata-1, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-1 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,789] INFO [MergedLog partition=_confluent-link-metadata-37, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,790] INFO Created log for partition _confluent-link-metadata-37 in /var/lib/kafka/data/_confluent-link-metadata-37 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,790] INFO [Partition _confluent-link-metadata-37 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-37 (kafka.cluster.Partition)
[2025-06-09 19:34:59,790] INFO [Partition _confluent-link-metadata-37 broker=1] Log loaded for partition _confluent-link-metadata-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,790] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-37 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,790] INFO [MergedLog partition=_confluent-link-metadata-37, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-37 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,792] INFO [MergedLog partition=_confluent-link-metadata-8, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,792] INFO Created log for partition _confluent-link-metadata-8 in /var/lib/kafka/data/_confluent-link-metadata-8 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,793] INFO [Partition _confluent-link-metadata-8 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-8 (kafka.cluster.Partition)
[2025-06-09 19:34:59,793] INFO [Partition _confluent-link-metadata-8 broker=1] Log loaded for partition _confluent-link-metadata-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,793] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-8 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,793] INFO [MergedLog partition=_confluent-link-metadata-8, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-8 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,795] INFO [MergedLog partition=_confluent-link-metadata-2, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,796] INFO Created log for partition _confluent-link-metadata-2 in /var/lib/kafka/data/_confluent-link-metadata-2 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,798] INFO [MergedLog partition=_confluent-link-metadata-36, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,799] INFO Created log for partition _confluent-link-metadata-36 in /var/lib/kafka/data/_confluent-link-metadata-36 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,799] INFO [Partition _confluent-link-metadata-36 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-36 (kafka.cluster.Partition)
[2025-06-09 19:34:59,799] INFO [Partition _confluent-link-metadata-36 broker=1] Log loaded for partition _confluent-link-metadata-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,799] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-36 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,800] INFO [MergedLog partition=_confluent-link-metadata-36, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-36 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,800] INFO [Partition _confluent-link-metadata-2 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-2 (kafka.cluster.Partition)
[2025-06-09 19:34:59,800] INFO [Partition _confluent-link-metadata-2 broker=1] Log loaded for partition _confluent-link-metadata-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,800] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-2 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,800] INFO [MergedLog partition=_confluent-link-metadata-2, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-2 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,801] INFO [MergedLog partition=_confluent-link-metadata-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,802] INFO Created log for partition _confluent-link-metadata-0 in /var/lib/kafka/data/_confluent-link-metadata-0 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,802] INFO [Partition _confluent-link-metadata-0 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,802] INFO [Partition _confluent-link-metadata-0 broker=1] Log loaded for partition _confluent-link-metadata-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,803] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-0 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,803] INFO [MergedLog partition=_confluent-link-metadata-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,804] INFO [MergedLog partition=_confluent-link-metadata-38, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,805] INFO Created log for partition _confluent-link-metadata-38 in /var/lib/kafka/data/_confluent-link-metadata-38 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,805] INFO [Partition _confluent-link-metadata-38 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-38 (kafka.cluster.Partition)
[2025-06-09 19:34:59,805] INFO [Partition _confluent-link-metadata-38 broker=1] Log loaded for partition _confluent-link-metadata-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,805] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-38 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,805] INFO [MergedLog partition=_confluent-link-metadata-38, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-38 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,807] INFO [MergedLog partition=_confluent-link-metadata-9, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,808] INFO Created log for partition _confluent-link-metadata-9 in /var/lib/kafka/data/_confluent-link-metadata-9 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,809] INFO [Partition _confluent-link-metadata-9 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-9 (kafka.cluster.Partition)
[2025-06-09 19:34:59,809] INFO [Partition _confluent-link-metadata-9 broker=1] Log loaded for partition _confluent-link-metadata-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,809] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-9 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,809] INFO [MergedLog partition=_confluent-link-metadata-9, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-9 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,823] INFO [MergedLog partition=_confluent-link-metadata-11, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,824] INFO Created log for partition _confluent-link-metadata-11 in /var/lib/kafka/data/_confluent-link-metadata-11 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,824] INFO [Partition _confluent-link-metadata-11 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-11 (kafka.cluster.Partition)
[2025-06-09 19:34:59,824] INFO [Partition _confluent-link-metadata-11 broker=1] Log loaded for partition _confluent-link-metadata-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,824] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-11 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,825] INFO [MergedLog partition=_confluent-link-metadata-11, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-11 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,830] INFO [MergedLog partition=_confluent-link-metadata-4, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,831] INFO Created log for partition _confluent-link-metadata-4 in /var/lib/kafka/data/_confluent-link-metadata-4 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,832] INFO [Partition _confluent-link-metadata-4 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-4 (kafka.cluster.Partition)
[2025-06-09 19:34:59,832] INFO [Partition _confluent-link-metadata-4 broker=1] Log loaded for partition _confluent-link-metadata-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,833] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-4 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,833] INFO [MergedLog partition=_confluent-link-metadata-4, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-4 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,834] INFO [MergedLog partition=_confluent-link-metadata-7, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,834] INFO Created log for partition _confluent-link-metadata-7 in /var/lib/kafka/data/_confluent-link-metadata-7 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,834] INFO [Partition _confluent-link-metadata-7 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-7 (kafka.cluster.Partition)
[2025-06-09 19:34:59,835] INFO [Partition _confluent-link-metadata-7 broker=1] Log loaded for partition _confluent-link-metadata-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,835] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-7 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,835] INFO [MergedLog partition=_confluent-link-metadata-7, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-7 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,837] INFO [MergedLog partition=_confluent-link-metadata-12, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,838] INFO Created log for partition _confluent-link-metadata-12 in /var/lib/kafka/data/_confluent-link-metadata-12 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,838] INFO Creating kafka exporter named '_local' (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-06-09 19:34:59,838] INFO [Partition _confluent-link-metadata-12 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-12 (kafka.cluster.Partition)
[2025-06-09 19:34:59,839] INFO [Partition _confluent-link-metadata-12 broker=1] Log loaded for partition _confluent-link-metadata-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,839] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-12 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,839] INFO [MergedLog partition=_confluent-link-metadata-12, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-12 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,841] INFO [MergedLog partition=_confluent-link-metadata-15, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,842] INFO Created log for partition _confluent-link-metadata-15 in /var/lib/kafka/data/_confluent-link-metadata-15 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,842] INFO [Partition _confluent-link-metadata-15 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-15 (kafka.cluster.Partition)
[2025-06-09 19:34:59,842] INFO [Partition _confluent-link-metadata-15 broker=1] Log loaded for partition _confluent-link-metadata-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,843] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-15 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,843] INFO [MergedLog partition=_confluent-link-metadata-15, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-15 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,845] INFO [MergedLog partition=_confluent-link-metadata-14, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,845] INFO Created log for partition _confluent-link-metadata-14 in /var/lib/kafka/data/_confluent-link-metadata-14 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,846] INFO [Partition _confluent-link-metadata-14 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-14 (kafka.cluster.Partition)
[2025-06-09 19:34:59,846] INFO [Partition _confluent-link-metadata-14 broker=1] Log loaded for partition _confluent-link-metadata-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,846] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-14 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,847] INFO [MergedLog partition=_confluent-link-metadata-14, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-14 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,849] INFO [MergedLog partition=_confluent-link-metadata-48, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,850] INFO Created log for partition _confluent-link-metadata-48 in /var/lib/kafka/data/_confluent-link-metadata-48 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,850] INFO [Partition _confluent-link-metadata-48 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-48 (kafka.cluster.Partition)
[2025-06-09 19:34:59,850] INFO [Partition _confluent-link-metadata-48 broker=1] Log loaded for partition _confluent-link-metadata-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,851] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-48 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,852] INFO Kafka Exporter _local getting producer client  (io.confluent.telemetry.exporter.kafka.KafkaExporter)
[2025-06-09 19:34:59,852] INFO [MergedLog partition=_confluent-link-metadata-48, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-48 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,852] INFO Creating new non-static producer client (io.confluent.telemetry.exporter.kafka.KafkaClientFactory)
[2025-06-09 19:34:59,852] INFO [MergedLog partition=_confluent-link-metadata-40, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,853] INFO Created log for partition _confluent-link-metadata-40 in /var/lib/kafka/data/_confluent-link-metadata-40 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,856] INFO [MergedLog partition=_confluent-link-metadata-44, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:34:59,856] INFO Created log for partition _confluent-link-metadata-44 in /var/lib/kafka/data/_confluent-link-metadata-44 with properties {cleanup.policy=compact, min.insync.replicas=2} (kafka.log.LogManager)
[2025-06-09 19:34:59,857] INFO [Partition _confluent-link-metadata-44 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-44 (kafka.cluster.Partition)
[2025-06-09 19:34:59,857] INFO [Partition _confluent-link-metadata-44 broker=1] Log loaded for partition _confluent-link-metadata-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,857] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-44 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,857] INFO [MergedLog partition=_confluent-link-metadata-44, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-44 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,857] INFO [Partition _confluent-link-metadata-40 broker=1] No checkpointed highwatermark is found for partition _confluent-link-metadata-40 (kafka.cluster.Partition)
[2025-06-09 19:34:59,857] INFO [Partition _confluent-link-metadata-40 broker=1] Log loaded for partition _confluent-link-metadata-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:34:59,857] INFO Setting topicIdPartition rrl02HWHRZesyNVFziuNjQ:_confluent-link-metadata-40 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:34:59,858] INFO [MergedLog partition=_confluent-link-metadata-40, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-link-metadata-40 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:34:59,859] INFO ProducerConfig values:
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = confluent-telemetry-reporter-local-producer
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = zstd
	compression.zstd.level = 3
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 10485760
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = class io.confluent.telemetry.events.exporter.kafka.RandomBrokerPartitionSubsetPartitioner
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.telemetry.serde.OpenTelemetryMetricsSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:34:59,865] INFO [DynamicConfigPublisher broker id=1] Updating topic _confluent-link-metadata with new configuration : cleanup.policy -> compact,min.insync.replicas -> 2 (kafka.server.metadata.DynamicConfigPublisher)
[2025-06-09 19:34:59,877] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:34:59,877] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:34:59,878] INFO Kafka startTimeMs: 1749497699877 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:34:59,885] INFO [Producer clientId=confluent-telemetry-reporter-local-producer] Cluster ID: MkU3OEVBNTcwNTJENDM2Qk (org.apache.kafka.clients.Metadata)
[2025-06-09 19:34:59,943] INFO Starting Confluent telemetry reporter with an interval of 60000 ms) (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-06-09 19:34:59,943] INFO Starting Confluent telemetry reporter with an interval of 60000 ms) (io.confluent.telemetry.reporter.TelemetryReporter)
[2025-06-09 19:34:59,959] ERROR Unable to submit events without credentials (io.confluent.telemetry.events.exporter.http.HttpExporter)
[2025-06-09 19:34:59,959] ERROR Unable to submit events without credentials (io.confluent.telemetry.events.exporter.http.HttpExporter)
[2025-06-09 19:34:59,960] INFO Application provider 'KafkaRestApplicationProvider' provided 1 instance(s). (io.confluent.http.server.KafkaHttpApplicationLoader)
[2025-06-09 19:34:59,970] INFO DynamicMetricsReporters initiated successfully. (kafka.server.DynamicMetricsReportersScheduler)
[2025-06-09 19:34:59,970] INFO Stopping DynamicMetricsReportersScheduler. (kafka.server.DynamicMetricsReportersScheduler)
[2025-06-09 19:35:00,109] INFO Loaded KafkaHttpServer implementation class io.confluent.http.server.KafkaHttpServerImpl (io.confluent.kafka.http.server.KafkaHttpServerLoader)
[2025-06-09 19:35:00,109] INFO KafkaHttpServer transitioned from NEW to STARTING.. (io.confluent.http.server.KafkaHttpServerImpl)
[2025-06-09 19:35:00,261] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-06-09 19:35:00,262] INFO SchemaRegistryConfig values:
	auto.register.schemas = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.custom.provider.class = null
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	http.connect.timeout.ms = 60000
	http.read.timeout.ms = 60000
	id.compatibility.strict = true
	key.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	key.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.retries = 3
	max.schemas.per.subject = 1000
	normalize.schemas = false
	propagate.schema.tags = false
	proxy.host =
	proxy.port = -1
	retries.max.wait.ms = 20000
	retries.wait.ms = 1000
	rule.actions = []
	rule.executors = []
	rule.service.loader.enable = true
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	schema.registry.url.randomize = false
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.schema.id.deserializer = class io.confluent.kafka.serializers.schema.id.DualSchemaIdDeserializer
	value.schema.id.serializer = class io.confluent.kafka.serializers.schema.id.PrefixSchemaIdSerializer
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:00,623] INFO HV000001: Hibernate Validator 8.0.1.Final (org.hibernate.validator.internal.util.Version)
[2025-06-09 19:35:00,816] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-06-09 19:35:00,818] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-06-09 19:35:00,824] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-06-09 19:35:00,831] WARN Using default value http://localhost:8081 for config schema.registry.url. In a future release this config won't have a default value anymore. If you are using Schema Registry, please, specify schema.registry.url explicitly. Requests will fail in a future release if you try to use Schema Registry but have not specified a value for schema.registry.url. An empty value for this property means that the Schema Registry is disabled. (io.confluent.kafkarest.KafkaRestConfig)
[2025-06-09 19:35:01,219] INFO KafkaHttpServer transitioned from STARTING to RUNNING.. (io.confluent.http.server.KafkaHttpServerImpl)
[2025-06-09 19:35:01,228] INFO LicenseConfig values:
	confluent.license = [hidden]
	confluent.license.retry.backoff.max.ms = 100000
	confluent.license.retry.backoff.min.ms = 1000
	confluent.license.topic = _confluent-license
	confluent.license.topic.create.timeout.ms = 600000
	confluent.license.topic.replication.factor = 1
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,228] INFO LicenseConfig values:
	confluent.license = [hidden]
	confluent.license.retry.backoff.max.ms = 100000
	confluent.license.retry.backoff.min.ms = 1000
	confluent.license.topic = _confluent-license
	confluent.license.topic.create.timeout.ms = 600000
	confluent.license.topic.replication.factor = 1
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,240] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,241] INFO These configurations '[replication.factor, confluent.link.metadata.topic.replication.factor, confluent.balancer.topics.replication.factor, confluent.command.topic.replication, min.insync.replicas, cluster.link.metadata.topic.replication.factor]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,241] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,241] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,241] INFO Kafka startTimeMs: 1749497701241 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,262] INFO App info kafka.admin.client for _confluent-license-admin-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,274] INFO Starting License Store (io.confluent.license.LicenseStore)
[2025-06-09 19:35:01,274] INFO Starting KafkaBasedLog with topic _confluent-command reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-06-09 19:35:01,274] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,275] INFO These configurations '[replication.factor, confluent.link.metadata.topic.replication.factor, confluent.balancer.topics.replication.factor, confluent.command.topic.replication, min.insync.replicas, cluster.link.metadata.topic.replication.factor]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,275] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,275] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,275] INFO Kafka startTimeMs: 1749497701275 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,284] INFO [ControllerServer id=1] Using the default placer, StripedReplicaPlacer, to make the assignment for topic _confluent-command. (kafka.assignor.ConfluentReplicaPlacer)
[2025-06-09 19:35:01,312] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(_confluent-command-0) (kafka.server.ReplicaFetcherManager)
[2025-06-09 19:35:01,313] INFO App info kafka.admin.client for _confluent-license-admin-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,316] INFO [MergedLog partition=_confluent-command-0, dir=/var/lib/kafka/data] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.MergedLogUtils)
[2025-06-09 19:35:01,316] INFO Created log for partition _confluent-command-0 in /var/lib/kafka/data/_confluent-command-0 with properties {cleanup.policy=compact, min.insync.replicas=1} (kafka.log.LogManager)
[2025-06-09 19:35:01,316] INFO ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-consumer-1
	client.rack =
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,317] INFO [Partition _confluent-command-0 broker=1] No checkpointed highwatermark is found for partition _confluent-command-0 (kafka.cluster.Partition)
[2025-06-09 19:35:01,317] INFO [Partition _confluent-command-0 broker=1] Log loaded for partition _confluent-command-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-06-09 19:35:01,317] INFO Setting topicIdPartition lCSabzzKSxG_AsjVL_CnYA:_confluent-command-0 (kafka.tier.state.FileTierPartitionState)
[2025-06-09 19:35:01,317] INFO [MergedLog partition=_confluent-command-0, dir=/var/lib/kafka/data] Initializing tier metadata without recovery for _confluent-command-0 because, either the recovery is active (false) or local log start offset 0 and check-pointed log start offset 0 do not indicate any missing tier metadata. (kafka.log.MergedLog)
[2025-06-09 19:35:01,318] INFO [DynamicConfigPublisher broker id=1] Updating topic _confluent-command with new configuration : cleanup.policy -> compact,min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
[2025-06-09 19:35:01,343] INFO These configurations '[confluent.link.metadata.topic.replication.factor, confluent.balancer.topics.replication.factor, confluent.command.topic.replication, cluster.link.metadata.topic.replication.factor]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,343] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,343] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,343] INFO Kafka startTimeMs: 1749497701343 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,348] INFO [Consumer clientId=_confluent-license-consumer-1, groupId=null] Cluster ID: MkU3OEVBNTcwNTJENDM2Qk (org.apache.kafka.clients.Metadata)
[2025-06-09 19:35:01,354] INFO App info kafka.consumer for _confluent-license-consumer-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,355] INFO ProducerConfig values:
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = false
	interceptor.classes = []
	key.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	linger.ms = 5
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,356] INFO These configurations '[cluster.link.metadata.topic.replication.factor, confluent.link.metadata.topic.replication.factor, confluent.balancer.topics.replication.factor, confluent.command.topic.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,356] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,356] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,356] INFO Kafka startTimeMs: 1749497701356 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,357] INFO ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-consumer-1
	client.rack =
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,358] INFO These configurations '[cluster.link.metadata.topic.replication.factor, confluent.link.metadata.topic.replication.factor, confluent.balancer.topics.replication.factor, confluent.command.topic.replication]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,358] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,358] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,358] INFO Kafka startTimeMs: 1749497701358 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,360] INFO [Producer clientId=_confluent-license-producer-1] Cluster ID: MkU3OEVBNTcwNTJENDM2Qk (org.apache.kafka.clients.Metadata)
[2025-06-09 19:35:01,361] INFO [Consumer clientId=_confluent-license-consumer-1, groupId=null] Cluster ID: MkU3OEVBNTcwNTJENDM2Qk (org.apache.kafka.clients.Metadata)
[2025-06-09 19:35:01,362] INFO [Consumer clientId=_confluent-license-consumer-1, groupId=null] Assigned to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer)
[2025-06-09 19:35:01,365] INFO [Consumer clientId=_confluent-license-consumer-1, groupId=null] Seeking to AutoOffsetResetStrategy{type=earliest} offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-06-09 19:35:01,384] INFO Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-06-09 19:35:01,384] INFO Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-06-09 19:35:01,384] INFO Started License Store (io.confluent.license.LicenseStore)
[2025-06-09 19:35:01,960] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,962] INFO These configurations '[replication.factor, confluent.link.metadata.topic.replication.factor, confluent.balancer.topics.replication.factor, confluent.command.topic.replication, min.insync.replicas, cluster.link.metadata.topic.replication.factor]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:01,962] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,962] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,962] INFO Kafka startTimeMs: 1749497701962 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:01,970] INFO App info kafka.admin.client for _confluent-license-admin-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:02,018] INFO AdminClientConfig values:
	bootstrap.controllers = []
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = _confluent-license-admin-1
	confluent.admin.client.describe.topic.partitions.enabled = true
	confluent.client.switchover.disable = false
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = false
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metadata.recovery.rebootstrap.trigger.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.jaas.config.jndi.allowlist = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.assertion.claim.aud = null
	sasl.oauthbearer.assertion.claim.exp.minutes = 5
	sasl.oauthbearer.assertion.claim.iss = null
	sasl.oauthbearer.assertion.claim.jti.include = false
	sasl.oauthbearer.assertion.claim.nbf.include = false
	sasl.oauthbearer.assertion.claim.sub = null
	sasl.oauthbearer.assertion.file = null
	sasl.oauthbearer.assertion.private.key.file = null
	sasl.oauthbearer.assertion.private.key.passphrase = null
	sasl.oauthbearer.assertion.template.file = null
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.iat.validation.enabled = false
	sasl.oauthbearer.jti.validation.enabled = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:02,019] INFO These configurations '[replication.factor, confluent.link.metadata.topic.replication.factor, confluent.balancer.topics.replication.factor, confluent.command.topic.replication, min.insync.replicas, cluster.link.metadata.topic.replication.factor]' were supplied but are not used yet. (org.apache.kafka.common.config.AbstractConfig)
[2025-06-09 19:35:02,020] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:02,020] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:02,020] INFO Kafka startTimeMs: 1749497702019 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:02,025] INFO App info kafka.admin.client for _confluent-license-admin-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:02,026] INFO License for single cluster, single node (io.confluent.license.LicenseManager)
[2025-06-09 19:35:02,029] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2025-06-09 19:35:02,029] INFO Kafka version: 8.0.0-0-ce (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:02,029] INFO Kafka commitId: 3e3ef2b4df5f3903 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:02,029] INFO Kafka startTimeMs: 1749497702029 (org.apache.kafka.common.utils.AppInfoParser)
[2025-06-09 19:35:02,030] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
[2025-06-09 19:35:29,248] INFO Beginning log roller... (kafka.log.LogManager)
[2025-06-09 19:35:29,251] INFO Log roller completed in 0 seconds (kafka.log.LogManager)